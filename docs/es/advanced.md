# Usos avanzados

Muchos ejemplos de casos de uso del mundo real est谩n disponibles en la carpeta [examples](https://github.com/bunkerity/bunkerweb/tree/v1.6.6/examples) del repositorio de GitHub.

Tambi茅n proporcionamos numerosos boilerplates, como archivos YAML para diversas integraciones y tipos de bases de datos. Estos est谩n disponibles en la carpeta [misc/integrations](https://github.com/bunkerity/bunkerweb/tree/v1.6.6/misc/integrations).

Esta secci贸n solo se enfoca en usos avanzados y ajustes de seguridad, consulta la [secci贸n de caracter铆sticas](features.md) de la documentaci贸n para ver todas las configuraciones disponibles.

!!! tip "Pruebas"
    Para realizar pruebas r谩pidas cuando el modo multisitio est谩 habilitado (y si no tienes las entradas DNS adecuadas configuradas para los dominios) puedes usar curl con la cabecera HTTP Host de tu elecci贸n:
    ```shell
    curl -H "Host: app1.example.com" http://ip-o-fqdn-del-servidor
    ```

    Si est谩s usando HTTPS, necesitar谩s jugar con SNI:
    ```shell
    curl -H "Host: app1.example.com" --resolve example.com:443:ip-del-servidor https://example.com
    ```

## Detr谩s de un balanceador de carga o proxy inverso {#behind-load-balancer-or-reverse-proxy}

!!! info "IP real"

    Cuando BunkerWeb est谩 a su vez detr谩s de un balanceador de carga o un proxy inverso, necesitas configurarlo para que pueda obtener la direcci贸n IP real de los clientes. **Si no lo haces, las caracter铆sticas de seguridad bloquear谩n la direcci贸n IP del balanceador de carga o del proxy inverso en lugar de la del cliente**.

BunkerWeb admite dos m茅todos para recuperar la direcci贸n IP real del cliente:

- Usando el `protocolo PROXY`
- Usando una cabecera HTTP como `X-Forwarded-For`

Se pueden usar las siguientes configuraciones:

- `USE_REAL_IP`: habilitar/deshabilitar la recuperaci贸n de la IP real
- `USE_PROXY_PROTOCOL`: habilitar/deshabilitar el soporte del protocolo PROXY.
- `REAL_IP_FROM`: lista de direcciones IP/red de confianza permitidas para enviarnos la "IP real"
- `REAL_IP_HEADER`: la cabecera HTTP que contiene la IP real o el valor especial `proxy_protocol` cuando se usa el protocolo PROXY

Encontrar谩s m谩s configuraciones sobre la IP real en la [secci贸n de caracter铆sticas](features.md#real-ip) de la documentaci贸n.

=== "Cabecera HTTP"

    Asumiremos lo siguiente con respecto a los balanceadores de carga o proxies inversos (necesitar谩s actualizar la configuraci贸n dependiendo de tu configuraci贸n):

    - Usan la cabecera `X-Forwarded-For` para establecer la IP real
    - Tienen IPs en las redes `1.2.3.0/24` y `100.64.0.0/10`

    === "Interfaz de usuario web"

        Navega a la p谩gina de **Configuraci贸n Global**, selecciona el plugin **Real IP** y completa las siguientes configuraciones:

        <figure markdown>![Configuraci贸n de IP real (cabecera) usando la interfaz de usuario web](assets/img/advanced-proxy1.png){ align=center }<figcaption>Configuraci贸n de IP real (cabecera) usando la interfaz de usuario web</figcaption></figure>

        Ten en cuenta que se recomienda reiniciar BunkerWeb cuando cambies la configuraci贸n relacionada con la IP real.

    === "Linux"

        Necesitar谩s agregar la configuraci贸n al archivo `/etc/bunkerweb/variables.env`:

        ```conf
        ...
        USE_REAL_IP=yes
        REAL_IP_FROM=1.2.3.0/24 100.64.0.0/16
        REAL_IP_HEADER=X-Forwarded-For
        ...
        ```

        Ten en cuenta que se recomienda emitir un reinicio en lugar de una recarga al configurar ajustes relacionados con la IP real:

        ```shell
        sudo systemctl restart bunkerweb && \
        sudo systemctl restart bunkerweb-scheduler
        ```

    === "Todo en uno"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno al ejecutar el contenedor Todo en uno:

        ```bash
        docker run -d \
            --name bunkerweb-aio \
            -v bw-storage:/data \
            -e USE_REAL_IP="yes" \
            -e REAL_IP_FROM="1.2.3.0/24 100.64.0.0/10" \
            -e REAL_IP_HEADER="X-Forwarded-For" \
            -p 80:8080/tcp \
            -p 443:8443/tcp \
            -p 443:8443/udp \
            bunkerity/bunkerweb-all-in-one:1.6.6
        ```

        Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

    === "Docker"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los contenedores de BunkerWeb y del programador:

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        ```

        Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

    === "Docker autoconf"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los contenedores de BunkerWeb y del programador:

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        ```

        Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

    === "Kubernetes"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los pods de BunkerWeb y del programador.

        Aqu铆 est谩 la parte correspondiente de tu archivo `values.yaml` que puedes usar:

        ```yaml
        bunkerweb:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "X-Forwarded-For"
        scheduler:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "X-Forwarded-For"
        ```

    === "Swarm"

        !!! warning "Obsoleto"
            La integraci贸n de Swarm est谩 obsoleta y se eliminar谩 en una futura versi贸n. Por favor, considera usar la [integraci贸n de Kubernetes](integrations.md#kubernetes) en su lugar.

            **Puedes encontrar m谩s informaci贸n en la [documentaci贸n de la integraci贸n de Swarm](integrations.md#swarm).**

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los servicios de BunkerWeb y del programador:

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        ```

        Ten en cuenta que si tu servicio ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

=== "Protocolo Proxy"

    !!! warning "Lee con atenci贸n"

        Solo usa el protocolo PROXY si est谩s seguro de que tu balanceador de carga o proxy inverso lo est谩 enviando. **Si lo habilitas y no se est谩 usando, obtendr谩s errores**.

    Asumiremos lo siguiente con respecto a los balanceadores de carga o proxies inversos (necesitar谩s actualizar la configuraci贸n dependiendo de tu configuraci贸n):

    - Usan el `protocolo PROXY` v1 o v2 para establecer la IP real
    - Tienen IPs en las redes `1.2.3.0/24` y `100.64.0.0/10`

    === "Interfaz de usuario web"

        Navega a la p谩gina de **Configuraci贸n Global**, selecciona el plugin **Real IP** y completa las siguientes configuraciones:

        <figure markdown>![Configuraci贸n de IP real (protocolo PROXY) usando la interfaz de usuario web](assets/img/advanced-proxy2.png){ align=center }<figcaption>Configuraci贸n de IP real (protocolo PROXY) usando la interfaz de usuario web</figcaption></figure>

        Ten en cuenta que se recomienda reiniciar BunkerWeb cuando cambies la configuraci贸n relacionada con la IP real.

    === "Linux"

        Necesitar谩s agregar la configuraci贸n al archivo `/etc/bunkerweb/variables.env`:

        ```conf
        ...
        USE_REAL_IP=yes
        USE_PROXY_PROTOCOL=yes
        REAL_IP_FROM=1.2.3.0/24 100.64.0.0/16
        REAL_IP_HEADER=proxy_protocol
        ...
        ```

        Ten en cuenta que se recomienda emitir un reinicio en lugar de una recarga al configurar ajustes relacionados con los protocolos proxy:

        ```shell
        sudo systemctl restart bunkerweb && \
        sudo systemctl restart bunkerweb-scheduler
        ```

    === "Todo en uno"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno al ejecutar el contenedor Todo en uno:

        ```bash
        docker run -d \
            --name bunkerweb-aio \
            -v bw-storage:/data \
            -e USE_REAL_IP="yes" \
            -e USE_PROXY_PROTOCOL="yes" \
            -e REAL_IP_FROM="1.2.3.0/24 100.64.0.0/10" \
            -e REAL_IP_HEADER="X-Forwarded-For" \
            -p 80:8080/tcp \
            -p 443:8443/tcp \
            -p 443:8443/udp \
            bunkerity/bunkerweb-all-in-one:1.6.6
        ```

        Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

    === "Docker"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los contenedores de BunkerWeb y del programador:

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ```

        Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

    === "Docker autoconf"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los contenedores de BunkerWeb y del programador:

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ```

        Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

    === "Kubernetes"

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los pods de BunkerWeb y del programador.

        Aqu铆 est谩 la parte correspondiente de tu archivo `values.yaml` que puedes usar:

        ```yaml
        bunkerweb:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: USE_PROXY_PROTOCOL
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "proxy_protocol"
        scheduler:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: USE_PROXY_PROTOCOL
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "proxy_protocol"
        ```

    === "Swarm"

        !!! warning "Obsoleto"
            La integraci贸n de Swarm est谩 obsoleta y se eliminar谩 en una futura versi贸n. Por favor, considera usar la [integraci贸n de Kubernetes](integrations.md#kubernetes) en su lugar.

            **Puedes encontrar m谩s informaci贸n en la [documentaci贸n de la integraci贸n de Swarm](integrations.md#swarm).**

        Necesitar谩s agregar la configuraci贸n a las variables de entorno de los servicios de BunkerWeb y del programador.

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.6
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ```

        Ten en cuenta que si tu servicio ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se actualicen las nuevas variables de entorno.

## Alta disponibilidad y balanceo de carga

Para que tus aplicaciones sigan disponibles incluso si un servidor falla, puedes desplegar BunkerWeb en un cl煤ster de **Alta Disponibilidad (HA)**. Esta arquitectura incluye un **Manager** (Scheduler) que orquesta la configuraci贸n y varios **Workers** (instancias BunkerWeb) que manejan el tr谩fico.

```mermaid
flowchart LR

  %% ================ Styles =================
  classDef manager     fill:#eef2ff,stroke:#4c1d95,stroke-width:1px,rx:6px,ry:6px;
  classDef component     fill:#f9fafb,stroke:#6b7280,stroke-width:1px,rx:4px,ry:4px;
  classDef lb            fill:#e0f2fe,stroke:#0369a1,stroke-width:1px,rx:6px,ry:6px;
  classDef database fill:#d1fae5,stroke:#059669,stroke-width:1px,rx:4px,ry:4px;
  classDef datastore     fill:#fee2e2,stroke:#b91c1c,stroke-width:1px,rx:4px,ry:4px;
  classDef backend       fill:#ede9fe,stroke:#7c3aed,stroke-width:1px,rx:4px,ry:4px;
  classDef client        fill:#e5e7eb,stroke:#4b5563,stroke-width:1px,rx:4px,ry:4px;

  %% Container styles
  style CLUSTER fill:#f3f4f6,stroke:#d1d5db,stroke-width:1px,stroke-dasharray:6 3;
  style WORKERS fill:none,stroke:#9ca3af,stroke-width:1px,stroke-dasharray:4 2;

  %% ============== Outside left =============
  Client["Cliente"]:::client
  LB["Load Balancer"]:::lb

  %% ============== Cluster ==================
  subgraph CLUSTER[" "]
    direction TB

    %% ---- Top row: Manager + Redis ----
    subgraph TOP["Manager & Data Stores"]
      direction LR
      Manager["Manager<br/>(Scheduler)"]:::manager
      BDD["BDD"]:::database
      Redis["Redis/Valkey"]:::datastore
      UI["Interfaz Web"]:::manager
    end

    %% ---- Middle: Workers ----
    subgraph WORKERS["Workers (BunkerWeb)"]
      direction TB
      Worker1["Worker 1"]:::component
      WorkerN["Worker N"]:::component
    end

    %% ---- Bottom: App ----
    App["App"]:::backend
  end

  %% ============ Outside right ============
  Admin["Admin"]:::client

  %% ============ Traffic & control ===========
  %% Manager / control plane
  Manager -->|API 5000| Worker1
  Manager -->|API 5000| WorkerN
  Manager -->|bwcli| Redis
  Manager -->|Config| BDD

  %% User interface (UI)
  UI -->|Config| BDD
  UI -->|Reports / Bans| Redis
  BDD --- UI
  Redis --- UI
  linkStyle 6 stroke-width:0px;
  linkStyle 7 stroke-width:0px;

  %% Workers <-> Redis
  Worker1 -->|Cach茅 compartida| Redis
  WorkerN -->|Cach茅 compartida| Redis

  %% Workers -> App
  Worker1 -->|Tr谩fico leg铆timo| App
  WorkerN -->|Tr谩fico leg铆timo| App

  %% Client (right side) -> Load balancer -> Workers -> App
  Client -->|Petici贸n| LB
  LB -->|HTTP/TCP| Worker1
  LB -->|HTTP/TCP| WorkerN

  %% Admin -> UI
  UI --- Admin
  Admin -->|HTTP| UI
  linkStyle 15 stroke-width:0px;
```

!!! info "C贸mo funcionan las API de BunkerWeb"
    BunkerWeb maneja dos conceptos distintos de API:

    - Una **API interna** que conecta autom谩ticamente managers y workers para la orquestaci贸n. Siempre est谩 habilitada y no requiere configuraci贸n manual.
    - Un **servicio API** opcional (`bunkerweb-api`) que expone una interfaz REST p煤blica para herramientas de automatizaci贸n (bwcli, CI/CD, etc.). Est谩 deshabilitada por defecto en instalaciones Linux y es independiente de las comunicaciones internas managerworker.

### Requisitos previos

Antes de configurar un cl煤ster, aseg煤rate de contar con:

- **2 o m谩s hosts Linux** con acceso root/sudo.
- **Conectividad de red** entre los hosts (especialmente en el puerto TCP 5000 para la API interna).
- **IP o hostname** de la aplicaci贸n a proteger.
- *(Opcional)* **Load Balancer** (p. ej. HAProxy) para repartir el tr谩fico entre los workers.

### 1. Instalar el Manager

El Manager es el cerebro del cl煤ster. Ejecuta el Scheduler, la base de datos y, opcionalmente, la interfaz web.

!!! warning "Seguridad de la interfaz web"
    La interfaz web escucha en un puerto dedicado (7000 por defecto) y solo deber铆a ser accesible por administradores. Si piensas exponerla a internet, **recomendamos encarecidamente** protegerla con una instancia de BunkerWeb delante.

=== "Linux"

    1. **Descarga y ejecuta el instalador** en el host del manager:

        ```bash
        # Descargar script y checksum
        curl -fsSL -O https://github.com/bunkerity/bunkerweb/releases/download/v1.6.6/install-bunkerweb.sh
        curl -fsSL -O https://github.com/bunkerity/bunkerweb/releases/download/v1.6.6/install-bunkerweb.sh.sha256

        # Verificar checksum
        sha256sum -c install-bunkerweb.sh.sha256

        # Ejecutar instalador
        chmod +x install-bunkerweb.sh
        sudo ./install-bunkerweb.sh
        ```

        !!! danger "Aviso de seguridad"
            Comprueba siempre la integridad del script con el checksum proporcionado antes de ejecutarlo.

    2. **Selecciona la opci贸n 2) Manager** y sigue las indicaciones:

        | Pregunta                    | Acci贸n                                                                                           |
        | :------------------------- | :------------------------------------------------------------------------------------------------ |
        | **Instancias BunkerWeb**   | Introduce las IP de tus nodos worker separadas por espacios (ej.: `192.168.10.11 192.168.10.12`). |
        | **Whitelist IP**           | Acepta la IP detectada o introduce un subnet (ej.: `192.168.10.0/24`) para permitir el acceso a la API. |
        | **Resolutores DNS**        | Pulsa `N` para usar el valor por defecto o indica los tuyos.                                      |
        | **HTTPS para la API interna** | **Recomendado:** `Y` para generar certificados y asegurar la comunicaci贸n manager-worker.        |
        | **Servicio Web UI**        | `Y` para activar la interfaz web (muy recomendado).                                              |
        | **Servicio API**           | `N` salvo que necesites la API REST p煤blica para herramientas externas.                           |

    #### Asegurar y exponer la UI

    Si activaste la interfaz web, debes asegurarla. Puedes alojarla en el Manager o en una m谩quina separada.

    === "Alojada en el Manager"

        1. Edita `/etc/bunkerweb/ui.env` y define credenciales fuertes:

        ```ini
        # OVERRIDE_ADMIN_CREDS=no
        ADMIN_USERNAME=admin
        ADMIN_PASSWORD=changeme
        # FLASK_SECRET=changeme
        # TOTP_ENCRYPTION_KEYS=changeme
        LISTEN_ADDR=0.0.0.0
        # LISTEN_PORT=7000
        FORWARDED_ALLOW_IPS=127.0.0.1
        # ENABLE_HEALTHCHECK=no
        ```

        !!! warning "Cambia las credenciales por defecto"
            Sustituye `admin` y `changeme` por credenciales robustas antes de arrancar el servicio UI en producci贸n.

        2. Reinicia la UI:

        ```bash
        sudo systemctl restart bunkerweb-ui
        ```

    === "Host externo"

        Para m谩s aislamiento, instala la UI en un nodo independiente.

        1. Ejecuta el instalador y elige **Opci贸n 5) Web UI Only**.
        2. Edita `/etc/bunkerweb/ui.env` para apuntar a la base de datos del Manager:

            ```ini
            # Configuraci贸n de base de datos (debe coincidir con la del Manager)
            DATABASE_URI=mariadb+pymysql://bunkerweb:changeme@db-host:3306/bunkerweb
            # Para PostgreSQL: postgresql://bunkerweb:changeme@db-host:5432/bunkerweb
            # Para MySQL: mysql+pymysql://bunkerweb:changeme@db-host:3306/bunkerweb

            # Configuraci贸n de Redis (si usas Redis/Valkey para persistencia)
            # Si no se proporciona, se toma autom谩ticamente de la base de datos
            # REDIS_HOST=redis-host

            # Credenciales de seguridad
            ADMIN_USERNAME=admin
            ADMIN_PASSWORD=changeme

            # Ajustes de red
            LISTEN_ADDR=0.0.0.0
            # LISTEN_PORT=7000
            ```

        3. Reinicia el servicio:

            ```bash
            sudo systemctl restart bunkerweb-ui
            ```

        !!! tip "Configuraci贸n de firewall"
            Aseg煤rate de que el host de la UI pueda llegar a los puertos de base de datos y Redis. Puede que debas ajustar las reglas de firewall tanto en el host de la UI como en los hosts de la base/Redis.

=== "Docker"

    Crea un archivo `docker-compose.yml` en el host del manager:

    ```yaml title="docker-compose.yml"
    x-ui-env: &bw-ui-env
      # Anclamos las variables de entorno para evitar duplicaciones
      DATABASE_URI: \"mariadb+pymysql://bunkerweb:changeme@bw-db:3306/db\" # Usa una contrase帽a m谩s fuerte

    services:
      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.6
        environment:
          <<: *bw-ui-env
          BUNKERWEB_INSTANCES: \"192.168.1.11 192.168.1.12\" # Sustituye por las IP de tus workers
          API_WHITELIST_IP: \"127.0.0.0/8 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16\" # Permitir redes locales
          # API_LISTEN_HTTPS: \"yes\" # Recomendado para asegurar la API interna
          # API_TOKEN: \"my_secure_token\" # Opcional: token adicional
          SERVER_NAME: \"\"
          MULTISITE: \"yes\"
          USE_REDIS: \"yes\"
          REDIS_HOST: \"redis\"
        volumes:
          - bw-storage:/data # Persistencia del cach茅 y backups
        restart: \"unless-stopped\"
        networks:
          - bw-db
          - bw-redis

      bw-ui:
        image: bunkerity/bunkerweb-ui:1.6.6
        ports:
          - \"7000:7000\" # Exponer el puerto de la UI
        environment:
          <<: *bw-ui-env
          ADMIN_USERNAME: \"changeme\"
          ADMIN_PASSWORD: \"changeme\" # Usa una contrase帽a m谩s fuerte
          TOTP_ENCRYPTION_KEYS: \"mysecret\" # Usa una clave m谩s fuerte (ver requisitos previos)
        restart: \"unless-stopped\"
        networks:
          - bw-db
          - bw-redis

      bw-db:
        image: mariadb:11
        # Establecemos el tama帽o m谩ximo de paquete para evitar problemas con consultas grandes
        command: --max-allowed-packet=67108864
        environment:
          MYSQL_RANDOM_ROOT_PASSWORD: \"yes\"
          MYSQL_DATABASE: \"db\"
          MYSQL_USER: \"bunkerweb\"
          MYSQL_PASSWORD: \"changeme\" # Usa una contrase帽a m谩s fuerte
        volumes:
          - bw-data:/var/lib/mysql
        restart: \"unless-stopped\"
        networks:
          - bw-db

      redis: # Redis para la persistencia de informes/prohibiciones/estad铆sticas
        image: redis:7-alpine
        command: >
          redis-server
          --maxmemory 256mb
          --maxmemory-policy allkeys-lru
          --save 60 1000
          --appendonly yes
        volumes:
          - redis-data:/data
        restart: \"unless-stopped\"
        networks:
          - bw-redis

    volumes:
      bw-data:
      bw-storage:
      redis-data:

    networks:
      bw-db:
        name: bw-db
      bw-redis:
        name: bw-redis
    ```

    Arranca el stack del manager:

    ```bash
    docker compose up -d
    ```

### 2. Instalar los Workers

Los workers son los nodos que procesan el tr谩fico entrante.

=== "Linux"

    1. **Ejecuta el instalador** en cada nodo worker (mismos comandos que para el Manager).
    2. **Selecciona la opci贸n 3) Worker** y configura:

        | Pregunta                    | Acci贸n                                                    |
        | :------------------------- | :-------------------------------------------------------- |
        | **IP del Manager**         | Introduce la IP de tu Manager (ej.: `192.168.10.10`).     |
        | **HTTPS para la API interna** | Debe coincidir con el ajuste del Manager (`Y` o `N`).     |

    El worker se registrar谩 autom谩ticamente en el Manager.

=== "Docker"

    Crea un archivo `docker-compose.yml` en cada worker:

    ```yaml title="docker-compose.yml"
    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        ports:
          - \"80:8080/tcp\"
          - \"443:8443/tcp\"
          - \"443:8443/udp\" # Compatibilidad QUIC / HTTP3
          - \"5000:5000/tcp\" # Puerto de la API interna
        environment:
          API_WHITELIST_IP: \"127.0.0.0/8 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16\"
          # API_LISTEN_HTTPS: \"yes\" # Recomendado para asegurar la API interna (debe coincidir con el Manager)
          # API_TOKEN: \"my_secure_token\" # Opcional: token adicional (debe coincidir con el Manager)
        restart: \"unless-stopped\"
    ```

    Inicia el worker:

    ```bash
    docker compose up -d
    ```

### 3. Gestionar los Workers

Puedes a帽adir m谩s workers m谩s adelante usando la interfaz web o la CLI.

=== "V铆a interfaz web"

    1. **Ve a la pesta帽a Instances**.
    2. **Haz clic en Add instance**.
    3. **Introduce la IP/hostname del worker** y guarda.

    <div class=\"grid grid-2\" markdown style=\"display:grid; align-items:center;\">
    <figure markdown style=\"display:flex; flex-direction:column; justify-content:center; align-items:center; height:100%;\">
      ![BunkerWeb UI - Crear instancia](assets/img/ui-ha-create-instance.webp){ width=\"100%\" }
      <figcaption>BunkerWeb UI - Crear instancia</figcaption>
    </figure>
    <figure markdown style=\"display:flex; flex-direction:column; justify-content:center; align-items:center; height:100%;\">
      ![BunkerWeb UI - Formulario de instancia](assets/img/ui-ha-create-instance-form.webp){ width=\"100%\" }
      <figcaption>BunkerWeb UI - Formulario de instancia</figcaption>
    </figure>
    </div>

=== \"V铆a configuraci贸n\"

    === \"Linux\"

        1. **Edita** `/etc/bunkerweb/variables.env` en el Manager:

            ```bash
            BUNKERWEB_INSTANCES=192.168.10.11 192.168.10.12 192.168.10.13
            ```

        2. **Reinicia el Scheduler**:

            ```bash
            sudo systemctl restart bunkerweb-scheduler
            ```

    === \"Docker\"

        1. **Edita** el archivo `docker-compose.yml` en el Manager para actualizar `BUNKERWEB_INSTANCES`.

        2. **Recrea el contenedor del Scheduler**:

            ```bash
            docker compose up -d bw-scheduler
            ```

### 4. Verificar la instalaci贸n

=== "Linux"

    1. **Comprobar estado**: accede a la UI (`http://<ip-manager>:7000`) y abre la pesta帽a **Instances**. Todos los workers deben aparecer **Up**.
    2. **Probar conmutaci贸n**: det茅n BunkerWeb en un worker (`sudo systemctl stop bunkerweb`) y verifica que el tr谩fico sigue fluyendo.

=== "Docker"

    1. **Comprobar estado**: accede a la UI (`http://<ip-manager>:7000`) y abre la pesta帽a **Instances**. Todos los workers deben aparecer **Up**.
    2. **Probar conmutaci贸n**: det茅n BunkerWeb en un worker (`docker compose stop bunkerweb`) y verifica que el tr谩fico sigue fluyendo.

### 5. Balanceo de carga

Para repartir el tr谩fico entre tus workers, utiliza un Load Balancer. Recomendamos uno de capa 4 (TCP) que soporte **PROXY protocol** para preservar la IP del cliente.

=== "HAProxy - Capa 4 (TCP)"

    Ejemplo de configuraci贸n **HAProxy** que pasa el tr谩fico (modo TCP) manteniendo la IP cliente mediante **PROXY protocol**.

    ```cfg title=\"haproxy.cfg\"
    defaults
        timeout connect 5s
        timeout client 5s
        timeout server 5s

    frontend http_front
        mode tcp
        bind *:80
        default_backend http_back

    frontend https_front
        mode tcp
        bind *:443
        default_backend https_back

    backend http_back
        mode tcp
        balance roundrobin
        server worker01 192.168.10.11:80 check send-proxy-v2
        server worker02 192.168.10.12:80 check send-proxy-v2

    backend https_back
        mode tcp
        balance roundrobin
        server worker01 192.168.10.11:443 check send-proxy-v2
        server worker02 192.168.10.12:443 check send-proxy-v2
    ```

=== "HAProxy - Capa 7 (HTTP)"

    Ejemplo de configuraci贸n **HAProxy** para balanceo en capa 7 (HTTP). A帽ade la cabecera `X-Forwarded-For` para que BunkerWeb obtenga la IP del cliente.

    ```cfg title=\"haproxy.cfg\"
    defaults
        timeout connect 5s
        timeout client 5s
        timeout server 5s

    frontend http_front
        mode http
        bind *:80
        default_backend http_back

    frontend https_front
        mode http
        bind *:443
        default_backend https_back

    backend http_back
        mode http
        balance roundrobin
        option forwardfor
        server worker01 192.168.10.11:80 check
        server worker02 192.168.10.12:80 check

    backend https_back
        mode http
        balance roundrobin
        option forwardfor
        server worker01 192.168.10.11:443 check
        server worker02 192.168.10.12:443 check
    ```

Reinicia HAProxy una vez guardada la configuraci贸n:

```bash
sudo systemctl restart haproxy
```

Para m谩s informaci贸n, consulta la [documentaci贸n oficial de HAProxy](http://docs.haproxy.org/).

!!! tip "Configurar IP real"
    No olvides configurar BunkerWeb para recibir la IP real del cliente (usando PROXY protocol o la cabecera X-Forwarded-For).

    Consulta la secci贸n [Detr谩s de un balanceador de carga o proxy inverso](#behind-load-balancer-or-reverse-proxy) para asegurarte de que recibes la IP correcta del cliente.

    Revisa `/var/log/bunkerweb/access.log` en cada worker para confirmar que las solicitudes llegan desde la red del PROXY protocol y que los dos workers comparten la carga. Tu cl煤ster BunkerWeb ya est谩 listo para proteger cargas de producci贸n con alta disponibilidad.

## Usando mecanismos de resoluci贸n DNS personalizados

La configuraci贸n de NGINX de BunkerWeb se puede personalizar para usar diferentes resolutores de DNS seg煤n tus necesidades. Esto puede ser particularmente 煤til en varios escenarios:

1. Para respetar las entradas en tu archivo local `/etc/hosts`
2. Cuando necesitas usar servidores DNS personalizados para ciertos dominios
3. Para integrarse con soluciones locales de cach茅 de DNS

### Usando systemd-resolved

Muchos sistemas Linux modernos usan `systemd-resolved` para la resoluci贸n de DNS. Si quieres que BunkerWeb respete el contenido de tu archivo `/etc/hosts` y use el mecanismo de resoluci贸n de DNS del sistema, puedes configurarlo para que use el servicio DNS local de systemd-resolved.

Para verificar que systemd-resolved se est谩 ejecutando en tu sistema, puedes usar:

```bash
systemctl status systemd-resolved
```

Para habilitar systemd-resolved como tu resolutor de DNS en BunkerWeb, establece la configuraci贸n `DNS_RESOLVERS` a `127.0.0.53`, que es la direcci贸n de escucha predeterminada para systemd-resolved:

=== "Interfaz de usuario web"

    Navega a la p谩gina de **Configuraci贸n Global** y establece los resolutores de DNS en `127.0.0.53`

    <figure markdown>![Configuraci贸n de resolutores de DNS usando la interfaz de usuario web](assets/img/advanced-dns-resolvers.png){ align=center }<figcaption>Configuraci贸n de resolutores de DNS usando la interfaz de usuario web</figcaption></figure>

=== "Linux"

    Necesitar谩s modificar el archivo `/etc/bunkerweb/variables.env`:

    ```conf
    ...
    DNS_RESOLVERS=127.0.0.53
    ...
    ```

    Despu茅s de hacer este cambio, recarga el Programador para aplicar la configuraci贸n:

    ```shell
    sudo systemctl reload bunkerweb-scheduler
    ```

### Usando dnsmasq

[dnsmasq](http://www.thekelleys.org.uk/dnsmasq/doc.html) es un servidor ligero de DNS, DHCP y TFTP que se usa com煤nmente para el almacenamiento en cach茅 y la personalizaci贸n de DNS local. Es particularmente 煤til cuando necesitas m谩s control sobre tu resoluci贸n de DNS del que proporciona systemd-resolved.

=== "Linux"

    Primero, instala y configura dnsmasq en tu sistema Linux:

    === "Debian/Ubuntu"

        ```bash
        # Instalar dnsmasq
        sudo apt-get update && sudo apt-get install dnsmasq

        # Configurar dnsmasq para escuchar solo en localhost
        echo "listen-address=127.0.0.1" | sudo tee -a /etc/dnsmasq.conf
        echo "bind-interfaces" | sudo tee -a /etc/dnsmasq.conf

        # Agregar entradas DNS personalizadas si es necesario
        echo "address=/custom.example.com/192.168.1.10" | sudo tee -a /etc/dnsmasq.conf

        # Reiniciar dnsmasq
        sudo systemctl restart dnsmasq
        sudo systemctl enable dnsmasq
        ```

    === "RHEL/Fedora"

        ```bash
        # Instalar dnsmasq
        sudo dnf install dnsmasq

        # Configurar dnsmasq para escuchar solo en localhost
        echo "listen-address=127.0.0.1" | sudo tee -a /etc/dnsmasq.conf
        echo "bind-interfaces" | sudo tee -a /etc/dnsmasq.conf

        # Agregar entradas DNS personalizadas si es necesario
        echo "address=/custom.example.com/192.168.1.10" | sudo tee -a /etc/dnsmasq.conf

        # Reiniciar dnsmasq
        sudo systemctl restart dnsmasq
        sudo systemctl enable dnsmasq
        ```

    Luego configura BunkerWeb para que use dnsmasq estableciendo `DNS_RESOLVERS` en `127.0.0.1`:

    === "Interfaz de usuario web"

        Navega a la p谩gina de **Configuraci贸n Global**, selecciona el plugin **NGINX** y establece los resolutores de DNS en `127.0.0.1`.

        <figure markdown>![Configuraci贸n de resolutores de DNS usando la interfaz de usuario web](assets/img/advanced-dns-resolvers2.png){ align=center }<figcaption>Configuraci贸n de resolutores de DNS usando la interfaz de usuario web</figcaption></figure>

    === "Linux"

        Necesitar谩s modificar el archivo `/etc/bunkerweb/variables.env`:

        ```conf
        ...
        DNS_RESOLVERS=127.0.0.1
        ...
        ```

        Despu茅s de hacer este cambio, recarga el Programador:

        ```shell
        sudo systemctl reload bunkerweb-scheduler
        ```

=== "Todo en uno"

    Cuando uses el contenedor Todo en uno, ejecuta dnsmasq en un contenedor separado y configura BunkerWeb para usarlo:

    ```bash
    # Crear una red personalizada para la comunicaci贸n DNS
    docker network create bw-dns

    # Ejecutar el contenedor dnsmasq usando dockurr/dnsmasq con Quad9 DNS
    # Quad9 proporciona resoluci贸n de DNS centrada en la seguridad con bloqueo de malware
    docker run -d \
        --name dnsmasq \
        --network bw-dns \
        -e DNS1="9.9.9.9" \
        -e DNS2="149.112.112.112" \
        -p 53:53/udp \
        -p 53:53/tcp \
        --cap-add=NET_ADMIN \
        --restart=always \
        dockurr/dnsmasq

    # Ejecutar BunkerWeb Todo en uno con el resolutor de DNS dnsmasq
    docker run -d \
        --name bunkerweb-aio \
        --network bw-dns \
        -v bw-storage:/data \
        -e DNS_RESOLVERS="dnsmasq" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        bunkerity/bunkerweb-all-in-one:1.6.6
    ```

=== "Docker"

    Agrega un servicio dnsmasq a tu archivo docker-compose y configura BunkerWeb para usarlo:

    ```yaml
    services:
      dnsmasq:
        image: dockurr/dnsmasq
        container_name: dnsmasq
        environment:
          # Usando los servidores DNS de Quad9 para mayor seguridad y privacidad
          # Primario: 9.9.9.9 (Quad9 con bloqueo de malware)
          # Secundario: 149.112.112.112 (Servidor de respaldo de Quad9)
          DNS1: "9.9.9.9"
          DNS2: "149.112.112.112"
        ports:
          - 53:53/udp
          - 53:53/tcp
        cap_add:
          - NET_ADMIN
        restart: always
        networks:
          - bw-dns

      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        ...
        environment:
          DNS_RESOLVERS: "dnsmasq"
        ...
        networks:
          - bw-universe
          - bw-services
          - bw-dns

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.6
        ...
        environment:
          DNS_RESOLVERS: "dnsmasq"
        ...
        networks:
          - bw-universe
          - bw-dns

    networks:
      # ...redes existentes...
      bw-dns:
        name: bw-dns
    ```

## Configuraciones personalizadas {#custom-configurations}

Para personalizar y a帽adir configuraciones personalizadas a BunkerWeb, puedes aprovechar su base NGINX. Las configuraciones personalizadas de NGINX se pueden a帽adir en diferentes contextos de NGINX, incluidas las configuraciones para el Firewall de Aplicaciones Web (WAF) ModSecurity, que es un componente central de BunkerWeb. Se pueden encontrar m谩s detalles sobre las configuraciones de ModSecurity [aqu铆](features.md#custom-configurations).

Estos son los tipos de configuraciones personalizadas disponibles:

- **http**: Configuraciones a nivel HTTP de NGINX.
- **server-http**: Configuraciones a nivel HTTP/Servidor de NGINX.
- **default-server-http**: Configuraciones a nivel de Servidor de NGINX, espec铆ficamente para el "servidor predeterminado" cuando el nombre del cliente proporcionado no coincide con ning煤n nombre de servidor en `SERVER_NAME`.
- **modsec-crs**: Configuraciones aplicadas antes de que se cargue el Core Rule Set de OWASP.
- **modsec**: Configuraciones aplicadas despu茅s de que se cargue el Core Rule Set de OWASP, o se utilizan cuando el Core Rule Set no est谩 cargado.
- **crs-plugins-before**: Configuraciones para los plugins CRS, aplicadas antes de que se carguen los plugins CRS.
- **crs-plugins-after**: Configuraciones para los plugins CRS, aplicadas despu茅s de que se carguen los plugins CRS.
- **stream**: Configuraciones a nivel de Stream de NGINX.
- **server-stream**: Configuraciones a nivel de Stream/Servidor de NGINX.

Las configuraciones personalizadas se pueden aplicar globalmente o espec铆ficamente para un servidor en particular, dependiendo del contexto aplicable y de si el [modo multisitio](features.md#multisite-mode) est谩 habilitado.

El m茅todo para aplicar configuraciones personalizadas depende de la integraci贸n que se est茅 utilizando. Sin embargo, el proceso subyacente implica a帽adir archivos con el sufijo `.conf` a carpetas espec铆ficas. Para aplicar una configuraci贸n personalizada para un servidor espec铆fico, el archivo debe colocarse en una subcarpeta con el nombre del servidor principal.

Algunas integraciones proporcionan formas m谩s convenientes de aplicar configuraciones, como el uso de [Configs](https://docs.docker.com/engine/swarm/configs/) en Docker Swarm o [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) en Kubernetes. Estas opciones ofrecen enfoques m谩s sencillos para gestionar y aplicar configuraciones.

=== "Interfaz de usuario web"

    Navega a la p谩gina de **Configuraciones**, haz clic en **Crear nueva configuraci贸n personalizada**, luego puedes elegir si es global o espec铆fica para un servicio, el tipo de configuraci贸n y el nombre de la configuraci贸n:

    <figure markdown>![Configuraciones personalizadas usando la interfaz de usuario web](assets/img/advanced-config.png){ align=center }<figcaption>Configuraciones personalizadas usando la interfaz de usuario web</figcaption></figure>

    No olvides hacer clic en el bot贸n ` Guardar`.

=== "Linux"

    Cuando se utiliza la [integraci贸n de Linux](integrations.md#linux), las configuraciones personalizadas deben escribirse en la carpeta `/etc/bunkerweb/configs`.

    Aqu铆 hay un ejemplo para server-http/hello-world.conf:

    ```nginx
    location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }
    ```

    Debido a que BunkerWeb se ejecuta como un usuario sin privilegios (nginx:nginx), necesitar谩s editar los permisos:

    ```shell
    chown -R root:nginx /etc/bunkerweb/configs && \
    chmod -R 770 /etc/bunkerweb/configs
    ```

    Ahora verifiquemos el estado del Programador:

    ```shell
    systemctl status bunkerweb-scheduler
    ```

    Si ya se est谩 ejecutando, podemos recargarlo:

    ```shell
    systemctl reload bunkerweb-scheduler
    ```

    De lo contrario, tendremos que iniciarlo:

    ```shell
    systemctl start bunkerweb-scheduler
    ```

=== "Todo en uno"

    Cuando se utiliza la [imagen Todo en uno](integrations.md#all-in-one-aio-image), tienes dos opciones para a帽adir configuraciones personalizadas:

    - Usar configuraciones espec铆ficas `*_CUSTOM_CONF_*` como variables de entorno al ejecutar el contenedor (recomendado).
    - Escribir archivos `.conf` en el directorio `/data/configs/` dentro del volumen montado en `/data`.

    **Usando configuraciones (Variables de Entorno)**

    Las configuraciones a usar deben seguir el patr贸n `<SITE>_CUSTOM_CONF_<TYPE>_<NAME>`:

    - `<SITE>` : Nombre del servidor principal opcional si el modo multisitio est谩 habilitado y la configuraci贸n debe aplicarse a un servicio espec铆fico.
    - `<TYPE>` : El tipo de configuraci贸n, los valores aceptados son `HTTP`, `DEFAULT_SERVER_HTTP`, `SERVER_HTTP`, `MODSEC`, `MODSEC_CRS`, `CRS_PLUGINS_BEFORE`, `CRS_PLUGINS_AFTER`, `STREAM` y `SERVER_STREAM`.
    - `<NAME>` : El nombre de la configuraci贸n sin el sufijo `.conf`.

    Aqu铆 hay un ejemplo de prueba al ejecutar el contenedor Todo en uno:

    ```bash
    docker run -d \
        --name bunkerweb-aio \
        -v bw-storage:/data \
        -e "CUSTOM_CONF_SERVER_HTTP_hello-world=location /hello { \
            default_type 'text/plain'; \
            content_by_lua_block { \
              ngx.say('world'); \
            } \
          }" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        bunkerity/bunkerweb-all-in-one:1.6.6
    ```

    Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se apliquen las nuevas variables de entorno.

    **Usando archivos**

    Lo primero que hay que hacer es crear las carpetas:

    ```shell
    mkdir -p ./bw-data/configs/server-http
    ```

    Ahora puedes escribir tus configuraciones:

    ```nginx
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" > ./bw-data/configs/server-http/hello-world.conf
    ```

    Debido a que el programador se ejecuta como un usuario sin privilegios con UID y GID 101, necesitar谩s editar los permisos:

    ```shell
    chown -R root:101 bw-data && \
    chmod -R 770 bw-data
    ```

    Al iniciar el contenedor del programador, necesitar谩s montar la carpeta en /data:

    ```bash
    docker run -d \
        --name bunkerweb-aio \
        -v ./bw-data:/data \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        bunkerity/bunkerweb-all-in-one:1.6.6
    ```

=== "Docker"

    Cuando se utiliza la [integraci贸n de Docker](integrations.md#docker), tienes dos opciones para a帽adir configuraciones personalizadas:

    - Usar configuraciones espec铆ficas `*_CUSTOM_CONF_*` como variables de entorno (recomendado)
    - Escribir archivos .conf en el volumen montado en /data del programador

    **Usando configuraciones**

    Las configuraciones a usar deben seguir el patr贸n `<SITE>_CUSTOM_CONF_<TYPE>_<NAME>`:

    - `<SITE>`: nombre del servidor principal opcional si el modo multisitio est谩 habilitado y la configuraci贸n debe aplicarse a un servicio espec铆fico
    - `<TYPE>`: el tipo de configuraci贸n, los valores aceptados son `HTTP`, `DEFAULT_SERVER_HTTP`, `SERVER_HTTP`, `MODSEC`, `MODSEC_CRS`, `CRS_PLUGINS_BEFORE`, `CRS_PLUGINS_AFTER`, `STREAM` y `SERVER_STREAM`
    - `<NAME>`: el nombre de la configuraci贸n sin el sufijo .conf

    Aqu铆 hay un ejemplo de prueba usando un archivo docker-compose:

    ```yaml
    ...
    bw-scheduler:
      image: bunkerity/bunkerweb-scheduler:1.6.6
      environment:
        - |
          CUSTOM_CONF_SERVER_HTTP_hello-world=
          location /hello {
            default_type 'text/plain';
            content_by_lua_block {
              ngx.say('world')
            }
          }
      ...
    ```

    **Usando archivos**

    Lo primero que hay que hacer es crear las carpetas:

    ```shell
    mkdir -p ./bw-data/configs/server-http
    ```

    Ahora puedes escribir tus configuraciones:

    ```nginx
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" > ./bw-data/configs/server-http/hello-world.conf
    ```

    Debido a que el programador se ejecuta como un usuario sin privilegios con UID y GID 101, necesitar谩s editar los permisos:

    ```shell
    chown -R root:101 bw-data && \
    chmod -R 770 bw-data
    ```

    Al iniciar el contenedor del programador, necesitar谩s montar la carpeta en /data:

    ```yaml
    bw-scheduler:
      image: bunkerity/bunkerweb-scheduler:1.6.6
      volumes:
        - ./bw-data:/data
      ...
    ```

=== "Docker autoconf"

    Cuando se utiliza la [integraci贸n de autoconfiguraci贸n de Docker](integrations.md#docker-autoconf), tienes dos opciones para a帽adir configuraciones personalizadas:

    - Usar configuraciones espec铆ficas `*_CUSTOM_CONF_*` como etiquetas (m谩s f谩cil)
    - Escribir archivos .conf en el volumen montado en /data del programador

    **Usando etiquetas**

    !!! warning "Limitaciones al usar etiquetas"
        Cuando usas etiquetas con la integraci贸n de autoconfiguraci贸n de Docker, solo puedes aplicar configuraciones personalizadas para el servicio web correspondiente. No es posible aplicar configuraciones **http**, **default-server-http**, **stream** o cualquier configuraci贸n global (como **server-http** o **server-stream** para todos los servicios): necesitar谩s montar archivos para ese prop贸sito.

    Las etiquetas a usar deben seguir el patr贸n `bunkerweb.CUSTOM_CONF_<TYPE>_<NAME>`:

    - `<TYPE>`: el tipo de configuraci贸n, los valores aceptados son `SERVER_HTTP`, `MODSEC`, `MODSEC_CRS`, `CRS_PLUGINS_BEFORE`, `CRS_PLUGINS_AFTER` y `SERVER_STREAM`
    - `<NAME>`: el nombre de la configuraci贸n sin el sufijo .conf

    Aqu铆 hay un ejemplo de prueba usando un archivo docker-compose:

    ```yaml
    myapp:
      image: nginxdemos/nginx-hello
      labels:
        - |
          bunkerweb.CUSTOM_CONF_SERVER_HTTP_hello-world=
          location /hello {
            default_type 'text/plain';
            content_by_lua_block {
                ngx.say('world')
            }
          }
      ...
    ```

    **Usando archivos**

    Lo primero que hay que hacer es crear las carpetas:

    ```shell
    mkdir -p ./bw-data/configs/server-http
    ```

    Ahora puedes escribir tus configuraciones:

    ```nginx
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" > ./bw-data/configs/server-http/hello-world.conf
    ```

    Debido a que el programador se ejecuta como un usuario sin privilegios con UID y GID 101, necesitar谩s editar los permisos:

    ```shell
    chown -R root:101 bw-data && \
    chmod -R 770 bw-data
    ```

    Al iniciar el contenedor del programador, necesitar谩s montar la carpeta en /data:

    ```yaml
    bw-scheduler:
      image: bunkerity/bunkerweb-scheduler:1.6.6
      volumes:
        - ./bw-data:/data
      ...
    ```

=== "Kubernetes"

    Cuando se utiliza la [integraci贸n de Kubernetes](integrations.md#kubernetes),
    las configuraciones personalizadas se gestionan mediante [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/).

    No es necesario montar la ConfigMap en un Pod (por ejemplo, como variable de entorno o volumen).
    El pod de autoconfiguraci贸n escucha los eventos de ConfigMap y aplica los cambios en cuanto se detectan.

    Anota cada ConfigMap que deba gestionar el controlador de Ingress:

    - `bunkerweb.io/CONFIG_TYPE`: obligatorio. Elige uno de los tipos compatibles (`http`, `server-http`, `default-server-http`, `modsec`,
      `modsec-crs`, `crs-plugins-before`, `crs-plugins-after`, `stream`, `server-stream` o `settings`).
    - `bunkerweb.io/CONFIG_SITE`: opcional. Establece el nombre del servidor principal (tal como se publica a trav茅s del `Ingress`)
      para limitar la configuraci贸n a ese servicio; d茅jalo vac铆o para aplicarla globalmente.

    Aqu铆 est谩 el ejemplo:

    ```yaml
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: cfg-bunkerweb-all-server-http
      annotations:
        bunkerweb.io/CONFIG_TYPE: "server-http"
    data:
      myconf: |
      location /hello {
        default_type 'text/plain';
        content_by_lua_block {
          ngx.say('world')
        }
      }
    ```

    !!! info "C贸mo funciona la reconciliaci贸n"
        - El controlador de Ingress vigila continuamente las ConfigMap anotadas.
        - Si la variable de entorno `NAMESPACES` est谩 definida, solo se tienen en cuenta las ConfigMap de esos espacios de nombres.
        - Crear o actualizar una ConfigMap gestionada provoca la recarga inmediata de la configuraci贸n.
        - Eliminar la ConfigMap, o quitar la anotaci贸n `bunkerweb.io/CONFIG_TYPE`, elimina la configuraci贸n personalizada asociada.
        - Si defines `bunkerweb.io/CONFIG_SITE`, el servicio referenciado debe existir previamente;
          de lo contrario, la ConfigMap se ignora hasta que aparezca el servicio.

    !!! tip "Configuraci贸n extra personalizada"
        Desde la versi贸n `1.6.0`, puedes a帽adir o sobrescribir par谩metros anotando una ConfigMap con `bunkerweb.io/CONFIG_TYPE=settings`.
        El controlador de Ingress de autoconf lee cada entrada de `data` y la aplica como si fuera una variable de entorno:

        - Sin `bunkerweb.io/CONFIG_SITE`, todas las claves se aplican globalmente.
        - Cuando `bunkerweb.io/CONFIG_SITE` est谩 definido, el controlador a帽ade autom谩ticamente el prefijo `<nombre-del-servidor>_` (cada `/` se sustituye por `_`) a las claves que a煤n no est谩n acotadas. A帽ade el prefijo manualmente si necesitas mezclar claves globales y espec铆ficas en la misma ConfigMap.
        - Los nombres o valores no v谩lidos se omiten y el controlador autoconf registra una advertencia.

        Aqu铆 hay un ejemplo:

        ```yaml
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: cfg-bunkerweb-extra-settings
          annotations:
            bunkerweb.io/CONFIG_TYPE: "settings"
        data:
          USE_ANTIBOT: "captcha" # configuraci贸n multisitio que se aplicar谩 a todos los servicios que no la sobrescriban
          USE_REDIS: "yes" # configuraci贸n global que se aplicar谩 globalmente
          ...
        ```

=== "Swarm"

    !!! warning "Obsoleto"
        La integraci贸n de Swarm est谩 obsoleta y se eliminar谩 en una futura versi贸n. Por favor, considera usar la [integraci贸n de Kubernetes](integrations.md#kubernetes) en su lugar.

        **Puedes encontrar m谩s informaci贸n en la [documentaci贸n de la integraci贸n de Swarm](integrations.md#swarm).**

    Cuando se utiliza la [integraci贸n de Swarm](integrations.md#swarm), las configuraciones personalizadas se gestionan mediante [Docker Configs](https://docs.docker.com/engine/swarm/configs/).

    Para mantenerlo simple, ni siquiera necesitas adjuntar la Configuraci贸n a un servicio: el servicio de autoconfiguraci贸n est谩 escuchando los eventos de Configuraci贸n y actualizar谩 las configuraciones personalizadas cuando sea necesario.

    Al crear una Configuraci贸n, necesitar谩s a帽adir etiquetas especiales:

    *   **bunkerweb.CONFIG_TYPE**: debe establecerse a un tipo de configuraci贸n personalizada v谩lido (http, server-http, default-server-http, modsec, modsec-crs, crs-plugins-before, crs-plugins-after, stream, server-stream o settings)
    *   **bunkerweb.CONFIG_SITE**: establece un nombre de servidor para aplicar la configuraci贸n a ese servidor espec铆fico (opcional, se aplicar谩 globalmente si no se establece)

    Aqu铆 est谩 el ejemplo:

    ```nginx
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" | docker config create -l bunkerweb.CONFIG_TYPE=server-http my-config -
    ```

    No hay mecanismo de actualizaci贸n: la alternativa es eliminar una configuraci贸n existente usando `docker config rm` y luego recrearla.

## Ejecutando muchos servicios en producci贸n {#running-many-services-in-production}

### CRS Global

!!! warning "Plugins CRS"
    Cuando el CRS se carga globalmente, **los plugins CRS no son compatibles**. Si necesitas usarlos, tendr谩s que cargar el CRS por servicio.

Si usas BunkerWeb en producci贸n con un gran n煤mero de servicios y habilitas la **caracter铆stica de ModSecurity globalmente** con las reglas CRS, el tiempo requerido para cargar las configuraciones de BunkerWeb puede volverse demasiado largo, resultando potencialmente en un tiempo de espera agotado.

La soluci贸n es cargar las reglas CRS globalmente en lugar de por servicio. Este comportamiento no est谩 habilitado por defecto por razones de compatibilidad con versiones anteriores y porque tiene un inconveniente: si habilitas la carga global de reglas CRS, **ya no ser谩 posible definir reglas modsec-crs** (ejecutadas antes de las reglas CRS) por servicio. Sin embargo, esta limitaci贸n puede ser superada escribiendo reglas de exclusi贸n globales `modsec-crs` como esta:

```
SecRule REQUEST_FILENAME "@rx ^/somewhere$" "nolog,phase:4,allow,id:1010,chain"
SecRule REQUEST_HEADERS:Host "@rx ^app1\.example\.com$" "nolog"
```

Puedes habilitar la carga global de CRS estableciendo `USE_MODSECURITY_GLOBAL_CRS` en `yes`.

### Ajustar max_allowed_packet para MariaDB/MySQL

Parece que el valor predeterminado para el par谩metro `max_allowed_packet` en los servidores de bases de datos MariaDB y MySQL no es suficiente cuando se utiliza BunkerWeb con un gran n煤mero de servicios.

Si encuentras errores como este, especialmente en el programador:

```
[Warning] Aborted connection 5 to db: 'db' user: 'bunkerweb' host: '172.20.0.4' (Got a packet bigger than 'max_allowed_packet' bytes)
```

Necesitar谩s aumentar el `max_allowed_packet` en tu servidor de base de datos.

## Persistencia de bloqueos e informes {#persistence-of-bans-and-reports}

Por defecto, BunkerWeb almacena los bloqueos e informes en un almac茅n de datos Lua local. Aunque es simple y eficiente, esta configuraci贸n significa que los datos se pierden cuando se reinicia la instancia. Para asegurar que los bloqueos e informes persistan a trav茅s de los reinicios, puedes configurar BunkerWeb para que utilice un servidor remoto [Redis](https://redis.io/) o [Valkey](https://valkey.io/).

**驴Por qu茅 usar Redis/Valkey?**

Redis y Valkey son potentes almacenes de datos en memoria com煤nmente utilizados como bases de datos, cach茅s y agentes de mensajes. Son altamente escalables y soportan una variedad de estructuras de datos, incluyendo:

- **Strings**: Pares b谩sicos de clave-valor.
- **Hashes**: Pares de campo-valor dentro de una sola clave.
- **Lists**: Colecciones ordenadas de cadenas.
- **Sets**: Colecciones no ordenadas de cadenas 煤nicas.
- **Sorted Sets**: Colecciones ordenadas con puntuaciones.

Al aprovechar Redis o Valkey, BunkerWeb puede almacenar persistentemente bloqueos, informes y datos de cach茅, asegurando durabilidad y escalabilidad.

**Habilitando el soporte de Redis/Valkey**

Para habilitar el soporte de Redis o Valkey, configura los siguientes ajustes en tu archivo de configuraci贸n de BunkerWeb:

```conf
# Habilitar el soporte de Redis/Valkey
USE_REDIS=yes

# Nombre de host o direcci贸n IP del servidor Redis/Valkey
REDIS_HOST=<hostname>

# N煤mero de puerto del servidor Redis/Valkey (predeterminado: 6379)
REDIS_PORT=6379

# N煤mero de base de datos de Redis/Valkey (predeterminado: 0)
REDIS_DATABASE=0
```

- **`USE_REDIS`**: Establ茅celo en `yes` para habilitar la integraci贸n con Redis/Valkey.
- **`REDIS_HOST`**: Especifica el nombre de host o la direcci贸n IP del servidor Redis/Valkey.
- **`REDIS_PORT`**: Especifica el n煤mero de puerto para el servidor Redis/Valkey. El valor predeterminado es `6379`.
- **`REDIS_DATABASE`**: Especifica el n煤mero de la base de datos de Redis/Valkey a utilizar. El valor predeterminado es `0`.

Si necesitas configuraciones m谩s avanzadas, como autenticaci贸n, soporte SSL/TLS o modo Sentinel, consulta la [documentaci贸n de configuraci贸n del plugin de Redis](features.md#redis) para obtener una gu铆a detallada.

## Proteger aplicaciones UDP/TCP

!!! example "Caracter铆stica experimental"

	  Esta caracter铆stica no est谩 lista para producci贸n. Si茅ntete libre de probarla y reportarnos cualquier error usando los [issues](https://github.com/bunkerity/bunkerweb/issues) en el repositorio de GitHub.

BunkerWeb ofrece la capacidad de funcionar como un **proxy inverso gen茅rico UDP/TCP**, permiti茅ndote proteger cualquier aplicaci贸n basada en red que opere al menos en la capa 4 del modelo OSI. En lugar de utilizar el m贸dulo HTTP "cl谩sico", BunkerWeb aprovecha el [m贸dulo stream](https://nginx.org/en/docs/stream/ngx_stream_core_module.html) de NGINX.

Es importante tener en cuenta que **no todas las configuraciones y caracter铆sticas de seguridad est谩n disponibles cuando se utiliza el m贸dulo stream**. Puedes encontrar informaci贸n adicional sobre esto en las secciones de [caracter铆sticas](features.md) de la documentaci贸n.

Configurar un proxy inverso b谩sico es bastante similar a la configuraci贸n HTTP, ya que implica usar las mismas configuraciones: `USE_REVERSE_PROXY=yes` y `REVERSE_PROXY_HOST=myapp:9000`. Incluso cuando BunkerWeb est谩 posicionado detr谩s de un Balanceador de Carga, las configuraciones siguen siendo las mismas (siendo el **protocolo PROXY** la opci贸n soportada por razones evidentes).

Adem谩s de eso, se utilizan las siguientes configuraciones espec铆ficas:

- `SERVER_TYPE=stream`: activa el modo `stream` (UDP/TCP gen茅rico) en lugar del `http` (que es el predeterminado)
- `LISTEN_STREAM_PORT=4242`: el puerto de escucha "plano" (sin SSL/TLS) en el que BunkerWeb escuchar谩
- `LISTEN_STREAM_PORT_SSL=4343`: el puerto de escucha "ssl/tls" en el que BunkerWeb escuchar谩
- `USE_UDP=no`: escucha y reenv铆a paquetes UDP en lugar de TCP

Para obtener una lista completa de las configuraciones relacionadas con el modo `stream`, consulta la secci贸n de [caracter铆sticas](features.md) de la documentaci贸n.

!!! tip "m煤ltiples puertos de escucha"

    Desde la versi贸n `1.6.0`, BunkerWeb soporta m煤ltiples puertos de escucha para el modo `stream`. Puedes especificarlos usando las configuraciones `LISTEN_STREAM_PORT` y `LISTEN_STREAM_PORT_SSL`.

    Aqu铆 hay un ejemplo:

    ```conf
    ...
    LISTEN_STREAM_PORT=4242
    LISTEN_STREAM_PORT_SSL=4343
    LISTEN_STREAM_PORT_1=4244
    LISTEN_STREAM_PORT_SSL_1=4344
    ...
    ```

=== "Todo en uno"

    Necesitar谩s agregar la configuraci贸n a las variables de entorno al ejecutar el contenedor Todo en uno. Tambi茅n necesitar谩s exponer los puertos de stream.

    Este ejemplo configura BunkerWeb para hacer proxy de dos aplicaciones basadas en stream, `app1.example.com` y `app2.example.com`.

    ```bash
    docker run -d \
        --name bunkerweb-aio \
        -v bw-storage:/data \
        -e SERVICE_UI="no" \
        -e SERVER_NAME="app1.example.com app2.example.com" \
        -e MULTISITE="yes" \
        -e USE_REVERSE_PROXY="yes" \
        -e SERVER_TYPE="stream" \
        -e app1.example.com_REVERSE_PROXY_HOST="myapp1:9000" \
        -e app1.example.com_LISTEN_STREAM_PORT="10000" \
        -e app2.example.com_REVERSE_PROXY_HOST="myapp2:9000" \
        -e app2.example.com_LISTEN_STREAM_PORT="20000" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        -p 10000:10000/tcp \
        -p 20000:20000/tcp \
        bunkerity/bunkerweb-all-in-one:1.6.6
    ```

    Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se apliquen las nuevas variables de entorno.

    Tus aplicaciones (`myapp1`, `myapp2`) deber铆an estar ejecut谩ndose en contenedores separados (o ser accesibles de otra manera) y sus nombres de host/IPs (p. ej., `myapp1`, `myapp2` usados en `_REVERSE_PROXY_HOST`) deben ser resolvibles y alcanzables desde el contenedor `bunkerweb-aio`. Esto t铆picamente implica conectarlos a una red Docker compartida.

    !!! note "Desactivar el servicio de la interfaz de usuario"
        Se recomienda desactivar el servicio de la interfaz de usuario (p. ej., estableciendo `SERVICE_UI=no` como una variable de entorno) ya que la interfaz de usuario web no es compatible con `SERVER_TYPE=stream`.

=== "Docker"

    Cuando se utiliza la integraci贸n con Docker, la forma m谩s f谩cil de proteger las aplicaciones de red existentes es agregar los servicios a la red `bw-services`:

    ```yaml
    x-bw-api-env: &bw-api-env
      # Usamos un ancla para evitar repetir la misma configuraci贸n para todos los servicios
      API_WHITELIST_IP: "127.0.0.0/8 10.20.30.0/24"
      # Token de API opcional para llamadas de API autenticadas
      API_TOKEN: ""

    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        ports:
          - "80:8080" # Mantenlo si quieres usar la automatizaci贸n de Let's Encrypt al usar el tipo de desaf铆o http
          - "10000:10000" # app1
          - "20000:20000" # app2
        labels:
          - "bunkerweb.INSTANCE=yes"
        environment:
          <<: *bw-api-env
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-services

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.6
        environment:
          <<: *bw-api-env
          BUNKERWEB_INSTANCES: "bunkerweb" # Esta configuraci贸n es obligatoria para especificar la instancia de BunkerWeb
          SERVER_NAME: "app1.example.com app2.example.com"
          MULTISITE: "yes"
          USE_REVERSE_PROXY: "yes" # Se aplicar谩 a todos los servicios
          SERVER_TYPE: "stream" # Se aplicar谩 a todos los servicios
          app1.example.com_REVERSE_PROXY_HOST: "myapp1:9000"
          app1.example.com_LISTEN_STREAM_PORT: "10000"
          app2.example.com_REVERSE_PROXY_HOST: "myapp2:9000"
          app2.example.com_LISTEN_STREAM_PORT: "20000"
        volumes:
          - bw-storage:/data # Esto se usa para persistir la cach茅 y otros datos como las copias de seguridad
        restart: "unless-stopped"
        networks:
          - bw-universe

      myapp1:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app1" ]
        networks:
          - bw-services

      myapp2:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app2" ]
        networks:
          - bw-services

    volumes:
      bw-storage:

    networks:
      bw-universe:
        name: bw-universe
        ipam:
          driver: default
          config:
            - subnet: 10.20.30.0/24
      bw-services:
        name: bw-services
    ```

=== "Docker autoconf"

    Antes de ejecutar el stack de [integraci贸n Docker autoconf](integrations.md#docker-autoconf) en tu m谩quina, necesitar谩s editar los puertos:

    ```yaml
    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        ports:
          - "80:8080" # Mantenlo si quieres usar la automatizaci贸n de Let's Encrypt cuando usas el tipo de desaf铆o http
          - "10000:10000" # app1
          - "20000:20000" # app2
    ...
    ```

    Una vez que el stack est茅 en ejecuci贸n, puedes conectar tus aplicaciones existentes a la red `bw-services` y configurar BunkerWeb con etiquetas:

    ```yaml
    services:
      myapp1:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app1" ]
        networks:
          - bw-services
        labels:
          - "bunkerweb.SERVER_NAME=app1.example.com"
          - "bunkerweb.SERVER_TYPE=stream"
          - "bunkerweb.USE_REVERSE_PROXY=yes"
          - "bunkerweb.REVERSE_PROXY_HOST=myapp1:9000"
          - "bunkerweb.LISTEN_STREAM_PORT=10000"

      myapp2:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app2" ]
        networks:
          - bw-services
        labels:
          - "bunkerweb.SERVER_NAME=app2.example.com"
          - "bunkerweb.SERVER_TYPE=stream"
          - "bunkerweb.USE_REVERSE_PROXY=yes"
          - "bunkerweb.REVERSE_PROXY_HOST=myapp2:9000"
          - "bunkerweb.LISTEN_STREAM_PORT=20000"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

=== "Kubernetes"

    !!! example "Caracter铆stica experimental"

        Por el momento, los [Ingresses](https://kubernetes.io/docs/concepts/services-networking/ingress/) no soportan el modo `stream`. **Lo que estamos haciendo aqu铆 es una soluci贸n alternativa para que funcione.**

        Si茅ntete libre de probarlo y reportarnos cualquier error usando los [issues](https://github.com/bunkerity/bunkerweb/issues) en el repositorio de GitHub.

    Antes de ejecutar el stack de la [integraci贸n de Kubernetes](integrations.md#kubernetes) en tu m谩quina, necesitar谩s abrir los puertos en tu balanceador de carga:

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: lb
    spec:
      type: LoadBalancer
      ports:
        - name: http # Mantenlo si quieres usar la automatizaci贸n de Let's Encrypt cuando usas el tipo de desaf铆o http
          port: 80
          targetPort: 8080
        - name: app1
          port: 10000
          targetPort: 10000
        - name: app2
          port: 20000
          targetPort: 20000
      selector:
        app: bunkerweb
    ```

    Una vez que el stack est茅 en ejecuci贸n, puedes crear tus recursos de ingress:

    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: ingress
      namespace: services
      annotations:
        bunkerweb.io/SERVER_TYPE: "stream" # Se aplicar谩 a todos los servicios
        bunkerweb.io/app1.example.com_LISTEN_STREAM_PORT: "10000"
        bunkerweb.io/app2.example.com_LISTEN_STREAM_PORT: "20000"
    spec:
      rules:
        - host: app1.example.com
          http:
            paths:
              - path: / # Esto no se usa en modo stream pero es obligatorio
                pathType: Prefix
                backend:
                  service:
                    name: svc-app1
                    port:
                      number: 9000
        - host: app2.example.com
          http:
            paths:
              - path: / # Esto no se usa en modo stream pero es obligatorio
                pathType: Prefix
                backend:
                  service:
                    name: svc-app2
                    port:
                      number: 9000
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: app1
      namespace: services
      labels:
        app: app1
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: app1
      template:
        metadata:
          labels:
            app: app1
        spec:
          containers:
            - name: app1
              image: istio/tcp-echo-server:1.3
              args: ["9000", "app1"]
              ports:
                - containerPort: 9000
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: svc-app1
      namespace: services
    spec:
      selector:
        app: app1
      ports:
        - protocol: TCP
          port: 9000
          targetPort: 9000
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: app2
      namespace: services
      labels:
        app: app2
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: app2
      template:
        metadata:
          labels:
            app: app2
        spec:
          containers:
            - name: app2
              image: istio/tcp-echo-server:1.3
              args: ["9000", "app2"]
              ports:
                - containerPort: 9000
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: svc-app2
      namespace: services
    spec:
      selector:
        app: app2
      ports:
        - protocol: TCP
          port: 9000
          targetPort: 9000
    ```

=== "Linux"

    Necesitar谩s agregar la configuraci贸n al archivo `/etc/bunkerweb/variables.env`:

    ```conf
    ...
    SERVER_NAME=app1.example.com app2.example.com
    MULTISITE=yes
    USE_REVERSE_PROXY=yes
    SERVER_TYPE=stream
    app1.example.com_REVERSE_PROXY_HOST=myapp1.domain.or.ip:9000
    app1.example.com_LISTEN_STREAM_PORT=10000
    app2.example.com_REVERSE_PROXY_HOST=myapp2.domain.or.ip:9000
    app2.example.com_LISTEN_STREAM_PORT=20000
    ...
    ```

    Ahora verifiquemos el estado del Programador:

    ```shell
    systemctl status bunkerweb-scheduler
    ```

    Si ya se est谩 ejecutando, podemos recargarlo:

    ```shell
    systemctl reload bunkerweb-scheduler
    ```

    De lo contrario, tendremos que iniciarlo:

    ```shell
    systemctl start bunkerweb-scheduler
    ```

=== "Swarm"

    !!! warning "Obsoleto"
        La integraci贸n de Swarm est谩 obsoleta y se eliminar谩 en una futura versi贸n. Por favor, considera usar la [integraci贸n de Kubernetes](integrations.md#kubernetes) en su lugar.

        **Puedes encontrar m谩s informaci贸n en la [documentaci贸n de la integraci贸n de Swarm](integrations.md#swarm).**

    Antes de ejecutar el stack de [integraci贸n de Swarm](integrations.md#swarm) en tu m谩quina, necesitar谩s editar los puertos:

    ```yaml
    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        ports:
          # Mantenlo si quieres usar la automatizaci贸n de Let's Encrypt cuando usas el tipo de desaf铆o http
          - published: 80
            target: 8080
            mode: host
            protocol: tcp
          # app1
          - published: 10000
            target: 10000
            mode: host
            protocol: tcp
          # app2
          - published: 20000
            target: 20000
            mode: host
            protocol: tcp
    ...
    ```

    Una vez que el stack est茅 en ejecuci贸n, puedes conectar tus aplicaciones existentes a la red `bw-services` y configurar BunkerWeb con etiquetas:

    ```yaml
    services:

      myapp1:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app1" ]
        networks:
          - bw-services
        deploy:
          placement:
            constraints:
              - "node.role==worker"
          labels:
            - "bunkerweb.SERVER_NAME=app1.example.com"
            - "bunkerweb.SERVER_TYPE=stream"
            - "bunkerweb.USE_REVERSE_PROXY=yes"
            - "bunkerweb.REVERSE_PROXY_HOST=myapp1:9000"
            - "bunkerweb.LISTEN_STREAM_PORT=10000"

      myapp2:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app2" ]
        networks:
          - bw-services
        deploy:
          placement:
            constraints:
              - "node.role==worker"
          labels:
            - "bunkerweb.SERVER_NAME=app2.example.com"
            - "bunkerweb.SERVER_TYPE=stream"
            - "bunkerweb.USE_REVERSE_PROXY=yes"
            - "bunkerweb.REVERSE_PROXY_HOST=myapp2:9000"
            - "bunkerweb.LISTEN_STREAM_PORT=20000"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

## PHP

!!! example "Caracter铆stica experimental"
	  Por el momento, el soporte de PHP con BunkerWeb todav铆a est谩 en beta y te recomendamos que utilices una arquitectura de proxy inverso si puedes. Por cierto, PHP no es compatible en absoluto con algunas integraciones como Kubernetes.

BunkerWeb soporta PHP usando instancias externas o remotas de [PHP-FPM](https://www.php.net/manual/en/install.fpm.php). Asumiremos que ya est谩s familiarizado con la gesti贸n de este tipo de servicios.

Se pueden usar las siguientes configuraciones:

- `REMOTE_PHP`: Nombre de host de la instancia remota de PHP-FPM.
- `REMOTE_PHP_PATH`: Carpeta ra铆z que contiene los archivos en la instancia remota de PHP-FPM.
- `REMOTE_PHP_PORT`: Puerto de la instancia remota de PHP-FPM (*el predeterminado es 9000*).
- `LOCAL_PHP`: Ruta al archivo de socket local de la instancia de PHP-FPM.
- `LOCAL_PHP_PATH`: Carpeta ra铆z que contiene los archivos en la instancia local de PHP-FPM.

=== "Todo en uno"

    Cuando se utiliza la [imagen Todo en uno](integrations.md#all-in-one-aio-image), para soportar aplicaciones PHP, necesitar谩s:

    - Montar tus archivos PHP en la carpeta `/var/www/html` de BunkerWeb.
    - Configurar un contenedor PHP-FPM para tu aplicaci贸n y montar la carpeta que contiene los archivos PHP.
    - Usar las configuraciones espec铆ficas `REMOTE_PHP` y `REMOTE_PHP_PATH` como variables de entorno al ejecutar BunkerWeb.

    Si habilitas el [modo multisitio](features.md#multisite-mode), necesitar谩s crear directorios separados para cada una de tus aplicaciones. Cada subdirectorio debe nombrarse usando el primer valor de `SERVER_NAME`. Aqu铆 hay un ejemplo de prueba:

    ```
    www
     app1.example.com
        index.php
     app2.example.com
         index.php

    2 directorios, 2 archivos
    ```

    Asumiremos que tus aplicaciones PHP est谩n ubicadas en una carpeta llamada `www`. Ten en cuenta que necesitar谩s corregir los permisos para que BunkerWeb (UID/GID 101) pueda al menos leer archivos y listar carpetas, y que PHP-FPM (UID/GID 33 si usas la imagen `php:fpm`) sea el propietario de los archivos y carpetas:

    ```shell
    chown -R 33:101 ./www && \
    find ./www -type f -exec chmod 0640 {} \; && \
    find ./www -type d -exec chmod 0750 {} \;
    ```

    Ahora puedes ejecutar BunkerWeb, configurarlo para tu aplicaci贸n PHP y tambi茅n ejecutar las aplicaciones PHP. Necesitar谩s crear una red Docker personalizada para permitir que BunkerWeb se comunique con tus contenedores PHP-FPM.

    ```bash
    # Crear una red personalizada
    docker network create php-network

    # Ejecutar contenedores PHP-FPM
    docker run -d --name myapp1-php --network php-network -v ./www/app1.example.com:/app php:fpm
    docker run -d --name myapp2-php --network php-network -v ./www/app2.example.com:/app php:fpm

    # Ejecutar BunkerWeb Todo en uno
    docker run -d \
        --name bunkerweb-aio \
        --network php-network \
        -v ./www:/var/www/html \
        -v bw-storage:/data \
        -e SERVER_NAME="app1.example.com app2.example.com" \
        -e MULTISITE="yes" \
        -e REMOTE_PHP_PATH="/app" \
        -e app1.example.com_REMOTE_PHP="myapp1-php" \
        -e app2.example.com_REMOTE_PHP="myapp2-php" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        bunkerity/bunkerweb-all-in-one:1.6.6
    ```

    Ten en cuenta que si tu contenedor ya est谩 creado, necesitar谩s eliminarlo y recrearlo para que se apliquen las nuevas variables de entorno.

=== "Docker"

    Cuando se utiliza la [integraci贸n de Docker](integrations.md#docker), para admitir aplicaciones PHP, necesitar谩s:

    - Montar tus archivos PHP en la carpeta `/var/www/html` de BunkerWeb
    - Configurar un contenedor PHP-FPM para tu aplicaci贸n y montar la carpeta que contiene los archivos PHP
    - Usar las configuraciones espec铆ficas `REMOTE_PHP` y `REMOTE_PHP_PATH` como variables de entorno al iniciar BunkerWeb

    Si habilitas el [modo multisitio](features.md#multisite-mode), necesitar谩s crear directorios separados para cada una de tus aplicaciones. Cada subdirectorio debe nombrarse utilizando el primer valor de `SERVER_NAME`. Aqu铆 hay un ejemplo de prueba:

    ```
    www
     app1.example.com
        index.php
     app2.example.com
        index.php
     app3.example.com
         index.php

    3 directorios, 3 archivos
    ```

    Asumiremos que tus aplicaciones PHP est谩n ubicadas en una carpeta llamada `www`. Ten en cuenta que necesitar谩s arreglar los permisos para que BunkerWeb (UID/GID 101) pueda al menos leer archivos y listar carpetas y PHP-FPM (UID/GID 33 si usas la imagen `php:fpm`) sea el propietario de los archivos y carpetas:

    ```shell
    chown -R 33:101 ./www && \
    find ./www -type f -exec chmod 0640 {} \; && \
    find ./www -type d -exec chmod 0750 {} \;
    ```

    Ahora puedes ejecutar BunkerWeb, configurarlo para tu aplicaci贸n PHP y tambi茅n ejecutar las aplicaciones PHP:

    ```yaml
    x-bw-api-env: &bw-api-env
      # Usamos un ancla para evitar repetir la misma configuraci贸n para todos los servicios
      API_WHITELIST_IP: "127.0.0.0/8 10.20.30.0/24"

    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        ports:
          - "80:8080/tcp"
          - "443:8443/tcp"
          - "443:8443/udp" # QUIC
        environment:
          <<: *bw-api-env
        volumes:
          - ./www:/var/www/html
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-services

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.6
        environment:
          <<: *bw-api-env
          BUNKERWEB_INSTANCES: "bunkerweb" # Esta configuraci贸n es obligatoria para especificar la instancia de BunkerWeb
          SERVER_NAME: "app1.example.com app2.example.com"
          MULTISITE: "yes"
          REMOTE_PHP_PATH: "/app" # Se aplicar谩 a todos los servicios gracias a la configuraci贸n MULTISITE
          app1.example.com_REMOTE_PHP: "myapp1"
          app2.example.com_REMOTE_PHP: "myapp2"
          app3.example.com_REMOTE_PHP: "myapp3"
        volumes:
          - bw-storage:/data # Esto se usa para persistir la cach茅 y otros datos como las copias de seguridad
        restart: "unless-stopped"
        networks:
          - bw-universe

      myapp1:
        image: php:fpm
        volumes:
          - ./www/app1.example.com:/app
        networks:
          - bw-services

      myapp2:
        image: php:fpm
        volumes:
          - ./www/app2.example.com:/app
        networks:
          - bw-services

      myapp3:
        image: php:fpm
        volumes:
          - ./www/app3.example.com:/app
        networks:
          - bw-services

    volumes:
      bw-storage:

    networks:
      bw-universe:
        name: bw-universe
        ipam:
          driver: default
          config:
            - subnet: 10.20.30.0/24
      bw-services:
        name: bw-services
    ```

=== "Docker autoconf"

    !!! info "Modo multisitio habilitado"
        La integraci贸n de [Docker autoconf](integrations.md#docker-autoconf) implica el uso del modo multisitio: proteger una aplicaci贸n PHP es lo mismo que proteger varias.

    Cuando se utiliza la [integraci贸n de Docker autoconf](integrations.md#docker-autoconf), para admitir aplicaciones PHP, necesitar谩s:

    - Montar tus archivos PHP en la carpeta `/var/www/html` de BunkerWeb
    - Configurar contenedores PHP-FPM para tus aplicaciones y montar la carpeta que contiene las aplicaciones PHP
    - Usar las configuraciones espec铆ficas `REMOTE_PHP` y `REMOTE_PHP_PATH` como etiquetas para tu contenedor PHP-FPM

    Dado que la autoconfiguraci贸n de Docker implica el uso del [modo multisitio](features.md#multisite-mode), necesitar谩s crear directorios separados para cada una de tus aplicaciones. Cada subdirectorio debe tener el nombre del primer valor de `SERVER_NAME`. Aqu铆 hay un ejemplo de prueba:

    ```
    www
     app1.example.com
        index.php
     app2.example.com
        index.php
     app3.example.com
         index.php

    3 directorios, 3 archivos
    ```

    Una vez creadas las carpetas, copia tus archivos y corrige los permisos para que BunkerWeb (UID/GID 101) pueda al menos leer archivos y listar carpetas, y PHP-FPM (UID/GID 33 si usas la imagen `php:fpm`) sea el propietario de los archivos y carpetas:

    ```shell
    chown -R 33:101 ./www && \
    find ./www -type f -exec chmod 0640 {} \; && \
    find ./www -type d -exec chmod 0750 {} \;
    ```

    Cuando inicies el stack de autoconfiguraci贸n de BunkerWeb, monta la carpeta `www` en `/var/www/html` para el contenedor del **Scheduler**:

    ```yaml
    x-bw-api-env: &bw-api-env
      # Usamos un ancla para evitar repetir la misma configuraci贸n para todos los servicios
      AUTOCONF_MODE: "yes"
      API_WHITELIST_IP: "127.0.0.0/8 10.20.30.0/24"

    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        labels:
          - "bunkerweb.INSTANCE=yes"
        environment:
          <<: *bw-api-env
        volumes:
          - ./www:/var/www/html
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-services

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.6
        environment:
          <<: *bw-api-env
          BUNKERWEB_INSTANCES: "" # No necesitamos especificar la instancia de BunkerWeb aqu铆, ya que son detectadas autom谩ticamente por el servicio de autoconfiguraci贸n
          SERVER_NAME: "" # El nombre del servidor se llenar谩 con las etiquetas de los servicios
          MULTISITE: "yes" # Configuraci贸n obligatoria para la autoconfiguraci贸n
          DATABASE_URI: "mariadb+pymysql://bunkerweb:changeme@bw-db:3306/db" # Recuerda establecer una contrase帽a m谩s segura para la base de datos
        volumes:
          - bw-storage:/data # Se utiliza para persistir la cach茅 y otros datos como las copias de seguridad
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-db

      bw-autoconf:
        image: bunkerity/bunkerweb-autoconf:1.6.6
        depends_on:
          - bunkerweb
          - bw-docker
        environment:
          AUTOCONF_MODE: "yes"
          DATABASE_URI: "mariadb+pymysql://bunkerweb:changeme@bw-db:3306/db" # Recuerda establecer una contrase帽a m谩s segura para la base de datos
          DOCKER_HOST: "tcp://bw-docker:2375" # El socket de Docker
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-docker
          - bw-db

      bw-docker:
        image: tecnativa/docker-socket-proxy:nightly
        volumes:
          - /var/run/docker.sock:/var/run/docker.sock:ro
        environment:
          CONTAINERS: "1"
          LOG_LEVEL: "warning"
        networks:
          - bw-docker

      bw-db:
        image: mariadb:11
        # Establecemos el tama帽o m谩ximo de paquete permitido para evitar problemas con consultas grandes
        command: --max-allowed-packet=67108864
        environment:
          MYSQL_RANDOM_ROOT_PASSWORD: "yes"
          MYSQL_DATABASE: "db"
          MYSQL_USER: "bunkerweb"
          MYSQL_PASSWORD: "changeme" # Recuerda establecer una contrase帽a m谩s segura para la base de datos
        volumes:
          - bw-data:/var/lib/mysql
        networks:
          - bw-docker

    volumes:
      bw-data:
      bw-storage:

    networks:
      bw-universe:
        name: bw-universe
        ipam:
          driver: default
          config:
            - subnet: 10.20.30.0/24
      bw-services:
        name: bw-services
      bw-docker:
        name: bw-docker
    ```

    Ahora puedes crear tus contenedores PHP-FPM, montar las subcarpetas correctas y usar etiquetas para configurar BunkerWeb:

    ```yaml
    services:
      myapp1:
          image: php:fpm
          volumes:
            - ./www/app1.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp1
          labels:
            - "bunkerweb.SERVER_NAME=app1.example.com"
            - "bunkerweb.REMOTE_PHP=myapp1"
            - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp2:
          image: php:fpm
          volumes:
            - ./www/app2.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp2
          labels:
            - "bunkerweb.SERVER_NAME=app2.example.com"
            - "bunkerweb.REMOTE_PHP=myapp2"
            - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp3:
          image: php:fpm
          volumes:
            - ./www/app3.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp3
          labels:
            - "bunkerweb.SERVER_NAME=app3.example.com"
            - "bunkerweb.REMOTE_PHP=myapp3"
            - "bunkerweb.REMOTE_PHP_PATH=/app"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

=== "Kubernetes"

    !!! warning "PHP no es compatible con Kubernetes"
        La integraci贸n de Kubernetes permite la configuraci贸n a trav茅s de [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) y el controlador de BunkerWeb solo admite aplicaciones HTTP por el momento.

=== "Linux"

    Asumiremos que ya tienes el stack de [integraci贸n de Linux](integrations.md#linux) funcionando en tu m谩quina.

    Por defecto, BunkerWeb buscar谩 archivos web dentro de la carpeta `/var/www/html`. Puedes usarla para almacenar tus aplicaciones PHP. Ten en cuenta que necesitar谩s configurar tu servicio PHP-FPM para obtener o establecer el usuario/grupo de los procesos en ejecuci贸n y el archivo de socket UNIX utilizado para comunicarse con BunkerWeb.

    En primer lugar, deber谩s asegurarte de que tu instancia de PHP-FPM pueda acceder a los archivos dentro de la carpeta `/var/www/html` y tambi茅n de que BunkerWeb pueda acceder al archivo de socket UNIX para comunicarse con PHP-FPM. Recomendamos establecer un usuario diferente como `www-data` para el servicio PHP-FPM y dar al grupo nginx acceso al archivo de socket UNIX. Aqu铆 est谩 la configuraci贸n correspondiente de PHP-FPM:

    ```ini
    ...
    [www]
    user = www-data
    group = www-data
    listen = /run/php/php-fpm.sock
    listen.owner = www-data
    listen.group = nginx
    listen.mode = 0660
    ...
    ```

    No olvides reiniciar tu servicio PHP-FPM:

    ```shell
    systemctl restart php-fpm
    ```

    Si habilitas el [modo multisitio](features.md#multisite-mode), necesitar谩s crear directorios separados para cada una de tus aplicaciones. Cada subdirectorio debe nombrarse utilizando el primer valor de `SERVER_NAME`. Aqu铆 hay un ejemplo de prueba:

    ```
    /var/www/html
     app1.example.com
        index.php
     app2.example.com
        index.php
     app3.example.com
         index.php

    3 directorios, 3 archivos
    ```

    Ten en cuenta que necesitar谩s arreglar los permisos para que BunkerWeb (grupo `nginx`) pueda al menos leer archivos y listar carpetas, y PHP-FPM (usuario `www-data`, pero podr铆a ser diferente dependiendo de tu sistema) sea el propietario de los archivos y carpetas:

    ```shell
    chown -R www-data:nginx /var/www/html && \
    find /var/www/html -type f -exec chmod 0640 {} \; && \
    find /var/www/html -type d -exec chmod 0750 {} \;
    ```

    Ahora puedes editar el archivo `/etc/bunkerweb/variable.env`:

    ```conf
    HTTP_PORT=80
    HTTPS_PORT=443
    DNS_RESOLVERS=9.9.9.9 8.8.8.8 8.8.4.4
    API_LISTEN_IP=127.0.0.1
    MULTISITE=yes
    SERVER_NAME=app1.example.com app2.example.com app3.example.com
    app1.example.com_LOCAL_PHP=/run/php/php-fpm.sock
    app1.example.com_LOCAL_PHP_PATH=/var/www/html/app1.example.com
    app2.example.com_LOCAL_PHP=/run/php/php-fpm.sock
    app2.example.com_LOCAL_PHP_PATH=/var/www/html/app2.example.com
    app3.example.com_LOCAL_PHP=/run/php/php-fpm.sock
    app3.example.com_LOCAL_PHP_PATH=/var/www/html/app3.example.com
    ```

    Ahora verifiquemos el estado del Programador:

    ```shell
    systemctl status bunkerweb-scheduler
    ```

    Si ya se est谩n ejecutando, podemos recargarlo:

    ```shell
    systemctl reload bunkerweb-scheduler
    ```

    De lo contrario, tendremos que iniciarlo:

    ```shell
    systemctl start bunkerweb-scheduler
    ```

=== "Swarm"

    !!! warning "Obsoleto"
        La integraci贸n de Swarm est谩 obsoleta y se eliminar谩 en una futura versi贸n. Por favor, considera usar la [integraci贸n de Kubernetes](integrations.md#kubernetes) en su lugar.

        **Se puede encontrar m谩s informaci贸n en la [documentaci贸n de integraci贸n de Swarm](integrations.md#swarm).**

    !!! info "Modo multisitio habilitado"
        La integraci贸n [Swarm](integrations.md#docker-autoconf) implica el uso del modo multisitio: proteger una aplicaci贸n PHP es lo mismo que proteger varias.

    !!! info "Volumen compartido"
        Usar PHP con la integraci贸n de Docker Swarm necesita un volumen compartido entre todas las instancias de BunkerWeb y PHP-FPM, lo cual no se cubre en esta documentaci贸n.

    Cuando se usa la integraci贸n [Swarm](integrations.md#swarm), para admitir aplicaciones PHP, necesitar谩s:

    - Montar tus archivos PHP en la carpeta `/var/www/html` de BunkerWeb
    - Configurar contenedores PHP-FPM para tus aplicaciones y montar la carpeta que contiene las aplicaciones PHP
    - Usar las configuraciones espec铆ficas `REMOTE_PHP` y `REMOTE_PHP_PATH` como etiquetas para tu contenedor PHP-FPM

    Dado que la integraci贸n de Swarm implica el uso del [modo multisitio](features.md#multisite-mode), necesitar谩s crear directorios separados para cada una de tus aplicaciones. Cada subdirectorio debe tener el nombre del primer valor de `SERVER_NAME`. Aqu铆 hay un ejemplo de prueba:

    ```
    www
     app1.example.com
        index.php
     app2.example.com
        index.php
     app3.example.com
         index.php

    3 directorios, 3 archivos
    ```

    Como ejemplo, consideraremos que tienes una carpeta compartida montada en tus nodos de trabajo en el punto final `/shared`.

    Una vez creadas las carpetas, copia tus archivos y corrige los permisos para que BunkerWeb (UID/GID 101) pueda al menos leer archivos y listar carpetas, y PHP-FPM (UID/GID 33 si usas la imagen `php:fpm`) sea el propietario de los archivos y carpetas:

    ```shell
    chown -R 33:101 /shared/www && \
    find /shared/www -type f -exec chmod 0640 {} \; && \
    find /shared/www -type d -exec chmod 0750 {} \;
    ```

    Cuando inicies el stack de BunkerWeb, monta la carpeta `/shared/www` en `/var/www/html` para el contenedor del **Scheduler**:

    ```yaml
    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.6
        volumes:
          - /shared/www:/var/www/html
    ...
    ```

    Ahora puedes crear tus servicios PHP-FPM, montar las subcarpetas correctas y usar etiquetas para configurar BunkerWeb:

    ```yaml
    services:
      myapp1:
          image: php:fpm
          volumes:
            - ./www/app1.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp1
          deploy:
            placement:
              constraints:
                - "node.role==worker"
            labels:
              - "bunkerweb.SERVER_NAME=app1.example.com"
              - "bunkerweb.REMOTE_PHP=myapp1"
              - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp2:
          image: php:fpm
          volumes:
            - ./www/app2.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp2
          deploy:
            placement:
              constraints:
                - "node.role==worker"
            labels:
              - "bunkerweb.SERVER_NAME=app2.example.com"
              - "bunkerweb.REMOTE_PHP=myapp2"
              - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp3:
          image: php:fpm
          volumes:
            - ./www/app3.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp3
          deploy:
            placement:
              constraints:
                - "node.role==worker"
            labels:
              - "bunkerweb.SERVER_NAME=app3.example.com"
              - "bunkerweb.REMOTE_PHP=myapp3"
              - "bunkerweb.REMOTE_PHP_PATH=/app"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

## IPv6

!!! example "Caracter铆stica experimental"

    Esta caracter铆stica no est谩 lista para producci贸n. Si茅ntete libre de probarla y reportarnos cualquier error usando los [issues](https://github.com/bunkerity/bunkerweb/issues) en el repositorio de GitHub.

Por defecto, BunkerWeb solo escuchar谩 en direcciones IPv4 y no usar谩 IPv6 para las comunicaciones de red. Si quieres habilitar el soporte de IPv6, necesitas establecer `USE_IPV6=yes`. Ten en cuenta que la configuraci贸n de IPv6 de tu red y entorno est谩 fuera del alcance de esta documentaci贸n.

=== "Docker / Autoconf / Swarm"

    En primer lugar, necesitar谩s configurar tu demonio de Docker para habilitar el soporte de IPv6 para los contenedores y usar ip6tables si es necesario. Aqu铆 hay una configuraci贸n de ejemplo para tu archivo `/etc/docker/daemon.json`:

    ```json
    {
      "experimental": true,
      "ipv6": true,
      "ip6tables": true,
      "fixed-cidr-v6": "fd00:dead:beef::/48"
    }
    ```

    Ahora puedes reiniciar el servicio de Docker para aplicar los cambios:

    ```shell
    systemctl restart docker
    ```

    Una vez que Docker est茅 configurado para soportar IPv6, puedes agregar la configuraci贸n `USE_IPV6` y configurar la red `bw-services` para IPv6:

    ```yaml
    services:
      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.6
        environment:
          USE_IPv6: "yes"

    ...

    networks:
      bw-services:
        name: bw-services
        enable_ipv6: true
        ipam:
          config:
            - subnet: fd00:13:37::/48
              gateway: fd00:13:37::1

    ...
    ```

=== "Linux"

    Necesitar谩s agregar la configuraci贸n al archivo `/etc/bunkerweb/variables.env`:

    ```conf
    ...
    USE_IPV6=yes
    ...
    ```

    Verifiquemos el estado de BunkerWeb:

    ```shell
    systemctl status bunkerweb
    ```

    Si ya se est谩 ejecutando, podemos reiniciarlo:

    ```shell
    systemctl restart bunkerweb
    ```

    De lo contrario, tendremos que iniciarlo:

    ```shell
    systemctl start bunkerweb
    ```

## Opciones de configuraci贸n de registros

BunkerWeb ofrece una configuraci贸n de registros flexible que permite enviar registros a m煤ltiples destinos (por ejemplo, archivos, stdout/stderr o syslog) simult谩neamente. Esto es especialmente 煤til para integrarse con recopiladores externos de registros mientras se mantienen registros locales para la interfaz web.

Hay dos categor铆as principales de registros para configurar:

1. **Registros de servicio**: Logs generados por los componentes de BunkerWeb (Scheduler, UI, Autoconf, etc.). Se controlan por servicio mediante `LOG_TYPES` (y opcionalmente `LOG_FILE_PATH`, `LOG_SYSLOG_ADDRESS`, `LOG_SYSLOG_TAG`).
2. **Registros de acceso y error**: Registros HTTP de acceso y errores generados por NGINX. Solo el servicio `bunkerweb` usa estos (`ACCESS_LOG` / `ERROR_LOG` / `LOG_LEVEL`).

### Registros de servicio

Los registros de servicio se controlan con la configuraci贸n `LOG_TYPES`, que puede aceptar m煤ltiples valores separados por espacios (por ejemplo, `LOG_TYPES="stderr syslog"`).

| Valor    | Descripci贸n                                                                                                  |
| :------- | :----------------------------------------------------------------------------------------------------------- |
| `file`   | Escribe los registros en un archivo. Requerido para el visor de registros de la interfaz UI.                 |
| `stderr` | Escribe los registros en la salida de error est谩ndar. Est谩ndar en entornos con contenedores (`docker logs`). |
| `syslog` | Env铆a los registros a un servidor syslog. Requiere definir `LOG_SYSLOG_ADDRESS`.                             |

Al usar `syslog`, tambi茅n debes configurar:

- `LOG_SYSLOG_ADDRESS`: La direcci贸n del servidor syslog (por ejemplo, `udp://bw-syslog:514` o `/dev/log`).
- `LOG_SYSLOG_TAG`: Una etiqueta 煤nica para el servicio (por ejemplo, `bw-scheduler`) para distinguir sus entradas.
- `LOG_FILE_PATH`: Ruta para la salida de archivo cuando `LOG_TYPES` incluye `file` (por ejemplo, `/var/log/bunkerweb/scheduler.log`).

### Registros de acceso y error

Estos son registros est谩ndar de NGINX, configurados 煤nicamente mediante el **servicio `bunkerweb`**. Soportan m煤ltiples destinos a帽adiendo sufijos numerados a la configuraci贸n (por ejemplo, `ACCESS_LOG`, `ACCESS_LOG_1` junto con `LOG_FORMAT`, `LOG_FORMAT_1`, o `ERROR_LOG`, `ERROR_LOG_1` con sus respectivos `LOG_LEVEL`, `LOG_LEVEL_1`).

- `ACCESS_LOG`: Destino para los registros de acceso (por defecto: `/var/log/bunkerweb/access.log`). Acepta ruta de archivo, `syslog:server=host[:port][,param=value]`, buffer compartido `memory:name:size`, o `off` para desactivar. Consulta la [documentaci贸n de NGINX sobre access_log](https://nginx.org/en/docs/http/ngx_http_log_module.html#access_log) para m谩s detalles.
- `ERROR_LOG`: Destino para los registros de error (por defecto: `/var/log/bunkerweb/error.log`). Acepta ruta de archivo, `stderr`, `syslog:server=host[:port][,param=value]`, o buffer compartido `memory:size`. Consulta la [documentaci贸n de NGINX sobre error_log](https://nginx.org/en/docs/ngx_core_module.html#error_log) para m谩s detalles.
- `LOG_LEVEL`: Nivel de verbosidad de los registros de error (por defecto: `notice`).

Estas configuraciones aceptan valores est谩ndar de NGINX, incluyendo rutas de archivo, `stderr`, `syslog:server=...` (ver [documentaci贸n de syslog en NGINX](https://nginx.org/en/docs/syslog.html)), o buffers en memoria compartida. Soportan m煤ltiples destinos mediante sufijos numerados (consulta la [convenci贸n de m煤ltiples ajustes](features.md#multiple-settings)). Los dem谩s servicios (Scheduler, UI, Autoconf, etc.) dependen 煤nicamente de `LOG_TYPES`/`LOG_FILE_PATH`/`LOG_SYSLOG_*`.

**Ejemplo con m煤ltiples registros de acceso/errores (solo bunkerweb, sufijos numerados):**

```conf
ACCESS_LOG=/var/log/bunkerweb/access.log
ACCESS_LOG_1=syslog:server=unix:/dev/log,tag=bunkerweb
LOG_FORMAT=$host $remote_addr - $request_id $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent"
LOG_FORMAT_1=$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent
ERROR_LOG=/var/log/bunkerweb/error.log
ERROR_LOG_1=syslog:server=unix:/dev/log,tag=bunkerweb
LOG_LEVEL=notice
LOG_LEVEL_1=error
```

### Valores por defecto e integraci贸n  Ejemplos

=== "Linux"

    **Comportamiento predeterminado**: `LOG_TYPES="file"`. Los registros se escriben en `/var/log/bunkerweb/*.log`.

    **Ejemplo**: Mantener archivos locales (para la interfaz web) y tambi茅n enviar una copia al syslog del sistema.

    ```conf
      # Registros de servicio (establecidos en /etc/bunkerweb/variables.env o en archivos env espec铆ficos del servicio)
      LOG_TYPES="file syslog"
      LOG_SYSLOG_ADDRESS=/dev/log
      SCHEDULER_LOG_FILE_PATH=/var/log/bunkerweb/scheduler.log
      UI_LOG_FILE_PATH=/var/log/bunkerweb/ui.log
      # ...
      # LOG_SYSLOG_TAG se asigna autom谩ticamente por servicio (anular por servicio si es necesario)

      # Registros de NGINX (solo servicio bunkerweb; establecer en /etc/bunkerweb/variables.env)
      ACCESS_LOG_1=syslog:server=unix:/dev/log,tag=bunkerweb_access
      ERROR_LOG_1=syslog:server=unix:/dev/log,tag=bunkerweb
    ```

=== "Docker / Autoconf"

    **Comportamiento predeterminado**: `LOG_TYPES="stderr"`. Los registros son visibles mediante `docker logs`.

    **Ejemplo (adaptado de la gu铆a de inicio r谩pido)**: Mantener `docker logs` (stderr) Y enviar tambi茅n a un contenedor syslog central (necesario para la interfaz web y CrowdSec).

    ```yaml
    x-bw-env:
      &bw-env # Usamos un ancla para evitar repetir la misma configuraci贸n para ambos servicios
      API_WHITELIST_IP: "127.0.0.0/8 10.20.30.0/24" # Aseg煤rate de establecer el rango de IP correcto para que el Scheduler pueda enviar la configuraci贸n a la instancia
      # Opcional: establece un token de API y refl茅jalo en ambos contenedores
      API_TOKEN: ""
      DATABASE_URI: "mariadb+pymysql://bunkerweb:changeme@bw-db:3306/db" # Recuerda establecer una contrase帽a m谩s segura para la base de datos
      # Registros de servicio
      LOG_TYPES: "stderr syslog"
      LOG_SYSLOG_ADDRESS: "udp://bw-syslog:514"
      # LOG_SYSLOG_TAG se asigna autom谩ticamente por servicio (anular por servicio si es necesario)
      # Registros NGINX: enviar a Syslog (solo bunkerweb)
      ACCESS_LOG_1: "syslog:server=bw-syslog:514,tag=bunkerweb_access"
      ERROR_LOG_1: "syslog:server=bw-syslog:514,tag=bunkerweb"

    services:
      bunkerweb:
        # Este es el nombre que se usar谩 para identificar la instancia en el Scheduler
        image: bunkerity/bunkerweb:1.6.6
        ports:
          - "80:8080/tcp"
          - "443:8443/tcp"
          - "443:8443/udp" # Para soporte QUIC / HTTP3
        environment:
          <<: *bw-env # Usamos el ancla para evitar repetir la misma configuraci贸n para todos los servicios
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-services

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.6
        environment:
          <<: *bw-env
          BUNKERWEB_INSTANCES: "bunkerweb" # Aseg煤rate de establecer el nombre correcto de la instancia
          SERVER_NAME: ""
          MULTISITE: "yes"
          UI_HOST: "http://bw-ui:7000" # Cambia si es necesario
          USE_REDIS: "yes"
          REDIS_HOST: "redis"
        volumes:
          - bw-storage:/data # Esto se usa para persistir la cach茅 y otros datos como las copias de seguridad
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-db

      bw-ui:
        image: bunkerity/bunkerweb-ui:1.6.6
        environment:
          <<: *bw-env
        volumes:
          - bw-logs:/var/log/bunkerweb # Esto se usa para leer los registros syslog desde la interfaz web
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-db

      bw-db:
        image: mariadb:11
        # Establecemos el tama帽o m谩ximo de paquete permitido para evitar problemas con consultas grandes
        command: --max-allowed-packet=67108864
        environment:
          MYSQL_RANDOM_ROOT_PASSWORD: "yes"
          MYSQL_DATABASE: "db"
          MYSQL_USER: "bunkerweb"
          MYSQL_PASSWORD: "changeme" # Recuerda establecer una contrase帽a m谩s segura para la base de datos
        volumes:
          - bw-data:/var/lib/mysql
        restart: "unless-stopped"
        networks:
          - bw-db

      redis: # Servicio Redis para la persistencia de reportes/bloqueos/estad铆sticas
        image: redis:7-alpine
        command: >
          redis-server
          --maxmemory 256mb
          --maxmemory-policy allkeys-lru
          --save 60 1000
          --appendonly yes
        volumes:
          - redis-data:/data
        restart: "unless-stopped"
        networks:
          - bw-universe

      bw-syslog:
        image: balabit/syslog-ng:4.10.2
        cap_add:
          - NET_BIND_SERVICE # Enlazar a puertos bajos
          - NET_BROADCAST # Enviar broadcasts
          - NET_RAW # Usar sockets raw
          - DAC_READ_SEARCH # Leer archivos saltando permisos
          - DAC_OVERRIDE # Anular permisos de archivos
          - CHOWN # Cambiar propiedad de archivos
          - SYSLOG # Escribir en logs del sistema
        volumes:
          - bw-logs:/var/log/bunkerweb # Este es el volumen usado para almacenar los registros
          - ./syslog-ng.conf:/etc/syslog-ng/syslog-ng.conf # Este es el archivo de configuraci贸n de syslog-ng
        restart: "unless-stopped"
        networks:
          - bw-universe

    volumes:
      bw-data:
      bw-storage:
      redis-data:
      bw-logs:

    networks:
      bw-universe:
        name: bw-universe
      ipam:
        driver: default
        config:
          - subnet: 10.20.30.0/24 # Aseg煤rate de establecer el rango de IP correcto para que el Scheduler pueda enviar la configuraci贸n a la instancia
      bw-services:
        name: bw-services
      bw-db:
        name: bw-db
    ```

### Configuraci贸n de syslog-ng

Aqu铆 tienes un ejemplo de un archivo `syslog-ng.conf` que puedes usar para reenviar los registros a un archivo:

```conf
@version: 4.10

# Configuraci贸n de la fuente para recibir registros enviados por los servicios de BunkerWeb (ACCESS_LOG / ERROR_LOG y LOG_TYPES=syslog)
source s_net {
  udp(
    ip("0.0.0.0")
  );
};

# Plantilla para formatear los mensajes de registro
template t_imp {
  template("$MSG\n");
  template_escape(no);
};

# Configuraci贸n de destino para escribir registros en archivos con nombre din谩mico
destination d_dyna_file {
  file(
    "/var/log/bunkerweb/${PROGRAM}.log"
    template(t_imp)
    owner("101")
    group("101")
    dir_owner("root")
    dir_group("101")
    perm(0440)
    dir_perm(0770)
    create_dirs(yes)
    logrotate(
      enable(yes),
      size(100MB),
      rotations(7)
    )
  );
};

# Ruta de registro para dirigir los registros a archivos con nombre din谩mico
log {
  source(s_net);
  destination(d_dyna_file);
};
```

## Buenas pr谩cticas de registro de Docker

Cuando se utiliza Docker, es importante gestionar los registros de los contenedores para evitar que consuman un espacio excesivo en el disco. Por defecto, Docker utiliza el controlador de registro `json-file`, lo que puede dar lugar a archivos de registro muy grandes si no se configura.

Para evitar esto, puede configurar la rotaci贸n de registros. Esto se puede hacer para servicios espec铆ficos en su archivo `docker-compose.yml`, o globalmente para el demonio de Docker.

**Configuraci贸n por servicio**

Puede configurar el controlador de registro para sus servicios en su archivo `docker-compose.yml` para rotar autom谩ticamente los registros. Aqu铆 hay un ejemplo que mantiene hasta 10 archivos de registro de 20 MB cada uno:

```yaml
services:
  bunkerweb:
    image: bunkerity/bunkerweb:1.6.6
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "10"
    ...
```

Esta configuraci贸n asegura que los registros se roten, evitando que llenen su disco. Puede aplicar esto a cualquier servicio en su configuraci贸n de Docker Compose.

**Configuraci贸n global (daemon.json)**

Si desea aplicar esta configuraci贸n de registro a todos los contenedores en el host por defecto, puede configurar el demonio de Docker editando (o creando) el archivo `/etc/docker/daemon.json`:

```json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "20m",
    "max-file": "10"
  }
}
```

Despu茅s de modificar `daemon.json`, debe reiniciar el demonio de Docker para que los cambios surtan efecto:

```shell
sudo systemctl restart docker
```

Esta configuraci贸n global ser谩 heredada por todos los contenedores. Sin embargo, cualquier configuraci贸n de registro definida por servicio en un archivo `docker-compose.yml` anular谩 la configuraci贸n global en `daemon.json`.

## Ajuste de seguridad {#security-tuning}

BunkerWeb ofrece muchas caracter铆sticas de seguridad que puedes configurar con [caracter铆sticas](features.md). Aunque los valores predeterminados de las configuraciones aseguran una "seguridad por defecto" m铆nima, te recomendamos encarecidamente que los ajustes. Al hacerlo, podr谩s asegurar el nivel de seguridad de tu elecci贸n y tambi茅n gestionar los falsos positivos.

!!! tip "Otras caracter铆sticas"
    Esta secci贸n solo se enfoca en el ajuste de seguridad, consulta la secci贸n de [caracter铆sticas](features.md) de la documentaci贸n para otras configuraciones.

<figure markdown>
  ![Descripci贸n general](assets/img/core-order.svg){ align=center }
  <figcaption>Descripci贸n general y orden de los plugins de seguridad principales</figcaption>
</figure>

## Integraci贸n con la Consola de CrowdSec

Si a煤n no est谩s familiarizado con la integraci贸n de la Consola de CrowdSec, [CrowdSec](https://www.crowdsec.net/?utm_campaign=bunkerweb&utm_source=doc) aprovecha la inteligencia de la comunidad para combatir las amenazas cibern茅ticas. Pi茅nsalo como el "Waze de la ciberseguridad"cuando un servidor es atacado, otros sistemas en todo el mundo son alertados y protegidos de los mismos atacantes. Puedes aprender m谩s sobre ello [aqu铆](https://www.crowdsec.net/about?utm_campaign=bunkerweb&utm_source=blog).

**隆Felicidades, tu instancia de BunkerWeb ahora est谩 inscrita en tu Consola de CrowdSec!**

Consejo profesional: Al ver tus alertas, haz clic en la opci贸n "columnas" y marca la casilla "contexto" para acceder a los datos espec铆ficos de BunkerWeb.

<figure markdown>
  ![Descripci贸n general](assets/img/crowdity4.png){ align=center }
  <figcaption>Datos de BunkerWeb mostrados en la columna de contexto</figcaption>
</figure>

## Monitoreo y reportes

### Monitoreo <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Soporte STREAM :x:

El plugin de monitoreo te permite recolectar y recuperar m茅tricas sobre BunkerWeb. Al habilitarlo, tu(s) instancia(s) comenzar谩(n) a recolectar varios datos relacionados con ataques, solicitudes y rendimiento. Luego puedes recuperarlos llamando al punto final de la API `/monitoring` de forma regular o usando otros plugins como el exportador de Prometheus.

**Lista de caracter铆sticas**

- Habilitar la recolecci贸n de varias m茅tricas de BunkerWeb
- Recuperar m茅tricas de la API
- Usar en combinaci贸n con otros plugins (p. ej. exportador de Prometheus)
- P谩gina de interfaz de usuario dedicada para monitorear tu(s) instancia(s)

**Lista de configuraciones**

| Configuraci贸n                  | Predeterminado | Contexto | M煤ltiple | Descripci贸n                                                  |
| ------------------------------ | -------------- | -------- | -------- | ------------------------------------------------------------ |
| `USE_MONITORING`               | `yes`          | global   | no       | Habilitar el monitoreo de BunkerWeb.                         |
| `MONITORING_METRICS_DICT_SIZE` | `10M`          | global   | no       | Tama帽o del diccionario para almacenar m茅tricas de monitoreo. |

### Exportador de Prometheus <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Soporte STREAM :x:

El plugin exportador de Prometheus agrega un [exportador de Prometheus](https://prometheus.io/docs/instrumenting/exporters/) en tu(s) instancia(s) de BunkerWeb. Cuando est谩 habilitado, puedes configurar tu(s) instancia(s) de Prometheus para que extraigan datos de un punto final espec铆fico en BunkerWeb y recopilen m茅tricas internas.

Tambi茅n proporcionamos un [panel de control de Grafana](https://grafana.com/grafana/dashboards/20755-bunkerweb/) que puedes importar en tu propia instancia y conectar a tu propia fuente de datos de Prometheus.

**Ten en cuenta que el uso del plugin exportador de Prometheus requiere habilitar el plugin de Monitoreo (`USE_MONITORING=yes`)**

**Lista de caracter铆sticas**

- Exportador de Prometheus que proporciona m茅tricas internas de BunkerWeb
- Puerto, IP de escucha y URL dedicados y configurables
- Lista blanca de IP/red para m谩xima seguridad

**Lista de configuraciones**

| Configuraci贸n                  | Predeterminado                                        | Contexto | M煤ltiple | Descripci贸n                                                                              |
| ------------------------------ | ----------------------------------------------------- | -------- | -------- | ---------------------------------------------------------------------------------------- |
| `USE_PROMETHEUS_EXPORTER`      | `no`                                                  | global   | no       | Habilitar el exportador de Prometheus.                                                   |
| `PROMETHEUS_EXPORTER_IP`       | `0.0.0.0`                                             | global   | no       | IP de escucha del exportador de Prometheus.                                              |
| `PROMETHEUS_EXPORTER_PORT`     | `9113`                                                | global   | no       | Puerto de escucha del exportador de Prometheus.                                          |
| `PROMETHEUS_EXPORTER_URL`      | `/metrics`                                            | global   | no       | URL HTTP del exportador de Prometheus.                                                   |
| `PROMETHEUS_EXPORTER_ALLOW_IP` | `127.0.0.0/8 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16` | global   | no       | Lista de IP/redes permitidas para contactar el punto final del exportador de Prometheus. |

### Reportes <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Soporte STREAM :x:

!!! warning "Plugin de monitoreo necesario"
  Este plugin requiere que el plugin de monitoreo Pro est茅 instalado y habilitado con la configuraci贸n `USE_MONITORING` establecida en `yes`.

El plugin de Reportes proporciona una soluci贸n integral para reportes regulares de datos importantes de BunkerWeb, incluyendo estad铆sticas globales, ataques, bloqueos, solicitudes, razones e informaci贸n de AS. Ofrece una amplia gama de caracter铆sticas, incluyendo creaci贸n autom谩tica de reportes, opciones de personalizaci贸n e integraci贸n perfecta con el plugin de monitoreo pro. Con el plugin de Reportes, puedes generar y gestionar f谩cilmente reportes para monitorear el rendimiento y la seguridad de tu aplicaci贸n.

**Lista de caracter铆sticas**

- Reportes regulares de datos importantes de BunkerWeb, incluyendo estad铆sticas globales, ataques, bloqueos, solicitudes, razones e informaci贸n de AS.
- Integraci贸n con el plugin de monitoreo Pro para una integraci贸n perfecta y capacidades de reporte mejoradas.
- Soporte para webhooks (cl谩sicos, Discord y Slack) para notificaciones en tiempo real.
- Soporte para SMTP para notificaciones por correo electr贸nico.
- Opciones de configuraci贸n para personalizaci贸n y flexibilidad.

**Lista de configuraciones**

| Configuraci贸n                  | Predeterminado     | Contexto | Descripci贸n                                                                                             |
| ------------------------------ | ------------------ | -------- | ------------------------------------------------------------------------------------------------------- |
| `USE_REPORTING_SMTP`           | `no`               | global   | Habilitar el env铆o del reporte por correo electr贸nico (HTML).                                           |
| `USE_REPORTING_WEBHOOK`        | `no`               | global   | Habilitar el env铆o del reporte por webhook (Markdown).                                                  |
| `REPORTING_SCHEDULE`           | `weekly`           | global   | Cadencia del reporte: `daily`, `weekly` o `monthly`.                                                    |
| `REPORTING_WEBHOOK_URLS`       |                    | global   | URLs de webhook separadas por espacios; Discord y Slack se detectan autom谩ticamente.                    |
| `REPORTING_SMTP_EMAILS`        |                    | global   | Destinatarios de correo electr贸nico separados por espacios.                                             |
| `REPORTING_SMTP_HOST`          |                    | global   | Nombre de host o IP del servidor SMTP.                                                                  |
| `REPORTING_SMTP_PORT`          | `465`              | global   | Puerto SMTP. Usa `465` para SSL, `587` para TLS.                                                        |
| `REPORTING_SMTP_FROM_EMAIL`    |                    | global   | Direcci贸n del remitente (desactiva 2FA si es requerido por tu proveedor).                               |
| `REPORTING_SMTP_FROM_USER`     |                    | global   | Nombre de usuario SMTP (recurre al correo del remitente cuando se omite y se establece una contrase帽a). |
| `REPORTING_SMTP_FROM_PASSWORD` |                    | global   | Contrase帽a SMTP.                                                                                        |
| `REPORTING_SMTP_SSL`           | `SSL`              | global   | Seguridad de conexi贸n: `no`, `SSL` o `TLS`.                                                             |
| `REPORTING_SMTP_SUBJECT`       | `BunkerWeb Report` | global   | L铆nea de asunto para entregas por correo electr贸nico.                                                   |

!!! info "Notas de comportamiento"
  - `REPORTING_SMTP_EMAILS` es requerido cuando la entrega SMTP est谩 habilitada; `REPORTING_WEBHOOK_URLS` es requerido cuando la entrega por webhook est谩 habilitada.
  - Si tanto los webhooks como SMTP fallan, la entrega se reintenta en la pr贸xima ejecuci贸n programada.
  - Las plantillas HTML y Markdown se encuentran en `reporting/files/`; personal铆zalas con precauci贸n para mantener los marcadores de posici贸n intactos.

## Copia de seguridad y restauraci贸n

### Copia de seguridad S3 <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Soporte STREAM :white_check_mark:

La herramienta de Copia de seguridad S3 automatiza sin problemas la protecci贸n de datos, de forma similar al plugin de copia de seguridad de la comunidad. Sin embargo, se destaca por almacenar de forma segura las copias de seguridad directamente en un bucket S3.

Al activar esta funci贸n, est谩s salvaguardando proactivamente la **integridad de tus datos**. Almacenar las copias de seguridad de forma **remota** protege la informaci贸n crucial de amenazas como **fallos de hardware**, **ciberataques** o **desastres naturales**. Esto garantiza tanto la **seguridad** como la **disponibilidad**, permitiendo una r谩pida recuperaci贸n durante **eventos inesperados**, preservando la **continuidad operativa** y asegurando la **tranquilidad**.

??? warning "Informaci贸n para usuarios de Red Hat Enterprise Linux (RHEL) 8.9"
    Si est谩s utilizando **RHEL 8.9** y planeas usar una **base de datos externa**, necesitar谩s instalar el paquete `mysql-community-client` para asegurar que el comando `mysqldump` est茅 disponible. Puedes instalar el paquete ejecutando los siguientes comandos:

    === "MySQL/MariaDB"

        1. **Instalar el paquete de configuraci贸n del repositorio de MySQL**

            ```bash
            sudo dnf install https://dev.mysql.com/get/mysql80-community-release-el8-9.noarch.rpm
            ```

        2. **Habilitar el repositorio de MySQL**

            ```bash
            sudo dnf config-manager --enable mysql80-community
            ```

        3. **Instalar el cliente de MySQL**

            ```bash
            sudo dnf install mysql-community-client
            ```

    === "PostgreSQL"

        1. **Instalar el paquete de configuraci贸n del repositorio de PostgreSQL**

            ```bash
            dnf install "https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-$(uname -m)/pgdg-redhat-repo-latest.noarch.rpm"
            ```

        2. **Instalar el cliente de PostgreSQL**

            ```bash
            dnf install postgresql<version>
            ```

**Lista de caracter铆sticas**

- Copia de seguridad autom谩tica de datos a un bucket S3
- Opciones de programaci贸n flexibles: diaria, semanal o mensual
- Gesti贸n de rotaci贸n para controlar el n煤mero de copias de seguridad a mantener
- Nivel de compresi贸n personalizable para los archivos de copia de seguridad

**Lista de configuraciones**

| Configuraci贸n                 | Predeterminado | Contexto | Descripci贸n                                                     |
| ----------------------------- | -------------- | -------- | --------------------------------------------------------------- |
| `USE_BACKUP_S3`               | `no`           | global   | Habilitar o deshabilitar la funci贸n de copia de seguridad S3    |
| `BACKUP_S3_SCHEDULE`          | `daily`        | global   | La frecuencia de la copia de seguridad                          |
| `BACKUP_S3_ROTATION`          | `7`            | global   | El n煤mero de copias de seguridad a mantener                     |
| `BACKUP_S3_ENDPOINT`          |                | global   | El punto final S3                                               |
| `BACKUP_S3_BUCKET`            |                | global   | El bucket S3                                                    |
| `BACKUP_S3_DIR`               |                | global   | El directorio S3                                                |
| `BACKUP_S3_REGION`            |                | global   | La regi贸n S3                                                    |
| `BACKUP_S3_ACCESS_KEY_ID`     |                | global   | El ID de la clave de acceso S3                                  |
| `BACKUP_S3_ACCESS_KEY_SECRET` |                | global   | El secreto de la clave de acceso S3                             |
| `BACKUP_S3_COMP_LEVEL`        | `6`            | global   | El nivel de compresi贸n del archivo zip de la copia de seguridad |

#### Copia de seguridad manual

Para iniciar manualmente una copia de seguridad, ejecuta el siguiente comando:

=== "Linux"

    ```bash
    bwcli plugin backup_s3 save
    ```

=== "Docker"

    ```bash
    docker exec -it <scheduler_container> bwcli plugin backup_s3 save
    ```

Este comando crear谩 una copia de seguridad de tu base de datos y la almacenar谩 en el bucket S3 especificado en la configuraci贸n `BACKUP_S3_BUCKET`.

Tambi茅n puedes especificar un bucket S3 personalizado para la copia de seguridad proporcionando la variable de entorno `BACKUP_S3_BUCKET` al ejecutar el comando:

=== "Linux"

    ```bash
    BACKUP_S3_BUCKET=your-bucket-name bwcli plugin backup_s3 save
    ```

=== "Docker"

    ```bash
    docker exec -it -e BACKUP_S3_BUCKET=your-bucket-name <scheduler_container> bwcli plugin backup_s3 save
    ```

!!! note "Especificaciones para MariaDB/MySQL"

    En caso de que est茅s usando MariaDB/MySQL, puedes encontrar el siguiente error al intentar hacer una copia de seguridad de tu base de datos:

    ```bash
    caching_sha2_password could not be loaded: Error loading shared library /usr/lib/mariadb/plugin/caching_sha2_password.so
    ```

    Para resolver este problema, puedes ejecutar el siguiente comando para cambiar el plugin de autenticaci贸n a `mysql_native_password`:

    ```sql
    ALTER USER 'yourusername'@'localhost' IDENTIFIED WITH mysql_native_password BY 'youpassword';
    ```

    Si est谩s usando la integraci贸n de Docker, puedes agregar el siguiente comando al archivo `docker-compose.yml` para cambiar autom谩ticamente el plugin de autenticaci贸n:

    === "MariaDB"

        ```yaml
        bw-db:
            image: mariadb:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

    === "MySQL"

        ```yaml
        bw-db:
            image: mysql:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

#### Restauraci贸n manual

Para iniciar manualmente una restauraci贸n, ejecuta el siguiente comando:

=== "Linux"

    ```bash
    bwcli plugin backup_s3 restore
    ```

=== "Docker"

    ```bash
    docker exec -it <scheduler_container> bwcli plugin backup_s3 restore
    ```

Este comando crear谩 una copia de seguridad temporal de tu base de datos en el bucket S3 especificado en la configuraci贸n `BACKUP_S3_BUCKET` y restaurar谩 tu base de datos a la 煤ltima copia de seguridad disponible en el bucket.

Tambi茅n puedes especificar un archivo de copia de seguridad personalizado para la restauraci贸n proporcionando la ruta al mismo como argumento al ejecutar el comando:

=== "Linux"

    ```bash
    bwcli plugin backup_s3 restore s3_backup_file.zip
    ```

=== "Docker"

    ```bash
    docker exec -it <scheduler_container> bwcli plugin backup restore s3_backup_file.zip
    ```

!!! example "En caso de fallo"

    No te preocupes si la restauraci贸n falla, siempre puedes restaurar tu base de datos al estado anterior ejecutando el comando de nuevo, ya que se crea una copia de seguridad antes de la restauraci贸n:

    === "Linux"

        ```bash
        bwcli plugin backup_s3 restore
        ```

    === "Docker"

        ```bash
        docker exec -it <scheduler_container> bwcli plugin backup_s3 restore
        ```

## Migraci贸n <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Soporte STREAM :white_check_mark:

El plugin de Migraci贸n **revoluciona** las transferencias de configuraci贸n de BunkerWeb entre instancias con su **interfaz web f谩cil de usar**, simplificando todo el proceso de migraci贸n. Ya sea que est茅s actualizando sistemas, escalando la infraestructura o haciendo la transici贸n de entornos, esta herramienta te permite transferir sin esfuerzo **configuraciones, preferencias y datos** con una facilidad y confianza inigualables. Di adi贸s a los engorrosos procesos manuales y hola a una **experiencia de migraci贸n fluida y sin complicaciones**.

**Lista de caracter铆sticas**

- **Migraci贸n sin esfuerzo:** Transfiere f谩cilmente las configuraciones de BunkerWeb entre instancias sin las complejidades de los procedimientos manuales.

- **Interfaz web intuitiva:** Navega por el proceso de migraci贸n sin esfuerzo con una interfaz web f谩cil de usar dise帽ada para una operaci贸n intuitiva.

- **Compatibilidad entre bases de datos:** Disfruta de una migraci贸n fluida a trav茅s de varias plataformas de bases de datos, incluidas SQLite, MySQL, MariaDB y PostgreSQL, lo que garantiza la compatibilidad con tu entorno de base de datos preferido.

### Crear un archivo de migraci贸n

Para crear manualmente un archivo de migraci贸n, ejecuta el siguiente comando:

=== "Linux"

    ```bash
    bwcli plugin migration create /path/to/migration/file
    ```

=== "Docker"

    1. Crear un archivo de migraci贸n:

        ```bash
        docker exec -it <scheduler_container> bwcli plugin migration create /path/to/migration/file
        ```

    2. Copiar el archivo de migraci贸n a tu m谩quina local:

        ```bash
        docker cp <scheduler_container>:/path/to/migration/file /path/to/migration/file
        ```

Este comando crear谩 una copia de seguridad de tu base de datos y la almacenar谩 en el directorio de copia de seguridad especificado en el comando.

!!! note "Especificaciones para MariaDB/MySQL"

    En caso de que est茅s usando MariaDB/MySQL, puedes encontrar el siguiente error al intentar hacer una copia de seguridad de tu base de datos:

    ```bash
    caching_sha2_password could not be loaded: Error loading shared library /usr/lib/mariadb/plugin/caching_sha2_password.so
    ```

    Para resolver este problema, puedes ejecutar el siguiente comando para cambiar el plugin de autenticaci贸n a `mysql_native_password`:

    ```sql
    ALTER USER 'yourusername'@'localhost' IDENTIFIED WITH mysql_native_password BY 'youpassword';
    ```

    Si est谩s usando la integraci贸n de Docker, puedes agregar el siguiente comando al archivo `docker-compose.yml` para cambiar autom谩ticamente el plugin de autenticaci贸n:

    === "MariaDB"

        ```yaml
        bw-db:
            image: mariadb:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

    === "MySQL"

        ```yaml
        bw-db:
            image: mysql:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

### Iniciar una migraci贸n

Para iniciar manualmente una migraci贸n, ejecuta el siguiente comando:

=== "Linux"

    ```bash
    bwcli plugin migration migrate /path/to/migration/file
    ```

=== "Docker"

    1. Copia el archivo de migraci贸n al contenedor:

        ```bash
        docker cp /path/to/migration/file <scheduler_container>:/path/to/migration/file
        ```

    2. Inicia la migraci贸n:

        ```bash
        docker exec -it <scheduler_container> bwcli plugin migration migrate /path/to/migration/file
        ```

=== "Todo en uno"

    1. Copia el archivo de migraci贸n al contenedor:

        ```bash
        docker cp /path/to/migration/file bunkerweb-aio:/path/to/migration/file
        ```

    2. Inicia la migraci贸n:

        ```bash
        docker exec -it bunkerweb-aio bwcli plugin migration migrate /path/to/migration/file
        ```

Este comando migra sin problemas tus datos de BunkerWeb para que coincidan precisamente con la configuraci贸n descrita en el archivo de migraci贸n.

## Anti DDoS <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Soporte STREAM :x:

El plugin **Anti DDoS** proporciona protecci贸n avanzada contra ataques de denegaci贸n de servicio distribuido (DDoS) mediante el monitoreo, an谩lisis y filtrado de tr谩fico sospechoso en tiempo real.

Mediante el empleo de un **mecanismo de ventana deslizante**, el plugin mantiene un diccionario en memoria de las marcas de tiempo de las solicitudes para detectar picos de tr谩fico anormales de direcciones IP individuales. Seg煤n el modo de seguridad configurado, puede bloquear las conexiones ofensivas o registrar la actividad sospechosa para una revisi贸n posterior.

### Caracter铆sticas

- **An谩lisis de tr谩fico en tiempo real:** Monitorea continuamente las solicitudes entrantes para detectar posibles ataques DDoS.
- **Mecanismo de ventana deslizante:** Rastrea la actividad de solicitudes recientes dentro de una ventana de tiempo configurable.
- **Umbrales configurables:** Te permite definir el n煤mero m谩ximo de solicitudes sospechosas por IP.
- **L贸gica de bloqueo avanzada:** Eval煤a tanto el recuento de solicitudes por IP como el n煤mero de IP distintas que superan el umbral.
- **Modos de seguridad flexibles:** Elige entre el bloqueo inmediato de la conexi贸n o el modo de solo detecci贸n (registro).
- **Almac茅n de datos en memoria optimizado:** Garantiza b煤squedas de alta velocidad y un seguimiento eficiente de las m茅tricas.
- **Mantenimiento autom谩tico:** Borra peri贸dicamente los datos obsoletos para mantener un rendimiento 贸ptimo.

### Configuraci贸n

Personaliza el comportamiento del plugin usando las siguientes configuraciones:

| Configuraci贸n                | Predeterminado | Contexto | M煤ltiple | Descripci贸n                                                                                             |
| ---------------------------- | -------------- | -------- | -------- | ------------------------------------------------------------------------------------------------------- |
| `USE_ANTIDDOS`               | `no`           | global   | no       | Habilita o deshabilita la protecci贸n Anti DDoS. Establ茅celo en `"yes"` para activar el plugin.          |
| `ANTIDDOS_METRICS_DICT_SIZE` | `10M`          | global   | no       | Tama帽o del almac茅n de datos en memoria para el seguimiento de m茅tricas de DDoS (p. ej., `10M`, `500k`). |
| `ANTIDDOS_THRESHOLD`         | `100`          | global   | no       | N煤mero m谩ximo de solicitudes sospechosas permitidas por IP dentro de la ventana de tiempo definida.     |
| `ANTIDDOS_WINDOW_TIME`       | `10`           | global   | no       | Ventana de tiempo en segundos durante la cual se cuentan las solicitudes sospechosas.                   |
| `ANTIDDOS_STATUS_CODES`      | `429 403 444`  | global   | no       | C贸digos de estado HTTP considerados sospechosos y utilizados para activar acciones anti-DDoS.           |
| `ANTIDDOS_DISTINCT_IP`       | `5`            | global   | no       | N煤mero m铆nimo de IP distintas que deben superar el umbral antes de aplicar el modo de bloqueo.          |

### Mejores pr谩cticas

- **Ajuste de umbrales:** Ajusta `ANTIDDOS_THRESHOLD` y `ANTIDDOS_WINDOW_TIME` seg煤n tus patrones de tr谩fico t铆picos.
- **Revisi贸n de c贸digos de estado:** Actualiza regularmente `ANTIDDOS_STATUS_CODES` para capturar comportamientos sospechosos nuevos o en evoluci贸n.
- **Monitoreo:** Analiza los registros y las m茅tricas peri贸dicamente para ajustar la configuraci贸n y mejorar la protecci贸n general.

## Administrador de usuarios <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

<p align="center">
    <iframe style="display: block;" width="560" height="315" data-src="https://www.youtube-nocookie.com/embed/EIohiUf9Fg4" title="P谩gina del Administrador de usuarios" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

El Plugin de gesti贸n de usuarios ofrece una interfaz robusta para administrar cuentas de usuario dentro de tu sistema.

Con este plugin, los administradores pueden crear, actualizar y deshabilitar cuentas de usuario sin esfuerzo, gestionar roles de usuario, activar o desactivar la autenticaci贸n de dos factores (2FA) y ver informaci贸n detallada del usuario, como las marcas de tiempo del 煤ltimo inicio de sesi贸n y los estados de la cuenta (activa o inactiva). Dise帽ado teniendo en cuenta la seguridad y la facilidad de uso, este plugin simplifica las tareas rutinarias de gesti贸n de usuarios al tiempo que garantiza el cumplimiento y la auditabilidad.

### Caracter铆sticas

- **Operaciones de cuenta de usuario:** Importar en formato CSV/XSLX, crear, editar y eliminar cuentas de usuario con facilidad.
- **Control de acceso basado en roles:** Asigna y modifica roles de usuario para gestionar permisos y niveles de acceso.
- **Gesti贸n de 2FA:** Desactiva la autenticaci贸n de dos factores seg煤n las decisiones administrativas.
- **Informaci贸n completa del usuario:** Supervisa los datos clave del usuario, incluidas las 煤ltimas horas de inicio de sesi贸n, las fechas de creaci贸n de la cuenta y el estado activo/inactivo.
- **Registro de auditor铆a:** Mantiene un registro de auditor铆a de todas las acciones de gesti贸n de usuarios para mejorar la seguridad y el cumplimiento.

<figure markdown>
  ![Descripci贸n general](assets/img/user-manager.png){ align=center }
  <figcaption>P谩gina del Administrador de usuarios</figcaption>
</figure>

<figure markdown>
  ![Formulario de creaci贸n de usuario](assets/img/user-manager-create.png){ align=center }
  <figcaption>Administrador de usuarios - Formulario de creaci贸n de usuario</figcaption>
</figure>

<figure markdown>
  ![P谩gina de actividades](assets/img/user-manager-activities.png){ align=center }
  <figcaption>Administrador de usuarios - P谩gina de actividades</figcaption>
</figure>

## Easy Resolve <img src='../../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

El plugin Easy Resolve te permite remediar r谩pidamente falsos positivos y problemas recurrentes directamente desde la p谩gina de Informes. Convierte las acciones guiadas de "Resolver" en actualizaciones de configuraci贸n seguras y acotadas, sin edici贸n manual.

### Caracter铆sticas

- Acciones con un solo clic desde Informes y detalles del informe.
- Sugerencias contextuales para ModSecurity, lista negra y DNSBL.
- Genera exclusiones seguras de ModSecurity o actualiza las listas de ignorados.
- Aplica cambios a nivel de servicio o global con comprobaciones de permisos.
- Apertura autom谩tica opcional de la p谩gina de configuraci贸n relacionada despu茅s de aplicar.

<figure markdown>
  ![Descripci贸n general](assets/img/easy-resolve.png){ align=center }
  <figcaption>P谩gina de informes - con Easy Resolve</figcaption>
</figure>

<div class="grid grid-2" markdown>
<figure markdown>
  ![Resoluci贸n de ModSecurity](assets/img/easy-resolve-modsecurity.png){ width="100%" }
  <figcaption>Resoluci贸n de ModSecurity</figcaption>
</figure>
<figure markdown>
  ![Resoluci贸n de DNSBL](assets/img/easy-resolve-dnsbl.png){ width="100%" }
  <figcaption>Resoluci贸n de DNSBL</figcaption>
</figure>
</div>

<div class="grid grid-5" markdown>
<figure markdown>
  ![Resoluci贸n de lista negra - IP](assets/img/easy-resolve-blacklist-ip.png){ width="100%" }
  <figcaption>Lista negra - IP</figcaption>
</figure>
<figure markdown>
  ![Resoluci贸n de lista negra - User-Agent](assets/img/easy-resolve-blacklist-ua.png){ width="100%" }
  <figcaption>Lista negra - User-Agent</figcaption>
</figure>
<figure markdown>
  ![Resoluci贸n de lista negra - rDNS](assets/img/easy-resolve-blacklist-rdns.png){ width="100%" }
  <figcaption>Lista negra - rDNS</figcaption>
</figure>
<figure markdown>
  ![Resoluci贸n de lista negra - ASN](assets/img/easy-resolve-blacklist-asn.png){ width="100%" }
  <figcaption>Lista negra - ASN</figcaption>
</figure>
<figure markdown>
  ![Resoluci贸n de lista negra - URI](assets/img/easy-resolve-blacklist-uri.png){ width="100%" }
  <figcaption>Lista negra - URI</figcaption>
</figure>
</div>

## Load Balancer <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

<p align="center">
    <iframe style="display: block;" width="560" height="315" data-src="https://www.youtube-nocookie.com/embed/cOVp0rAt5nw?si=iVhDio8o8S4F_uag" title="Load Balancer" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

El Plugin de Load Balancer convierte BunkerWeb en un director de tr谩fico con guardarra铆les. Declare pools upstream una vez, apunte su proxy inverso a ellos, y deje que el balanceo consciente de salud mantenga a los usuarios en backends responsivos. El modo sticky cookie emite autom谩ticamente una cookie `BWLBID` para que las sesiones se mantengan ancladas donde quiera.

### Caracter铆sticas

- Bloques por upstream: nombre pools y reutil铆celos en hosts de proxy inverso.
- Balanceo flexible: round-robin por defecto, o sticky v铆a IP o cookie firmado.
- Objetivos inteligentes: resoluci贸n DNS opcional para backends de hostname m谩s ajuste de keepalive.
- Salud integrada: sondas HTTP/HTTPS con rutas personalizadas, intervalos, c贸digos de estado y verificaciones SSL.
- Continuidad de sesi贸n: cookie `BWLBID` autom谩tica cuando se habilita el modo sticky-cookie.

### Configuraci贸n

**Definici贸n de upstream**

| Configuraci贸n                             | Predeterminado | Contexto | M煤ltiple | Descripci贸n                                                                             |
| ----------------------------------------- | -------------- | -------- | -------- | --------------------------------------------------------------------------------------- |
| `LOADBALANCER_UPSTREAM_NAME`              |                | global   | s铆       | Identificador upstream (referenciado por `REVERSE_PROXY_HOST`).                         |
| `LOADBALANCER_UPSTREAM_SERVERS`           |                | global   | s铆       | Lista separada por espacios de direcciones backend (ej. `10.0.0.1:8080 10.0.0.2:8080`). |
| `LOADBALANCER_UPSTREAM_MODE`              | `round-robin`  | global   | s铆       | Estrategia de balanceo (`round-robin` o `sticky`).                                      |
| `LOADBALANCER_UPSTREAM_STICKY_METHOD`     | `ip`           | global   | s铆       | M茅todo sticky (`ip` o `cookie`). Modo cookie emite `BWLBID`.                            |
| `LOADBALANCER_UPSTREAM_RESOLVE`           | `no`           | global   | s铆       | Resolver hostnames upstream v铆a DNS.                                                    |
| `LOADBALANCER_UPSTREAM_KEEPALIVE`         |                | global   | s铆       | Conexiones keepalive por worker.                                                        |
| `LOADBALANCER_UPSTREAM_KEEPALIVE_TIMEOUT` | `60s`          | global   | s铆       | Timeout inactivo para conexiones keepalive.                                             |
| `LOADBALANCER_UPSTREAM_KEEPALIVE_TIME`    | `1h`           | global   | s铆       | Vida m谩xima para conexiones keepalive.                                                  |

**Verificaciones de salud**

| Configuraci贸n                             | Predeterminado | Contexto | M煤ltiple | Descripci贸n                                                            |
| ----------------------------------------- | -------------- | -------- | -------- | ---------------------------------------------------------------------- |
| `LOADBALANCER_HEALTHCHECK_DICT_SIZE`      | `10m`          | global   | no       | Tama帽o de diccionario compartido para estado de verificaci贸n de salud. |
| `LOADBALANCER_HEALTHCHECK_URL`            | `/status`      | global   | s铆       | Ruta para sondear en cada backend.                                     |
| `LOADBALANCER_HEALTHCHECK_INTERVAL`       | `2000`         | global   | s铆       | Intervalo entre verificaciones (ms).                                   |
| `LOADBALANCER_HEALTHCHECK_TIMEOUT`        | `1000`         | global   | s铆       | Timeout por verificaci贸n (ms).                                         |
| `LOADBALANCER_HEALTHCHECK_FALL`           | `3`            | global   | s铆       | Fallos consecutivos antes de marcar como down.                         |
| `LOADBALANCER_HEALTHCHECK_RISE`           | `1`            | global   | s铆       | xitos consecutivos antes de marcar como up.                           |
| `LOADBALANCER_HEALTHCHECK_VALID_STATUSES` | `200`          | global   | s铆       | Lista separada por espacios de c贸digos de estado HTTP v谩lidos.         |
| `LOADBALANCER_HEALTHCHECK_CONCURRENCY`    | `10`           | global   | s铆       | M谩ximo de sondas concurrentes.                                         |
| `LOADBALANCER_HEALTHCHECK_TYPE`           | `http`         | global   | s铆       | Protocolo para verificaciones de salud (`http` o `https`).             |
| `LOADBALANCER_HEALTHCHECK_SSL_VERIFY`     | `yes`          | global   | s铆       | Verificar certificados TLS al usar verificaciones HTTPS.               |
| `LOADBALANCER_HEALTHCHECK_HOST`           |                | global   | s铆       | Sobrescribir header Host durante verificaciones (煤til para SNI).       |

### Inicio r谩pido

1. Defina su pool: configure `LOADBALANCER_UPSTREAM_NAME=my-app` y liste objetivos en `LOADBALANCER_UPSTREAM_SERVERS` (ej. `10.0.0.1:8080 10.0.0.2:8080`).
2. Dirija tr谩fico: configure `REVERSE_PROXY_HOST=http://my-app` para que el proxy inverso use el upstream nombrado.
3. Elija un modo: mantenga round-robin por defecto o configure `LOADBALANCER_UPSTREAM_MODE=sticky` con `LOADBALANCER_UPSTREAM_STICKY_METHOD=cookie` o `ip`.
4. Agregue salud: mantenga `/status` o ajuste URLs, intervalos y estados v谩lidos para reflejar el comportamiento de su app.
5. Ajuste conexiones: configure valores keepalive para reutilizar conexiones backend y reducir sobrecarga de handshake.

### Consejos de uso

- Haga coincidir `REVERSE_PROXY_HOST` con `LOADBALANCER_UPSTREAM_NAME` al usar cookies sticky para que los clientes se fijen al pool correcto.
- Mantenga intervalos y timeouts de verificaci贸n de salud balanceados para evitar fluctuaciones en enlaces lentos.
- Habilite `LOADBALANCER_UPSTREAM_RESOLVE` cuando apunte a hostnames que puedan cambiar v铆a DNS.
- Ajuste valores keepalive para reflejar capacidad backend y objetivos de reutilizaci贸n de conexiones.
