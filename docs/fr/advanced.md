# Utilisations avanc√©es

De nombreux exemples de cas d'utilisation concrets sont disponibles dans le dossier [examples](https://github.com/bunkerity/bunkerweb/tree/v1.6.5-rc1/examples) du d√©p√¥t GitHub.

Nous fournissons √©galement de nombreux mod√®les standard, tels que des fichiers YAML pour diverses int√©grations et types de bases de donn√©es. Ceux-ci sont disponibles dans le dossier [misc/integrations](https://github.com/bunkerity/bunkerweb/tree/v1.6.5-rc1/misc/integrations).

Cette section se concentre uniquement sur les utilisations avanc√©es et le r√©glage de la s√©curit√©, consultez la [section fonctionnalit√©s](features.md) de la documentation pour voir tous les param√®tres disponibles.

## Cas d'utilisation

!!! tip "Tester"
    Pour effectuer des tests rapides lorsque le mode multisite est activ√© (et si vous n'avez pas les bonnes entr√©es DNS configur√©es pour les domaines), vous pouvez utiliser curl avec l'en-t√™te HTTP Host de votre choix :
    ```shell
    curl -H "Host: app1.example.com" http://ip-or-fqdn-of-server
    ```

    Si vous utilisez HTTPS, vous devrez configurer le SNI :
    ```shell
    curl -H "Host: app1.example.com" --resolve example.com:443:ip-of-server https://example.com
    ```

### Derri√®re l'√©quilibreur de charge ou le proxy inverse

!!! info "Real IP"

    Lorsque BunkerWeb se trouve lui‚Äëm√™me derri√®re un √©quilibreur de charge ou un proxy inverse, vous devez le configurer afin qu'il puisse r√©cup√©rer la v√©ritable adresse IP des clients. **Si vous ne le faites pas, les fonctionnalit√©s de s√©curit√© bloqueront l'adresse IP de l'√©quilibreur de charge ou du proxy inverse au lieu de celle du client.**

BunkerWeb prend en fait en charge deux m√©thodes pour r√©cup√©rer l'adresse IP r√©elle du client :

- √Ä l'aide de l'ic√¥ne `PROXY protocol`
- √Ä l'aide d'un en-t√™te HTTP tel que `X-Forwarded-For`

Les param√®tres suivants peuvent √™tre utilis√©s :

- `USE_REAL_IP` : activer/d√©sactiver la r√©cup√©ration d'IP r√©elle
- `USE_PROXY_PROTOCOL` : activer/d√©sactiver la prise en charge du protocole PROXY.
- `REAL_IP_FROM` : liste d'adresses IP/r√©seau de confiance autoris√©es pour nous envoyer la "vraie IP"
- `REAL_IP_HEADER` : l'en-t√™te HTTP contenant l'IP r√©elle ou la valeur sp√©ciale `proxy_protocol` lors de l'utilisation du protocole PROXY

Vous trouverez plus de param√®tres sur l'IP r√©elle dans la [section des fonctionnalit√©s](features.md#real-ip) de la documentation.

=== "En-t√™te HTTP"

    Nous supposerons ce qui suit concernant les √©quilibreurs de charge ou les proxies inverses (vous devrez mettre √† jour les param√®tres en fonction de votre configuration) :

    - Ils utilisent l' `X-Forwarded-For` en-t√™te pour d√©finir l'adresse IP r√©elle
    - Ils ont des adresses IP dans les `1.2.3.0/24` r√©seaux`100.64.0.0/10` et

    === "Interface utilisateur Web"

        Acc√©dez √† la page **Config Globale**, s√©lectionnez le plugin **Real IP** et renseignez les param√®tres suivants :

        <figure markdown>![Param√®tres Real IP (en-t√™te) via l'interface Web](assets/img/advanced-proxy1.png){ align=center }<figcaption>Param√®tres Real IP (en-t√™te) via l'interface Web</figcaption></figure>

        Veuillez noter qu'il est recommand√© de red√©marrer BunkerWeb lorsque vous modifiez des param√®tres li√©s √† la r√©cup√©ration de la vraie adresse IP.

    === "Linux"

        Vous devrez ajouter ces param√®tres au fichier /etc/bunkerweb/variables.env :

        ```conf
        ...
        USE_REAL_IP=yes
        REAL_IP_FROM=1.2.3.0/24 100.64.0.0/16
        REAL_IP_HEADER=X-Forwarded-For
        ...
        ```

        Veuillez noter qu'il est recommand√© de red√©marrer plut√¥t que de recharger le service lorsque vous modifiez les param√®tres li√©s √† la r√©cup√©ration de la vraie adresse IP :

        ```shell
        sudo systemctl restart bunkerweb && \
        sudo systemctl restart bunkerweb-scheduler
        ```

    === "Tout-en-un"

        Vous devrez ajouter ces param√®tres aux variables d'environnement lors de l'ex√©cution du conteneur All-in-one :

        ```bash
        docker run -d \
            --name bunkerweb-aio \
            -v bw-storage:/data \
            -e USE_REAL_IP="yes" \
            -e REAL_IP_FROM="1.2.3.0/24 100.64.0.0/10" \
            -e REAL_IP_HEADER="X-Forwarded-For" \
            -p 80:8080/tcp \
            -p 443:8443/tcp \
            -p 443:8443/udp \
            bunkerity/bunkerweb-all-in-one:1.6.5-rc1
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

    === "Docker"

        Vous devrez ajouter ces param√®tres aux variables d'environnement des conteneurs BunkerWeb et du Scheduler :

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

    === "Docker autoconf"

        Vous devrez ajouter ces param√®tres aux variables d'environnement des conteneurs BunkerWeb et du Scheduler :

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

    === "Kubernetes"

        Vous devrez ajouter ces param√®tres aux variables d'environnement des pods BunkerWeb et du Scheduler.

        Voici la partie correspondante de votre fichier `values.yaml` que vous pouvez utiliser :

        ```yaml
        bunkerweb:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "X-Forwarded-For"
        scheduler:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "X-Forwarded-For"
        ```

    === "Swarm"

        !!! warning "Obsol√®te"
            L'int√©gration Swarm est obsol√®te et sera supprim√©e dans une future version. Veuillez envisager d'utiliser l'[int√©gration Kubernetes](integrations.md#kubernetes) √† la place.

            **Plus d'informations sont disponibles dans la [documentation de l'int√©gration Swarm](integrations.md#swarm).**

        Vous devrez ajouter ces param√®tres aux variables d'environnement des services BunkerWeb et scheduler :

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "X-Forwarded-For"
          ...
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

=== "Protocole proxy"

    !!! warning "Lire attentivement"

      N'utilisez le protocole `PROXY protocol` que si vous √™tes certain que votre √©quilibreur de charge ou proxy inverse l'envoie. **Si vous l'activez et qu'il n'est pas utilis√©, vous obtiendrez des erreurs**.

    Nous supposerons ce qui suit concernant les √©quilibreurs de charge ou les proxies inverses (vous devrez adapter les param√®tres en fonction de votre configuration) :

    - Ils utilisent le `PROXY protocol` v1 ou v2 pour d√©finir l'adresse IP r√©elle
    - Ils ont des adresses IP dans les r√©seaux `1.2.3.0/24` et `100.64.0.0/10`

    === "Interface utilisateur Web"

        Acc√©dez √† la page **Config Globale**, s√©lectionnez le plugin **Real IP** et renseignez les param√®tres suivants :

        <figure markdown>![Param√®tres Real IP (protocole PROXY) via l'interface Web](assets/img/advanced-proxy2.png){ align=center }<figcaption>Param√®tres Real IP (protocole PROXY) via l'interface Web</figcaption></figure>

        Veuillez noter qu'il est recommand√© de red√©marrer BunkerWeb lorsque vous modifiez des param√®tres li√©s √† la r√©cup√©ration de la vraie adresse IP.

    === "Linux"

        Vous devrez ajouter ces param√®tres au fichier /etc/bunkerweb/variables.env :

        ```conf
        ...
        USE_REAL_IP=yes
        USE_PROXY_PROTOCOL=yes
        REAL_IP_FROM=1.2.3.0/24 100.64.0.0/16
        REAL_IP_HEADER=proxy_protocol
        ...
        ```

        Veuillez noter qu'il est recommand√© de red√©marrer plut√¥t que de recharger le service lors de la configuration des param√®tres li√©s au protocole PROXY :

        ```shell
        sudo systemctl restart bunkerweb && \
        sudo systemctl restart bunkerweb-scheduler
        ```

    === "Tout-en-un"

        Vous devrez ajouter ces param√®tres aux variables d'environnement lors de l'ex√©cution du conteneur All-in-one :

        ```bash
        docker run -d \
            --name bunkerweb-aio \
            -v bw-storage:/data \
            -e USE_REAL_IP="yes" \
            -e USE_PROXY_PROTOCOL="yes" \
            -e REAL_IP_FROM="1.2.3.0/24 100.64.0.0/10" \
            -e REAL_IP_HEADER="X-Forwarded-For" \
            -p 80:8080/tcp \
            -p 443:8443/tcp \
            -p 443:8443/udp \
            bunkerity/bunkerweb-all-in-one:1.6.5-rc1
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

    === "Docker"

        Vous devrez ajouter ces param√®tres aux variables d'environnement des conteneurs BunkerWeb et du Scheduler :

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

    === "Docker autoconf"

        Vous devrez ajouter ces param√®tres aux variables d'environnement des conteneurs BunkerWeb et du Scheduler :

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

    === "Kubernetes"

        Vous devrez ajouter ces param√®tres aux variables d'environnement des pods BunkerWeb et du Scheduler.

        Voici la partie correspondante de votre fichier `values.yaml` que vous pouvez utiliser :

        ```yaml
        bunkerweb:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: USE_PROXY_PROTOCOL
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "proxy_protocol"
        scheduler:
          extraEnvs:
            - name: USE_REAL_IP
              value: "yes"
            - name: USE_PROXY_PROTOCOL
              value: "yes"
            - name: REAL_IP_FROM
              value: "1.2.3.0/24 100.64.0.0/10"
            - name: REAL_IP_HEADER
              value: "proxy_protocol"
        ```

    === "Swarm"

        !!! warning "Obsol√®te"
            L'int√©gration Swarm est obsol√®te et sera supprim√©e dans une future version. Veuillez envisager d'utiliser l'[int√©gration Kubernetes](integrations.md#kubernetes) √† la place.

            **Plus d'informations sont disponibles dans la [documentation de l'int√©gration Swarm](integrations.md#swarm).**

        Vous devrez ajouter ces param√®tres aux variables d'environnement des services BunkerWeb et scheduler :

        ```yaml
        bunkerweb:
          image: bunkerity/bunkerweb:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ...
        bw-scheduler:
          image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
          ...
          environment:
            USE_REAL_IP: "yes"
            USE_PROXY_PROTOCOL: "yes"
            REAL_IP_FROM: "1.2.3.0/24 100.64.0.0/10"
            REAL_IP_HEADER: "proxy_protocol"
          ...
        ```

        Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

### Utilisation de m√©canismes de r√©solution DNS personnalis√©s

La configuration NGINX de BunkerWeb peut √™tre personnalis√©e pour utiliser diff√©rents r√©solveurs DNS en fonction de vos besoins. Cela peut √™tre particuli√®rement utile dans divers sc√©narios :

1. Pour respecter les entr√©es de votre `/etc/hosts` fichier local
2. Lorsque vous devez utiliser des serveurs DNS personnalis√©s pour certains domaines
3. Pour s'int√©grer √† des solutions de mise en cache DNS locales

#### Utilisation de systemd-resolved

De nombreux syst√®mes Linux modernes utilisent `systemd-resolved` la r√©solution DNS. Si vous souhaitez que BunkerWeb respecte le contenu de votre `/etc/hosts` fichier et utilise le m√©canisme de r√©solution DNS du syst√®me, vous pouvez le configurer pour utiliser le service DNS local r√©solu par systemd.

Pour v√©rifier que systemd-resolved est en cours d'ex√©cution sur votre syst√®me, vous pouvez utiliser :

```bash
systemctl status systemd-resolved
```

Pour activer systemd-resolved comme r√©solveur DNS dans BunkerWeb, d√©finissez le `DNS_RESOLVERS` param√®tre sur `127.0.0.53`, qui est l'adresse d'√©coute par d√©faut pour systemd-resolved :

=== "Interface utilisateur Web"

    Acc√©dez √† la page **Config Globale** et d√©finissez les r√©solveurs DNS sur `127.0.0.53`

    <figure markdown>![Param√®tres des r√©solveurs DNS via l'interface Web](assets/img/advanced-dns-resolvers.png){ align=center }<figcaption>Param√®tres des r√©solveurs DNS via l'interface Web</figcaption></figure>

=== "Linux"

    Vous devrez modifier le fichier /etc/bunkerweb/variables.env :

    ```conf
    ...
    DNS_RESOLVERS=127.0.0.53
    ...
    ```

    Apr√®s avoir effectu√© cette modification, rechargez le Scheduler pour appliquer la configuration :

    ```shell
    sudo systemctl reload bunkerweb-scheduler
    ```

#### Utilisation de dnsmasq

[dnsmasq](http://www.thekelleys.org.uk/dnsmasq/doc.html) est un serveur DNS, DHCP et TFTP l√©ger qui est couramment utilis√© pour la mise en cache et la personnalisation du DNS local. C'est particuli√®rement utile lorsque vous avez besoin de plus de contr√¥le sur votre r√©solution DNS que celui fourni par systemd-resolved.

=== "Linux"

    Tout d'abord, installez et configurez dnsmasq sur votre syst√®me Linux¬†:

    === "Debian/Ubuntu"

        ```bash
        # Install dnsmasq
        sudo apt-get update && sudo apt-get install dnsmasq

        # Configure dnsmasq to listen only on localhost
        echo "listen-address=127.0.0.1" | sudo tee -a /etc/dnsmasq.conf
        echo "bind-interfaces" | sudo tee -a /etc/dnsmasq.conf

        # Add custom DNS entries if needed
        echo "address=/custom.example.com/192.168.1.10" | sudo tee -a /etc/dnsmasq.conf

        # Restart dnsmasq
        sudo systemctl restart dnsmasq
        sudo systemctl enable dnsmasq
        ```

    === "RHEL/Fedora"

        ```bash
        # Install dnsmasq
        sudo dnf install dnsmasq

        # Configure dnsmasq to listen only on localhost
        echo "listen-address=127.0.0.1" | sudo tee -a /etc/dnsmasq.conf
        echo "bind-interfaces" | sudo tee -a /etc/dnsmasq.conf

        # Add custom DNS entries if needed
        echo "address=/custom.example.com/192.168.1.10" | sudo tee -a /etc/dnsmasq.conf

        # Restart dnsmasq
        sudo systemctl restart dnsmasq
        sudo systemctl enable dnsmasq
        ```

    Ensuite, configurez BunkerWeb pour utiliser dnsmasq en d√©finissant `DNS_RESOLVERS` sur `127.0.0.1` :

    === "Web UI"

        Acc√©dez √† la page **Config Globale** et s√©lectionnez le plugin **NGINX**, puis d√©finissez les r√©solveurs DNS sur `127.0.0.1`.

        <figure markdown>![Param√®tres des r√©solveurs DNS via l'interface Web](assets/img/advanced-dns-resolvers2.png){ align=center }<figcaption>Param√®tres des r√©solveurs DNS via l'interface Web</figcaption></figure>

    === "Linux"

        Vous devrez modifier le fichier `/etc/bunkerweb/variables.env` :

        ```conf
        ...
        DNS_RESOLVERS=127.0.0.1
        ...
        ```

        Apr√®s avoir effectu√© cette modification, rechargez le Scheduler pour appliquer la configuration :

        ```shell
        sudo systemctl reload bunkerweb-scheduler
        ```

=== "Tout-en-un"

    Lorsque vous utilisez l'image All-in-one, ex√©cutez dnsmasq dans un conteneur s√©par√© et configurez BunkerWeb pour l'utiliser :

    ```bash
    # Create a custom network for DNS communication
    docker network create bw-dns

    # Run dnsmasq container using dockurr/dnsmasq with Quad9 DNS
    # Quad9 provides security-focused DNS resolution with malware blocking
    docker run -d \
        --name dnsmasq \
        --network bw-dns \
        -e DNS1="9.9.9.9" \
        -e DNS2="149.112.112.112" \
        -p 53:53/udp \
        -p 53:53/tcp \
        --cap-add=NET_ADMIN \
        --restart=always \
        dockurr/dnsmasq

    # Run BunkerWeb All-in-one with dnsmasq DNS resolver
    docker run -d \
        --name bunkerweb-aio \
        --network bw-dns \
        -v bw-storage:/data \
        -e DNS_RESOLVERS="dnsmasq" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        bunkerity/bunkerweb-all-in-one:1.6.5-rc1
    ```

=== "Docker"

    Ajoutez un service dnsmasq √† votre fichier docker-compose et configurez BunkerWeb pour l'utiliser¬†:

    ```yaml
    services:
      dnsmasq:
        image: dockurr/dnsmasq
        container_name: dnsmasq
        environment:
          # Using Quad9 DNS servers for enhanced security and privacy
          # Primary: 9.9.9.9 (Quad9 with malware blocking)
          # Secondary: 149.112.112.112 (Quad9 backup server)
          DNS1: "9.9.9.9"
          DNS2: "149.112.112.112"
        ports:
          - 53:53/udp
          - 53:53/tcp
        cap_add:
          - NET_ADMIN
        restart: always
        networks:
          - bw-dns

      bunkerweb:
        image: bunkerity/bunkerweb:1.6.5-rc1
        ...
        environment:
          DNS_RESOLVERS: "dnsmasq"
        ...
        networks:
          - bw-universe
          - bw-services
          - bw-dns

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
        ...
        environment:
          DNS_RESOLVERS: "dnsmasq"
        ...
        networks:
          - bw-universe
          - bw-dns

    networks:
      # ...existing networks...
      bw-dns:
        name: bw-dns
    ```

### Configurations personnalis√©es

Pour personnaliser et ajouter des configurations personnalis√©es √† BunkerWeb, vous pouvez profiter de sa base NGINX. Des configurations NGINX personnalis√©es peuvent √™tre ajout√©es dans diff√©rents contextes NGINX, y compris des configurations pour le pare-feu d'applications Web (WAF) ModSecurity, qui est un composant central de BunkerWeb. Vous trouverez plus de d√©tails sur les configurations de ModSecurity [ici](features.md#custom-configurations).

Voici les types de configurations personnalis√©es disponibles :

- **http** : Configurations au niveau HTTP de NGINX.
- **server-http** : configurations au niveau HTTP/Server de NGINX.
- **default-server-http**: configurations au niveau du serveur de NGINX, en particulier pour le "serveur par d√©faut" lorsque le nom de client fourni ne correspond √† aucun nom de serveur dans `SERVER_NAME`.
- **modsec-crs**: Configurations appliqu√©es avant le chargement de l'ensemble de r√®gles de base OWASP.
- **modsec**: configurations appliqu√©es apr√®s le chargement de l'ensemble de r√®gles de base OWASP ou utilis√©es lorsque l'ensemble de r√®gles de base n'est pas charg√©.
- **crs-plugins-before**: Configurations pour les plugins CRS, appliqu√©es avant le chargement des plugins CRS.
- **crs-plugins-after**: Configurations pour les plugins CRS, appliqu√©es apr√®s le chargement des plugins CRS.
- **stream** : Configurations au niveau du flux de NGINX.
- **server-stream** : Configurations au niveau Stream/Server de NGINX.

Les configurations personnalis√©es peuvent √™tre appliqu√©es globalement ou sp√©cifiquement pour un serveur particulier, en fonction du contexte applicable et de l'activation ou non du [mode multisite](concepts.md#multisite-mode) .

La m√©thode d'application des configurations personnalis√©es d√©pend de l'int√©gration utilis√©e. Cependant, le processus sous-jacent implique l'ajout de fichiers avec le `.conf` suffixe √† des dossiers sp√©cifiques. Pour appliquer une configuration personnalis√©e √† un serveur sp√©cifique, le fichier doit √™tre plac√© dans un sous-dossier nomm√© d'apr√®s le nom du serveur principal.

Certaines int√©grations offrent des moyens plus pratiques d'appliquer des configurations, par exemple √† l'aide de [Configs](https://docs.docker.com/engine/swarm/configs/) dans Docker Swarm ou de [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) dans Kubernetes. Ces options offrent des approches plus simples pour la gestion et l'application des configurations.

=== "Interface utilisateur Web"

    Acc√©dez √† la page **Configs**, cliquez sur **Create new custom config**, puis choisissez s'il s'agit d'une configuration globale ou sp√©cifique √† un service, le type de configuration et le nom de la configuration :

    <figure markdown>![Configurations personnalis√©es via l'interface Web](assets/img/advanced-config.png){ align=center }<figcaption>Configurations personnalis√©es via l'interface Web</figcaption></figure>

    N'oubliez pas de cliquer sur le bouton `üíæ Enregistrer`.

=== "Linux"

    Lorsque vous utilisez l'int√©gration [Linux](integrations.md#linux), les configurations personnalis√©es doivent √™tre √©crites dans le dossier `/etc/bunkerweb/configs`.

    Voici un exemple pour server-http/hello-world.conf :

    ```nginx
    location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }
    ```

    Comme BunkerWeb s'ex√©cute en tant qu'utilisateur non privil√©gi√© (nginx:nginx), vous devrez modifier les permissions :

    ```shell
    chown -R root:nginx /etc/bunkerweb/configs && \
    chmod -R 770 /etc/bunkerweb/configs
    ```

    V√©rifions maintenant l'√©tat du Scheduler :

    ```shell
    systemctl status bunkerweb-scheduler
    ```

    S'ils sont d√©j√† en cours d'ex√©cution, nous pouvons le recharger :

    ```shell
    systemctl reload bunkerweb-scheduler
    ```

    Sinon, nous devrons le d√©marrer :

    ```shell
    systemctl start bunkerweb-scheduler
    ```

=== "Tout-en-un"

    Lorsque vous utilisez l'image [Tout-en-un](integrations.md#all-in-one-aio-image), vous avez deux options pour ajouter des configurations personnalis√©es :

    - Utilisation de param√®tres sp√©cifiques `*_CUSTOM_CONF_*` comme variables d'environnement lors de l'ex√©cution du conteneur (recommand√©).
    - √âcriture `.conf` de fichiers dans le `/data/configs/` r√©pertoire du volume mont√© sur `/data`.

    **Utilisation des param√®tres (variables d'environnement)**

    Les param√®tres √† utiliser doivent suivre le sch√©ma `<SITE>_CUSTOM_CONF_<TYPE>_<NAME>`:

    - `<SITE>` : Nom du serveur primaire facultatif si le mode multisite est activ√© et que la configuration doit √™tre appliqu√©e √† un service sp√©cifique.
    - `<TYPE>` : Le type de configuration, les valeurs accept√©es sont `HTTP`, `DEFAULT_SERVER_HTTP`, `SERVER_HTTP` `MODSEC` `MODSEC_CRS` `CRS_PLUGINS_BEFORE`, `CRS_PLUGINS_AFTER` `STREAM` , et `SERVER_STREAM`.
    - `<NAME>` : Le nom de la configuration sans le `.conf` suffixe.

    Voici un exemple fictif lors de l'ex√©cution du conteneur All-in-one :

    ```bash
    docker run -d \
        --name bunkerweb-aio \
        -v bw-storage:/data \
        -e "CUSTOM_CONF_SERVER_HTTP_hello-world=location /hello { \
            default_type 'text/plain'; \
            content_by_lua_block { \
              ngx.say('world'); \
            } \
          }" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        bunkerity/bunkerweb-all-in-one:1.6.5-rc1
    ```

    Veuillez noter que si votre conteneur est d√©j√† cr√©√©, vous devrez le supprimer et le recr√©er pour que les nouvelles variables d'environnement soient appliqu√©es.

    **Utilisation de fichiers**

    La premi√®re chose √† faire est de cr√©er les dossiers :

    ```shell
    mkdir -p ./bw-data/configs/server-http
    ```

    Vous pouvez maintenant √©crire vos configurations :

    ```shell
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" > ./bw-data/configs/server-http/hello-world.conf
    ```

    √âtant donn√© que le Scheduler s'ex√©cute en tant qu'utilisateur non privil√©gi√© avec UID et GID 101, vous devrez modifier les autorisations :

    ```shell
    chown -R root:101 bw-data && \
    chmod -R 770 bw-data
    ```

    Au d√©marrage du conteneur de l'ordonnanceur, vous devrez monter le dossier sur /data :

    ```bash
    docker run -d \
        --name bunkerweb-aio \
        -v ./bw-data:/data \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        bunkerity/bunkerweb-all-in-one:1.6.5-rc1
    ```

=== "Docker"

    Lorsque vous utilisez l'int√©gration [Docker](integrations.md#docker), vous avez deux options pour ajouter des configurations personnalis√©es :

    - Utilisation de param√®tres sp√©cifiques `*_CUSTOM_CONF_*` comme variables d'environnement (recommand√©)
    - √âcriture des fichiers .conf sur le volume mont√© sur /data de l'ordonnanceur

    **Utilisation des param√®tres**

    Les param√®tres √† utiliser doivent suivre le sch√©ma `<SITE>_CUSTOM_CONF_<TYPE>_<NAME>` :

    - `<SITE>` : nom de serveur primaire facultatif si le mode multisite est activ√© et que la configuration doit √™tre appliqu√©e √† un service sp√©cifique
    - `<TYPE>` : le type de configuration, les valeurs accept√©es sont `HTTP`, `DEFAULT_SERVER_HTTP` `SERVER_HTTP` `MODSEC` `MODSEC_CRS` `CRS_PLUGINS_BEFORE`, `CRS_PLUGINS_AFTER`, `STREAM` , et `SERVER_STREAM`
    - `<NAME>` : le nom de config sans le suffixe .conf

    Voici un exemple factice utilisant un fichier docker-compose :

    ```yaml
    ...
    bw-scheduler:
      image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
      environment:
        - |
          CUSTOM_CONF_SERVER_HTTP_hello-world=
          location /hello {
            default_type 'text/plain';
            content_by_lua_block {
              ngx.say('world')
            }
          }
      ...
    ```

    **Utilisation de fichiers**

    La premi√®re chose √† faire est de cr√©er les dossiers :

    ```shell
    mkdir -p ./bw-data/configs/server-http
    ```

    Vous pouvez maintenant √©crire vos configurations :

    ```nginx
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" > ./bw-data/configs/server-http/hello-world.conf
    ```

    √âtant donn√© que le Scheduler s'ex√©cute en tant qu'utilisateur non privil√©gi√© avec UID et GID 101, vous devrez modifier les autorisations :

    ```shell
    chown -R root:101 bw-data && \
    chmod -R 770 bw-data
    ```

    Au d√©marrage du conteneur de l'ordonnanceur, vous devrez monter le dossier sur /data :

    ```yaml
    bw-scheduler:
      image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
      volumes:
        - ./bw-data:/data
      ...
    ```

=== "Docker autoconf"

    Lorsque vous utilisez l'int√©gration [Docker autoconf](integrations.md#docker-autoconf), vous avez deux options pour ajouter des configurations personnalis√©es :

    - Utilisation de param√®tres sp√©cifiques `*_CUSTOM_CONF_*` comme √©tiquettes (le plus simple)
    - √âcriture des fichiers .conf sur le volume mont√© sur /data de l'ordonnanceur

    **Utilisation des √©tiquettes**

    !!! warning "Limitations de l'utilisation des √©tiquettes"
        Lorsque vous utilisez des √©tiquettes avec l'int√©gration Docker autoconf, vous ne pouvez appliquer des configurations personnalis√©es que pour le service web correspondant. L'application de **http**, **default-server-http**, **stream** ou de toute configuration globale (comme **server-http** ou **server-stream** pour tous les services) n'est pas possible : vous devrez monter des fichiers √† cet effet.

    Les √©tiquettes √† utiliser doivent suivre le mod√®le `bunkerweb.CUSTOM_CONF_<TYPE>_<NAME>` :

    - `<TYPE>` : le type de configuration, les valeurs accept√©es sont `SERVER_HTTP`, `MODSEC`, `MODSEC_CRS`, `CRS_PLUGINS_BEFORE` `CRS_PLUGINS_AFTER` et `SERVER_STREAM`
    - `<NAME>` : le nom de config sans le suffixe .conf

    Voici un exemple factice utilisant un fichier docker-compose :

    ```yaml
    myapp:
      image: nginxdemos/nginx-hello
      labels:
        - |
          bunkerweb.CUSTOM_CONF_SERVER_HTTP_hello-world=
          location /hello {
            default_type 'text/plain';
            content_by_lua_block {
                ngx.say('world')
            }
          }
      ...
    ```

    **Utilisation de fichiers**

    La premi√®re chose √† faire est de cr√©er les dossiers :

    ```shell
    mkdir -p ./bw-data/configs/server-http
    ```

    Vous pouvez maintenant √©crire vos configurations :

    ```nginx
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" > ./bw-data/configs/server-http/hello-world.conf
    ```

    √âtant donn√© que le Scheduler s'ex√©cute en tant qu'utilisateur non privil√©gi√© avec UID et GID 101, vous devrez modifier les autorisations :

    ```shell
    chown -R root:101 bw-data && \
    chmod -R 770 bw-data
    ```

    Au d√©marrage du conteneur de l'ordonnanceur, vous devrez monter le dossier sur /data :

    ```yaml
    bw-scheduler:
      image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
      volumes:
        - ./bw-data:/data
      ...
    ```

=== "Kubernetes"

    Lors de l'utilisation de l'[int√©gration Kubernetes](integrations.md#kubernetes), les configurations personnalis√©es sont g√©r√©es √† l'aide de [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/).

    Pour simplifier, vous n'avez m√™me pas besoin d'attacher le ConfigMap √† un Pod (par ex. comme variable d'environnement ou volume) : le Pod d'autoconf √©coute les √©v√©nements ConfigMap et mettra √† jour les configurations personnalis√©es lorsque n√©cessaire.

    Lors de la cr√©ation d'un ConfigMap, vous devrez ajouter des labels sp√©ciaux :

    * **bunkerweb.io/CONFIG_TYPE** : doit √™tre d√©fini sur un type de configuration personnalis√© valide (http, server-http, default-server-http, modsec, modsec-crs, crs-plugins-before, crs-plugins-after, stream ou server-stream)
    * **bunkerweb.io/CONFIG_SITE** : d√©fini sur un nom de serveur pour appliquer la configuration √† ce serveur sp√©cifique (facultatif, sera appliqu√© globalement s'il n'est pas d√©fini)

    Voici l'exemple :

    ```yaml
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: cfg-bunkerweb-all-server-http
      annotations:
        bunkerweb.io/CONFIG_TYPE: "server-http"
    data:
      myconf: |
      location /hello {
        default_type 'text/plain';
        content_by_lua_block {
          ngx.say('world')
        }
      }
    ```

    !!! tip "Custom Extra Config"
        Depuis la version `1.6.0`, vous pouvez ajouter/remplacer des param√®tres √† l'aide de l'annotation `bunkerweb.io/CONFIG_TYPE=settings`. En voici un exemple :

        ```yaml
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: cfg-bunkerweb-extra-settings
          annotations:
            bunkerweb.io/CONFIG_TYPE: "settings"
        data:
          USE_ANTIBOT: "captcha" # multisite setting that will be applied to all services that do not override it
          USE_REDIS: "yes" # global setting that will be applied globally
          ...
        ```

=== "Swarm"

    !!! warning "Obsol√®te"
        L'int√©gration Swarm est obsol√®te et sera supprim√©e dans une future version. Veuillez envisager d'utiliser l'[int√©gration Kubernetes](integrations.md#kubernetes) √† la place.

        **Plus d'informations sont disponibles dans la [documentation de l'int√©gration Swarm](integrations.md#swarm).**

    Lorsque vous utilisez l'[Swarm integration](integrations.md#swarm), les configurations personnalis√©es sont g√©r√©es √† l'aide des [Docker Configs](https://docs.docker.com/engine/swarm/configs/).

    Pour simplifier, vous n'avez m√™me pas besoin d'attacher le Config √† un service : le service d'autoconf √©coute les √©v√©nements Config et mettra √† jour les configurations personnalis√©es lorsque n√©cessaire.

    Lors de la cr√©ation d'un Config, vous devrez ajouter des labels sp√©ciaux :

    * **bunkerweb.CONFIG_TYPE** : doit √™tre d√©fini sur un type de configuration personnalis√© valide (http, server-http, default-server-http, modsec, modsec-crs, crs-plugins-before, crs-plugins-after, stream ou server-stream)
    * **bunkerweb.CONFIG_SITE** : d√©fini sur un nom de serveur pour appliquer la configuration √† ce serveur sp√©cifique (facultatif, sera appliqu√© globalement s'il n'est pas d√©fini)

    Voici l'exemple :

    ```nginx
    echo "location /hello {
      default_type 'text/plain';
      content_by_lua_block {
        ngx.say('world')
      }
    }" | docker config create -l bunkerweb.CONFIG_TYPE=server-http my-config -
    ```

    Il n'y a pas de m√©canisme de mise √† jour : l'alternative est de supprimer une configuration existante √† l'aide puis de `docker config rm` la recr√©er.

### Ex√©cution de nombreux services en production

#### CRS mondial

!!! warning "Plugins CRS"
    Lorsque le SCR est charg√© globalement, les **plug-ins SCR ne sont pas pris en charge**. Si vous avez besoin de les utiliser, vous devrez charger le SCR par service.

Si vous utilisez BunkerWeb en production avec un grand nombre de services, et que vous activez la **fonctionnalit√© ModSecurity globalement** avec des r√®gles CRS, le temps n√©cessaire pour charger les configurations BunkerWeb peut devenir trop long, ce qui peut entra√Æner un d√©lai d'expiration.

La solution de contournement consiste √† charger les r√®gles CRS globalement plut√¥t que par service. Ce comportement n'est pas activ√© par d√©faut pour des raisons de compatibilit√© descendante et parce qu'il pr√©sente un inconv√©nient : si vous activez le chargement des r√®gles CRS globales, **il ne sera plus possible de d√©finir des r√®gles modsec-crs** (ex√©cut√©es avant les r√®gles CRS) par service. Cependant, cette limitation peut √™tre contourn√©e en √©crivant des r√®gles d'exclusion globales `modsec-crs` comme suit :

```
SecRule REQUEST_FILENAME "@rx ^/somewhere$" "nolog,phase:4,allow,id:1010,chain"
SecRule REQUEST_HEADERS:Host "@rx ^app1\.example\.com$" "nolog"
```

Vous pouvez activer le chargement global du SCR en d√©finissant `USE_MODSECURITY_GLOBAL_CRS` la valeur . `yes`

#### Ajuster max_allowed_packet pour MariaDB/MySQL

Il semble que la valeur par d√©faut du `max_allowed_packet` param√®tre dans les serveurs de bases de donn√©es MariaDB et MySQL ne soit pas suffisante lors de l'utilisation de BunkerWeb avec un grand nombre de services.

Si vous rencontrez des erreurs comme celle-ci, en particulier sur le Scheduler :

```
[Warning] Aborted connection 5 to db: 'db' user: 'bunkerweb' host: '172.20.0.4' (Got a packet bigger than 'max_allowed_packet' bytes)
```

Vous devrez augmenter le `max_allowed_packet` sur votre serveur de base de donn√©es.

### Persistance des interdictions et des signalements

Par d√©faut, BunkerWeb stocke les bannissements et les rapports dans un magasin de donn√©es Lua local. Bien que simple et efficace, cette configuration signifie que des donn√©es sont perdues lors du red√©marrage de l'instance. Pour vous assurer que les bannissements et les rapports persistent lors des red√©marrages, vous pouvez configurer BunkerWeb pour utiliser un [ serveur Redis](https://redis.io/) ou [Valkey](https://valkey.io/) distant  .

**Pourquoi utiliser Redis/Valkey ?**

Redis et Valkey sont de puissants magasins de donn√©es en m√©moire couramment utilis√©s comme bases de donn√©es, caches et courtiers de messages. Ils sont hautement √©volutifs et prennent en charge une vari√©t√© de structures de donn√©es, notamment :

- **Cha√Ænes**: paires cl√©-valeur de base.
- **Hachages**: paires champ-valeur au sein d'une seule cl√©.
- **Listes**: collections ordonn√©es de cha√Ænes.
- **Ensembles**: collections non ordonn√©es de cha√Ænes uniques.
- **Ensembles tri√©s**: Collections ordonn√©es avec partitions.

En tirant parti de Redis ou de Valkey, BunkerWeb peut stocker de mani√®re persistante les bannissements, les rapports et les donn√©es de cache, garantissant ainsi la durabilit√© et l'√©volutivit√©.

**Activation de la prise en charge Redis/Valkey**

Pour activer la prise en charge de Redis ou Valkey, configurez les param√®tres suivants dans votre fichier de configuration BunkerWeb :

```conf
# Enable Redis/Valkey support
USE_REDIS=yes

# Redis/Valkey server hostname or IP address
REDIS_HOST=<hostname>

# Redis/Valkey server port number (default: 6379)
REDIS_PORT=6379

# Redis/Valkey database number (default: 0)
REDIS_DATABASE=0
```

- **`USE_REDIS`**: R√©glez sur `yes` pour activer l'int√©gration Redis/Valkey.
- **`REDIS_HOST`**: Sp√©cifiez le nom d'h√¥te ou l'adresse IP du serveur Redis/Valkey.
- **`REDIS_PORT`**: Sp√©cifiez le num√©ro de port pour le serveur Redis/Valkey. La valeur par d√©faut est `6379`.
- **`REDIS_DATABASE`**: Indiquez le num√©ro de base de donn√©es Redis/Valkey √† utiliser. La valeur par d√©faut est `0`.

Si vous avez besoin de param√®tres plus avanc√©s, tels que l'authentification, la prise en charge SSL/TLS ou le mode Sentinel, reportez-vous √† la documentation sur les param√®tres du [plug-in Redis](features.md#redis) pour obtenir des conseils d√©taill√©s.

### Prot√©ger les applications UDP/TCP

!!! example "Fonctionnalit√© exp√©rimentale"

	  This feature is not production-ready. Feel free to test it and report us any bug using [issues](https://github.com/bunkerity/bunkerweb/issues) in the GitHub repository.

BunkerWeb offre la possibilit√© de fonctionner comme un **proxy inverse UDP/TCP g√©n√©rique**, ce qui vous permet de prot√©ger toutes les applications bas√©es sur le r√©seau fonctionnant au moins sur la couche 4 du mod√®le OSI. Au lieu d'utiliser le module HTTP "classique", BunkerWeb exploite le [module de flux](https://nginx.org/en/docs/stream/ngx_stream_core_module.html) de NGINX.

Il est important de noter que **tous les param√®tres et fonctionnalit√©s de s√©curit√© ne sont pas disponibles lors de l'utilisation du module de flux**. Vous trouverez de plus amples informations √† ce sujet dans les sections des [fonctionnalit√©s](features.md) de la documentation.

La configuration d'un proxy inverse de base est assez similaire √† la configuration HTTP, car elle implique l'utilisation des m√™mes param√®tres : `USE_REVERSE_PROXY=yes` et `REVERSE_PROXY_HOST=myapp:9000`. M√™me lorsque BunkerWeb est positionn√© derri√®re un √©quilibreur de charge, les param√®tres restent les m√™mes (le **protocole PROXY** √©tant l'option prise en charge pour des raisons √©videntes).

En plus de cela, les param√®tres sp√©cifiques suivants sont utilis√©s :

- `SERVER_TYPE=stream` : activer  le `stream` mode (UDP/TCP g√©n√©rique) au lieu d' `http` un (qui est la valeur par d√©faut)
- `LISTEN_STREAM_PORT=4242` : le port d'√©coute "simple" (sans SSL/TLS) sur lequel BunkerWeb √©coutera
- `LISTEN_STREAM_PORT_SSL=4343` : le port d'√©coute "ssl/tls" sur lequel BunkerWeb √©coutera
- `USE_UDP=no` : √©couter et transf√©rer les paquets UDP au lieu de TCP

Pour la liste compl√®te des param√®tres concernant `stream` le  mode, veuillez vous r√©f√©rer √† la sections des [fonctionnalit√©s](features.md) de la documentation.

!!! tip "Plusieurs ports d'√©coute"

    Depuis la version `1.6.0`, BunkerWeb prend en charge plusieurs ports d'√©coute pour le mode `stream`. Vous pouvez les sp√©cifier √† l'aide des param√®tres `LISTEN_STREAM_PORT` et `LISTEN_STREAM_PORT_SSL`.

    Voici un exemple :

    ```conf
    ...
    LISTEN_STREAM_PORT=4242
    LISTEN_STREAM_PORT_SSL=4343
    LISTEN_STREAM_PORT_1=4244
    LISTEN_STREAM_PORT_SSL_1=4344
    ...
    ```

=== "Tout-en-un"

    Vous devrez ajouter ces param√®tres aux variables d'environnement lors de l'ex√©cution du conteneur All-in-one. Vous devrez √©galement exposer les ports de stream.

    Cet exemple configure BunkerWeb pour agir comme proxy inverse pour deux applications bas√©es sur le mode stream : `app1.example.com` et `app2.example.com`.

    ```bash
    docker run -d \
        --name bunkerweb-aio \
        -v bw-storage:/data \
        -e SERVICE_UI="no" \
        -e SERVER_NAME="app1.example.com app2.example.com" \
        -e MULTISITE="yes" \
        -e USE_REVERSE_PROXY="yes" \
        -e SERVER_TYPE="stream" \
        -e app1.example.com_REVERSE_PROXY_HOST="myapp1:9000" \
        -e app1.example.com_LISTEN_STREAM_PORT="10000" \
        -e app2.example.com_REVERSE_PROXY_HOST="myapp2:9000" \
        -e app2.example.com_LISTEN_STREAM_PORT="20000" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        -p 10000:10000/tcp \
        -p 20000:20000/tcp \
        bunkerity/bunkerweb-all-in-one:1.6.5-rc1
    ```

    Veuillez noter que si votre conteneur existe d√©j√†, vous devrez le supprimer et le recr√©er afin que les nouvelles variables d'environnement soient prises en compte.

    Vos applications (`myapp1`, `myapp2`) doivent s'ex√©cuter dans des conteneurs s√©par√©s (ou √™tre autrement accessibles) et leurs noms d'h√¥te/adresses IP (par ex. `myapp1`, `myapp2` utilis√©s dans `_REVERSE_PROXY_HOST`) doivent √™tre r√©solubles et atteignables depuis le conteneur `bunkerweb-aio`. Cela implique g√©n√©ralement de les connecter √† un r√©seau Docker partag√©.

    !!! note "D√©sactiver le service UI"
        Il est recommand√© de d√©sactiver le service d'interface Web (par exemple en d√©finissant la variable d'environnement `SERVICE_UI=no`) car l'interface Web n'est pas compatible avec `SERVER_TYPE=stream`.

=== "Docker"

    Lors de l'utilisation de l'int√©gration Docker, la mani√®re la plus simple de prot√©ger des applications r√©seau existantes est d'ajouter les services au r√©seau `bw-services` :

    ```yaml
    x-bw-api-env: &bw-api-env
      # We use an anchor to avoid repeating the same settings for all services
      API_WHITELIST_IP: "127.0.0.0/8 10.20.30.0/24"

    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.5-rc1
        ports:
          - "80:8080" # Keep it if you want to use Let's Encrypt automation when using http challenge type
          - "10000:10000" # app1
          - "20000:20000" # app2
        labels:
          - "bunkerweb.INSTANCE=yes"
        environment:
          <<: *bw-api-env
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-services

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
        environment:
          <<: *bw-api-env
          BUNKERWEB_INSTANCES: "bunkerweb" # This setting is mandatory to specify the BunkerWeb instance
          SERVER_NAME: "app1.example.com app2.example.com"
          MULTISITE: "yes"
          USE_REVERSE_PROXY: "yes" # Will be applied to all services
          SERVER_TYPE: "stream" # Will be applied to all services
          app1.example.com_REVERSE_PROXY_HOST: "myapp1:9000"
          app1.example.com_LISTEN_STREAM_PORT: "10000"
          app2.example.com_REVERSE_PROXY_HOST: "myapp2:9000"
          app2.example.com_LISTEN_STREAM_PORT: "20000"
        volumes:
          - bw-storage:/data # This is used to persist the cache and other data like the backups
        restart: "unless-stopped"
        networks:
          - bw-universe

      myapp1:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app1" ]
        networks:
          - bw-services

      myapp2:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app2" ]
        networks:
          - bw-services

    volumes:
      bw-storage:

    networks:
      bw-universe:
        name: bw-universe
        ipam:
          driver: default
          config:
            - subnet: 10.20.30.0/24
      bw-services:
        name: bw-services
    ```

=== "Docker autoconf"

    Avant d'ex√©cuter la pile de l'int√©gration [Docker autoconf](integrations.md#docker-autoconf) sur votre machine, vous devrez modifier les ports :

    ```yaml
    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.5-rc1
        ports:
          - "80:8080" # Keep it if you want to use Let's Encrypt automation when using http challenge type
          - "10000:10000" # app1
          - "20000:20000" # app2
    ...
    ```

    Une fois la pile en cours d'ex√©cution, vous pouvez connecter vos applications existantes au r√©seau `bw-services` et configurer BunkerWeb avec des `labels` :

    ```yaml
    services:
      myapp1:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app1" ]
        networks:
          - bw-services
        labels:
          - "bunkerweb.SERVER_NAME=app1.example.com"
          - "bunkerweb.SERVER_TYPE=stream"
          - "bunkerweb.USE_REVERSE_PROXY=yes"
          - "bunkerweb.REVERSE_PROXY_HOST=myapp1:9000"
          - "bunkerweb.LISTEN_STREAM_PORT=10000"

      myapp2:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app2" ]
        networks:
          - bw-services
        labels:
          - "bunkerweb.SERVER_NAME=app2.example.com"
          - "bunkerweb.SERVER_TYPE=stream"
          - "bunkerweb.USE_REVERSE_PROXY=yes"
          - "bunkerweb.REVERSE_PROXY_HOST=myapp2:9000"
          - "bunkerweb.LISTEN_STREAM_PORT=20000"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

=== "Kubernetes"

    !!! example "Fonctionnalit√© exp√©rimentale"

        Actuellement, les [Ingresses](https://kubernetes.io/docs/concepts/services-networking/ingress/) ne prennent pas en charge le mode `stream`. **Ce que nous proposons ici est une solution de contournement pour le faire fonctionner.**

        N'h√©sitez pas √† le tester et √† nous signaler tout bug en ouvrant une issue via [issues](https://github.com/bunkerity/bunkerweb/issues) du d√©p√¥t GitHub.

    Avant d'ex√©cuter la pile de l'[int√©gration Kubernetes](integrations.md#kubernetes) sur votre machine, vous devrez ouvrir les ports sur votre √©quilibreur de charge :

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: lb
    spec:
      type: LoadBalancer
      ports:
        - name: http # Keep it if you want to use Let's Encrypt automation when using http challenge type
          port: 80
          targetPort: 8080
        - name: app1
          port: 10000
          targetPort: 10000
        - name: app2
          port: 20000
          targetPort: 20000
      selector:
        app: bunkerweb
    ```

    Une fois la pile en cours d'ex√©cution, vous pouvez cr√©er vos ressources Ingress :

    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: ingress
      namespace: services
      annotations:
        bunkerweb.io/SERVER_TYPE: "stream" # Will be applied to all services
        bunkerweb.io/app1.example.com_LISTEN_STREAM_PORT: "10000"
        bunkerweb.io/app2.example.com_LISTEN_STREAM_PORT: "20000"
    spec:
      rules:
        - host: app1.example.com
          http:
            paths:
              - path: / # This isn't used in stream mode but is required
                pathType: Prefix
                backend:
                  service:
                    name: svc-app1
                    port:
                      number: 9000
        - host: app2.example.com
          http:
            paths:
              - path: / # This isn't used in stream mode but is required
                pathType: Prefix
                backend:
                  service:
                    name: svc-app2
                    port:
                      number: 9000
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: app1
      namespace: services
      labels:
        app: app1
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: app1
      template:
        metadata:
          labels:
            app: app1
        spec:
          containers:
            - name: app1
              image: istio/tcp-echo-server:1.3
              args: ["9000", "app1"]
              ports:
                - containerPort: 9000
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: svc-app1
      namespace: services
    spec:
      selector:
        app: app1
      ports:
        - protocol: TCP
          port: 9000
          targetPort: 9000
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: app2
      namespace: services
      labels:
        app: app2
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: app2
      template:
        metadata:
          labels:
            app: app2
        spec:
          containers:
            - name: app2
              image: istio/tcp-echo-server:1.3
              args: ["9000", "app2"]
              ports:
                - containerPort: 9000
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: svc-app2
      namespace: services
    spec:
      selector:
        app: app2
      ports:
        - protocol: TCP
          port: 9000
          targetPort: 9000
    ```

=== "Linux"

    Vous devrez ajouter ces param√®tres au fichier /etc/bunkerweb/variables.env :

    ```conf
    ...
    SERVER_NAME=app1.example.com app2.example.com
    MULTISITE=yes
    USE_REVERSE_PROXY=yes
    SERVER_TYPE=stream
    app1.example.com_REVERSE_PROXY_HOST=myapp1.domain.or.ip:9000
    app1.example.com_LISTEN_STREAM_PORT=10000
    app2.example.com_REVERSE_PROXY_HOST=myapp2.domain.or.ip:9000
    app2.example.com_LISTEN_STREAM_PORT=20000
    ...
    ```

    V√©rifions maintenant l'√©tat du Scheduler :

    ```shell
    systemctl status bunkerweb-scheduler
    ```

    S'ils sont d√©j√† en cours d'ex√©cution, nous pouvons le recharger :

    ```shell
    systemctl reload bunkerweb-scheduler
    ```

    Sinon, nous devrons le d√©marrer :

    ```shell
    systemctl start bunkerweb-scheduler
    ```

=== "Swarm"

    !!! warning "Obsol√®te"
        L'int√©gration Swarm est obsol√®te et sera supprim√©e dans une future version. Veuillez envisager d'utiliser l'[int√©gration Kubernetes](integrations.md#kubernetes) √† la place.

        **Plus d'informations sont disponibles dans la [documentation de l'int√©gration Swarm](integrations.md#swarm).**

    Avant d'ex√©cuter la pile de l'int√©gration [Swarm](integrations.md#swarm) sur votre machine, vous devrez modifier les ports :

    ```yaml
    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.5-rc1
        ports:
          # Keep it if you want to use Let's Encrypt automation when using http challenge type
          - published: 80
            target: 8080
            mode: host
            protocol: tcp
          # app1
          - published: 10000
            target: 10000
            mode: host
            protocol: tcp
          # app2
          - published: 20000
            target: 20000
            mode: host
            protocol: tcp
    ...
    ```

    Une fois la pile en cours d'ex√©cution, vous pouvez connecter vos applications existantes au r√©seau `bw-services` et configurer BunkerWeb √† l'aide d'√©tiquettes :

    ```yaml
    services:

      myapp1:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app1" ]
        networks:
          - bw-services
        deploy:
          placement:
            constraints:
              - "node.role==worker"
          labels:
            - "bunkerweb.SERVER_NAME=app1.example.com"
            - "bunkerweb.SERVER_TYPE=stream"
            - "bunkerweb.USE_REVERSE_PROXY=yes"
            - "bunkerweb.REVERSE_PROXY_HOST=myapp1:9000"
            - "bunkerweb.LISTEN_STREAM_PORT=10000"

      myapp2:
        image: istio/tcp-echo-server:1.3
        command: [ "9000", "app2" ]
        networks:
          - bw-services
        deploy:
          placement:
            constraints:
              - "node.role==worker"
          labels:
            - "bunkerweb.SERVER_NAME=app2.example.com"
            - "bunkerweb.SERVER_TYPE=stream"
            - "bunkerweb.USE_REVERSE_PROXY=yes"
            - "bunkerweb.REVERSE_PROXY_HOST=myapp2:9000"
            - "bunkerweb.LISTEN_STREAM_PORT=20000"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

### Le PHP

!!! example "Fonctionnalit√© exp√©rimentale"
	  Pour le moment, le support PHP avec BunkerWeb est encore en version b√™ta et nous vous recommandons d'utiliser une architecture de proxy inverse si vous le pouvez. D'ailleurs, PHP n'est pas du tout pris en charge pour certaines int√©grations comme Kubernetes.

BunkerWeb prend en charge PHP en utilisant des  instances [PHP-FPM externes ou ](https://www.php.net/manual/en/install.fpm.php) distantes. Nous supposerons que vous √™tes d√©j√† familiaris√© avec la gestion de ce type de services.

 Les param√®tres suivants peuvent √™tre utilis√©s :

- `REMOTE_PHP` : Nom d'h√¥te de l'instance PHP-FPM distante.
- `REMOTE_PHP_PATH` : Dossier racine contenant les fichiers dans l'instance PHP-FPM distante.
- `REMOTE_PHP_PORT` : Port de l'instance PHP-FPM distante (*9000 par d√©faut*).
- `LOCAL_PHP` : Chemin d'acc√®s au fichier socket local de l'instance PHP-FPM.
- `LOCAL_PHP_PATH` : Dossier racine contenant les fichiers dans l'instance locale PHP-FPM.

=== "Tout-en-un"

    Lorsque vous utilisez l'image [Tout-en-un](integrations.md#all-in-one-aio-image), pour prendre en charge les applications PHP, vous devrez :

    - Montez vos fichiers PHP dans le `/var/www/html` dossier de BunkerWeb.
    - Configurez un conteneur PHP-FPM pour votre application et montez le dossier contenant les fichiers PHP.
    - Utilisez les param√®tres sp√©cifiques `REMOTE_PHP` et `REMOTE_PHP_PATH` comme variables d'environnement lors de l'ex√©cution de BunkerWeb.

    Si vous activez le [mode multisite](concepts.md#multisite-mode), vous devrez cr√©er des r√©pertoires distincts pour chacune de vos applications. Chaque sous-r√©pertoire doit √™tre nomm√© √† l'aide de la premi√®re valeur de `SERVER_NAME`. Voici un exemple fictif :

    ```
    www
    ‚îú‚îÄ‚îÄ app1.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îî‚îÄ‚îÄ app2.example.com
        ‚îî‚îÄ‚îÄ index.php

    2 directories, 2 files
    ```

    Nous supposerons que vos applications PHP se trouvent dans un dossier nomm√© `www`. Veuillez noter que vous devrez corriger les permissions pour que BunkerWeb (UID/GID 101) puisse au moins lire les fichiers et lister les dossiers et PHP-FPM (UID/GID 33 si vous utilisez l' `php:fpm` image) soit le propri√©taire des fichiers et dossiers :

    ```shell
    chown -R 33:101 ./www && \
    find ./www -type f -exec chmod 0640 {} \; && \
    find ./www -type d -exec chmod 0750 {} \;
    ```

    Vous pouvez maintenant ex√©cuter BunkerWeb, le configurer pour votre application PHP et √©galement ex√©cuter les applications PHP. Vous devrez cr√©er un r√©seau Docker personnalis√© pour permettre √† BunkerWeb de communiquer avec vos conteneurs PHP-FPM.

    ```bash
    # Create a custom network
    docker network create php-network

    # Run PHP-FPM containers
    docker run -d --name myapp1-php --network php-network -v ./www/app1.example.com:/app php:fpm
    docker run -d --name myapp2-php --network php-network -v ./www/app2.example.com:/app php:fpm

    # Run BunkerWeb All-in-one
    docker run -d \
        --name bunkerweb-aio \
        --network php-network \
        -v ./www:/var/www/html \
        -v bw-storage:/data \
        -e SERVER_NAME="app1.example.com app2.example.com" \
        -e MULTISITE="yes" \
        -e REMOTE_PHP_PATH="/app" \
        -e app1.example.com_REMOTE_PHP="myapp1-php" \
        -e app2.example.com_REMOTE_PHP="myapp2-php" \
        -p 80:8080/tcp \
        -p 443:8443/tcp \
        -p 443:8443/udp \
        bunkerity/bunkerweb-all-in-one:1.6.5-rc1
    ```

    Veuillez noter que si votre conteneur est d√©j√† cr√©√©, vous devrez le supprimer et le recr√©er pour que les nouvelles variables d'environnement soient appliqu√©es.

=== "Docker"

    Lors de l'utilisation de l'int√©gration [Docker](integrations.md#docker), pour prendre en charge les applications PHP, vous devrez :

    - Montez vos fichiers PHP dans le `/var/www/html` dossier de BunkerWeb
    - Configurez un conteneur PHP-FPM pour votre application et montez le dossier contenant les fichiers PHP
    - Utilisez les param√®tres sp√©cifiques `REMOTE_PHP` et `REMOTE_PHP_PATH` comme variables d'environnement lors du d√©marrage de BunkerWeb

    Si vous activez le [mode multisite](concepts.md#multisite-mode), vous devrez cr√©er des r√©pertoires distincts pour chacune de vos applications. Chaque sous-r√©pertoire doit √™tre nomm√© √† l'aide de la premi√®re valeur de `SERVER_NAME`. Voici un exemple fictif :

    ```
    www
    ‚îú‚îÄ‚îÄ app1.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îú‚îÄ‚îÄ app2.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îî‚îÄ‚îÄ app3.example.com
        ‚îî‚îÄ‚îÄ index.php

    3 directories, 3 files
    ```

    Nous supposerons que vos applications PHP se trouvent dans un dossier nomm√© `www`. Veuillez noter que vous devrez corriger les permissions pour que BunkerWeb (UID/GID 101) puisse au moins lire les fichiers et lister les dossiers et PHP-FPM (UID/GID 33 si vous utilisez l' `php:fpm` image) soit le propri√©taire des fichiers et dossiers :

    ```shell
    chown -R 33:101 ./www && \
    find ./www -type f -exec chmod 0640 {} \; && \
    find ./www -type d -exec chmod 0750 {} \;
    ```

    Vous pouvez maintenant ex√©cuter BunkerWeb, le configurer pour votre application PHP et √©galement ex√©cuter les applications PHP :

    ```yaml
    x-bw-api-env: &bw-api-env
      # We use an anchor to avoid repeating the same settings for all services
      API_WHITELIST_IP: "127.0.0.0/8 10.20.30.0/24"

    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.5-rc1
        ports:
          - "80:8080/tcp"
          - "443:8443/tcp"
          - "443:8443/udp" # QUIC
        environment:
          <<: *bw-api-env
        volumes:
          - ./www:/var/www/html
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-services

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
        environment:
          <<: *bw-api-env
          BUNKERWEB_INSTANCES: "bunkerweb" # This setting is mandatory to specify the BunkerWeb instance
          SERVER_NAME: "app1.example.com app2.example.com"
          MULTISITE: "yes"
          REMOTE_PHP_PATH: "/app" # Will be applied to all services thanks to the MULTISITE setting
          app1.example.com_REMOTE_PHP: "myapp1"
          app2.example.com_REMOTE_PHP: "myapp2"
          app3.example.com_REMOTE_PHP: "myapp3"
        volumes:
          - bw-storage:/data # This is used to persist the cache and other data like the backups
        restart: "unless-stopped"
        networks:
          - bw-universe

      myapp1:
        image: php:fpm
        volumes:
          - ./www/app1.example.com:/app
        networks:
          - bw-services

      myapp2:
        image: php:fpm
        volumes:
          - ./www/app2.example.com:/app
        networks:
          - bw-services

      myapp3:
        image: php:fpm
        volumes:
          - ./www/app3.example.com:/app
        networks:
          - bw-services

    volumes:
      bw-storage:

    networks:
      bw-universe:
        name: bw-universe
        ipam:
          driver: default
          config:
            - subnet: 10.20.30.0/24
      bw-services:
        name: bw-services
    ```

=== "Docker autoconf"

    !!! info "Mode multisite activ√©"
        L'int√©gration [Docker autoconf](integrations.md#docker-autoconf) implique l'utilisation du mode multisite : prot√©ger une application PHP √©quivaut √† prot√©ger plusieurs.

    Lors de l'utilisation de l'int√©gration [Docker autoconf](integrations.md#docker-autoconf), pour prendre en charge les applications PHP, vous devrez :

    - Montez vos fichiers PHP dans le `/var/www/html` dossier de BunkerWeb
    - Configurez un conteneur PHP-FPM pour vos applications et montez le dossier contenant les applications PHP
    - Utilisez les param√®tres sp√©cifiques `REMOTE_PHP` et `REMOTE_PHP_PATH` comme √©tiquettes pour votre conteneur PHP-FPM

    Comme l'autoconf de Docker implique d'utiliser le [mode multisite](concepts.md#multisite-mode), vous devrez cr√©er des r√©pertoires distincts pour chacune de vos applications. Chaque sous-r√©pertoire doit √™tre nomm√© √† l'aide de la premi√®re valeur de `SERVER_NAME`. Voici un exemple fictif :

    ```
    www
    ‚îú‚îÄ‚îÄ app1.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îú‚îÄ‚îÄ app2.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îî‚îÄ‚îÄ app3.example.com
        ‚îî‚îÄ‚îÄ index.php

    3 directories, 3 files
    ```

    Une fois les dossiers cr√©√©s, copiez vos fichiers et corrigez les permissions afin que BunkerWeb (UID/GID 101) puisse au moins lire les fichiers et lister les dossiers et PHP-FPM (UID/GID 33 si vous utilisez l' `php:fpm` image) soit le propri√©taire des fichiers et dossiers :

    ```shell
    chown -R 33:101 ./www && \
    find ./www -type f -exec chmod 0640 {} \; && \
    find ./www -type d -exec chmod 0750 {} \;
    ```

    Lorsque vous d√©marrez la pile autoconf de BunkerWeb, montez le `www` dossier dans `/var/www/html` le  conteneur **Scheduler** :

    ```yaml
    x-bw-api-env: &bw-api-env
      # We use an anchor to avoid repeating the same settings for all services
      AUTOCONF_MODE: "yes"
      API_WHITELIST_IP: "127.0.0.0/8 10.20.30.0/24"

    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.5-rc1
        labels:
          - "bunkerweb.INSTANCE=yes"
        environment:
          <<: *bw-api-env
        volumes:
          - ./www:/var/www/html
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-services

      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
        environment:
          <<: *bw-api-env
          BUNKERWEB_INSTANCES: "" # We don't need to specify the BunkerWeb instance here as they are automatically detected by the autoconf service
          SERVER_NAME: "" # The server name will be filled with services labels
          MULTISITE: "yes" # Mandatory setting for autoconf
          DATABASE_URI: "mariadb+pymysql://bunkerweb:changeme@bw-db:3306/db" # Remember to set a stronger password for the database
        volumes:
          - bw-storage:/data # This is used to persist the cache and other data like the backups
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-db

      bw-autoconf:
        image: bunkerity/bunkerweb-autoconf:1.6.5-rc1
        depends_on:
          - bunkerweb
          - bw-docker
        environment:
          AUTOCONF_MODE: "yes"
          DATABASE_URI: "mariadb+pymysql://bunkerweb:changeme@bw-db:3306/db" # Remember to set a stronger password for the database
          DOCKER_HOST: "tcp://bw-docker:2375" # The Docker socket
        restart: "unless-stopped"
        networks:
          - bw-universe
          - bw-docker
          - bw-db

      bw-docker:
        image: tecnativa/docker-socket-proxy:nightly
        volumes:
          - /var/run/docker.sock:/var/run/docker.sock:ro
        environment:
          CONTAINERS: "1"
          LOG_LEVEL: "warning"
        networks:
          - bw-docker

      bw-db:
        image: mariadb:11
        # We set the max allowed packet size to avoid issues with large queries
        command: --max-allowed-packet=67108864
        environment:
          MYSQL_RANDOM_ROOT_PASSWORD: "yes"
          MYSQL_DATABASE: "db"
          MYSQL_USER: "bunkerweb"
          MYSQL_PASSWORD: "changeme" # Remember to set a stronger password for the database
        volumes:
          - bw-data:/var/lib/mysql
        networks:
          - bw-docker

    volumes:
      bw-data:
      bw-storage:

    networks:
      bw-universe:
        name: bw-universe
        ipam:
          driver: default
          config:
            - subnet: 10.20.30.0/24
      bw-services:
        name: bw-services
      bw-docker:
        name: bw-docker
    ```

    Vous pouvez maintenant cr√©er vos conteneurs PHP-FPM, monter les bons sous-dossiers et utiliser des libell√©s pour configurer BunkerWeb :

    ```yaml
    services:
      myapp1:
          image: php:fpm
          volumes:
            - ./www/app1.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp1
          labels:
            - "bunkerweb.SERVER_NAME=app1.example.com"
            - "bunkerweb.REMOTE_PHP=myapp1"
            - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp2:
          image: php:fpm
          volumes:
            - ./www/app2.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp2
          labels:
            - "bunkerweb.SERVER_NAME=app2.example.com"
            - "bunkerweb.REMOTE_PHP=myapp2"
            - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp3:
          image: php:fpm
          volumes:
            - ./www/app3.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp3
          labels:
            - "bunkerweb.SERVER_NAME=app3.example.com"
            - "bunkerweb.REMOTE_PHP=myapp3"
            - "bunkerweb.REMOTE_PHP_PATH=/app"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

=== "Kubernetes"

    !!! warning "PHP n'est pas pris en charge pour Kubernetes"
      L'int√©gration Kubernetes permet la configuration via [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) et le contr√¥leur BunkerWeb ne prend actuellement en charge que les applications HTTP.

=== "Linux"

    Nous supposerons que vous avez d√©j√† la pile d'int√©gration [Linux integration](integrations.md#linux) en cours d'ex√©cution sur votre machine.

    Par d√©faut, BunkerWeb recherchera les fichiers web dans le dossier /var/www/html. Vous pouvez l'utiliser pour stocker vos applications PHP. Veuillez noter que vous devrez configurer votre service PHP-FPM pour d√©finir l'utilisateur/groupe des processus en cours et le fichier de socket UNIX utilis√© pour communiquer avec BunkerWeb.

    Tout d'abord, assurez-vous que votre instance PHP-FPM peut acc√©der aux fichiers situ√©s dans /var/www/html et que BunkerWeb peut acc√©der au fichier de socket UNIX afin de communiquer avec PHP-FPM. Il est recommand√© d'utiliser un utilisateur distinct tel que www-data pour le service PHP-FPM et d'autoriser le groupe nginx √† acc√©der au fichier de socket UNIX. Voici la configuration PHP-FPM correspondante :

    ```ini
    ...
    [www]
    user = www-data
    group = www-data
    listen = /run/php/php-fpm.sock
    listen.owner = www-data
    listen.group = nginx
    listen.mode = 0660
    ...
    ```

    N'oubliez pas de red√©marrer votre service PHP-FPM :

    ```shell
    systemctl restart php-fpm
    ```

    Si vous activez le [mode multisite](concepts.md#multisite-mode), vous devrez cr√©er des r√©pertoires distincts pour chacune de vos applications. Chaque sous-r√©pertoire doit √™tre nomm√© en utilisant la premi√®re valeur de `SERVER_NAME`. Voici un exemple fictif :

    ```
    /var/www/html
    ‚îú‚îÄ‚îÄ app1.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îú‚îÄ‚îÄ app2.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îî‚îÄ‚îÄ app3.example.com
        ‚îî‚îÄ‚îÄ index.php

    3 directories, 3 files
    ```

    Veuillez noter que vous devrez corriger les permissions afin que BunkerWeb (groupe `nginx`) puisse au moins lire les fichiers et lister les dossiers, et que PHP-FPM (utilisateur `www-data`, qui peut varier selon votre syst√®me) soit le propri√©taire des fichiers et dossiers¬†:

    ```shell
    chown -R www-data:nginx /var/www/html && \
    find /var/www/html -type f -exec chmod 0640 {} \; && \
    find /var/www/html -type d -exec chmod 0750 {} \;
    ```

    Vous pouvez maintenant √©diter le fichier `/etc/bunkerweb/variable.env` :

    ```conf
    HTTP_PORT=80
    HTTPS_PORT=443
    DNS_RESOLVERS=9.9.9.9 8.8.8.8 8.8.4.4
    API_LISTEN_IP=127.0.0.1
    MULTISITE=yes
    SERVER_NAME=app1.example.com app2.example.com app3.example.com
    app1.example.com_LOCAL_PHP=/run/php/php-fpm.sock
    app1.example.com_LOCAL_PHP_PATH=/var/www/html/app1.example.com
    app2.example.com_LOCAL_PHP=/run/php/php-fpm.sock
    app2.example.com_LOCAL_PHP_PATH=/var/www/html/app2.example.com
    app3.example.com_LOCAL_PHP=/run/php/php-fpm.sock
    app3.example.com_LOCAL_PHP_PATH=/var/www/html/app3.example.com
    ```

    V√©rifions maintenant l'√©tat du Scheduler :

    ```shell
    systemctl status bunkerweb-scheduler
    ```

    S'il est d√©j√† en cours d'ex√©cution, nous pouvons le recharger :

    ```shell
    systemctl reload bunkerweb-scheduler
    ```

    Sinon, nous devrons le d√©marrer :

    ```shell
    systemctl start bunkerweb-scheduler
    ```

=== "Swarm"

    !!! warning "Obsol√®te"
        L'int√©gration Swarm est obsol√®te et sera supprim√©e dans une future version. Veuillez envisager d'utiliser l'[int√©gration Kubernetes](integrations.md#kubernetes) √† la place.

        **Plus d'informations sont disponibles dans la [documentation de l'int√©gration Swarm](integrations.md#swarm).**

    !!! info "Mode multisite activ√©"
        L'int√©gration [Swarm](integrations.md#docker-autoconf) implique l'utilisation du mode multisite : prot√©ger une application PHP √©quivaut √† prot√©ger plusieurs applications.

    !!! info "Volume partag√©"
        L'utilisation de PHP avec l'int√©gration Docker Swarm n√©cessite un volume partag√© entre toutes les instances BunkerWeb et PHP-FPM, ce qui n'est pas couvert dans cette documentation.

    Lors de l'utilisation de l'int√©gration [Swarm](integrations.md#swarm), pour prendre en charge les applications PHP, vous devrez :

    - Montez vos fichiers PHP dans le `/var/www/html` dossier de BunkerWeb
    - Configurez un conteneur PHP-FPM pour vos applications et montez le dossier contenant les applications PHP
    - Utilisez les param√®tres sp√©cifiques `REMOTE_PHP` et `REMOTE_PHP_PATH` comme √©tiquettes pour votre conteneur PHP-FPM

    √âtant donn√© que l'int√©gration de Swarm implique l'utilisation du [mode multisite](concepts.md#multisite-mode), vous devrez cr√©er des r√©pertoires distincts pour chacune de vos applications. Chaque sous-r√©pertoire doit √™tre nomm√© √† l'aide de la premi√®re valeur de `SERVER_NAME`. Voici un exemple fictif :

    ```
    www
    ‚îú‚îÄ‚îÄ app1.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îú‚îÄ‚îÄ app2.example.com
    ‚îÇ   ‚îî‚îÄ‚îÄ index.php
    ‚îî‚îÄ‚îÄ app3.example.com
        ‚îî‚îÄ‚îÄ index.php

    3 directories, 3 files
    ```

    √Ä titre d'exemple, nous consid√©rerons que vous avez un dossier partag√© mont√© sur vos n≈ìuds de travail sur le point de `/shared` terminaison.

    Une fois les dossiers cr√©√©s, copiez vos fichiers et corrigez les permissions afin que BunkerWeb (UID/GID 101) puisse au moins lire les fichiers et lister les dossiers et PHP-FPM (UID/GID 33 si vous utilisez l' `php:fpm` image) soit le propri√©taire des fichiers et dossiers :

    ```shell
    chown -R 33:101 /shared/www && \
    find /shared/www -type f -exec chmod 0640 {} \; && \
    find /shared/www -type d -exec chmod 0750 {} \;
    ```

    Lorsque vous d√©marrez la pile BunkerWeb, montez le dossier /shared/www sur /var/www/html dans le conteneur **Scheduler** :

    ```yaml
    services:
      bunkerweb:
        image: bunkerity/bunkerweb:1.6.5-rc1
        volumes:
          - /shared/www:/var/www/html
    ...
    ```

    Vous pouvez maintenant cr√©er vos services PHP-FPM, monter les sous-dossiers appropri√©s et utiliser des labels pour configurer BunkerWeb :

    ```yaml
    services:
      myapp1:
          image: php:fpm
          volumes:
            - ./www/app1.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp1
          deploy:
            placement:
              constraints:
                - "node.role==worker"
            labels:
              - "bunkerweb.SERVER_NAME=app1.example.com"
              - "bunkerweb.REMOTE_PHP=myapp1"
              - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp2:
          image: php:fpm
          volumes:
            - ./www/app2.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp2
          deploy:
            placement:
              constraints:
                - "node.role==worker"
            labels:
              - "bunkerweb.SERVER_NAME=app2.example.com"
              - "bunkerweb.REMOTE_PHP=myapp2"
              - "bunkerweb.REMOTE_PHP_PATH=/app"

      myapp3:
          image: php:fpm
          volumes:
            - ./www/app3.example.com:/app
          networks:
            bw-services:
                aliases:
                  - myapp3
          deploy:
            placement:
              constraints:
                - "node.role==worker"
            labels:
              - "bunkerweb.SERVER_NAME=app3.example.com"
              - "bunkerweb.REMOTE_PHP=myapp3"
              - "bunkerweb.REMOTE_PHP_PATH=/app"

    networks:
      bw-services:
        external: true
        name: bw-services
    ```

### IPv6

!!! example "Fonctionnalit√© exp√©rimentale"

    Cette fonctionnalit√© n'est pas pr√™te pour la production. N'h√©sitez pas √† la tester et √† nous signaler tout bug via les [issues](https://github.com/bunkerity/bunkerweb/issues) du d√©p√¥t GitHub.

Par d√©faut, BunkerWeb n'√©coutera que les adresses IPv4 et n'utilisera pas IPv6 pour les communications r√©seau. Si vous souhaitez activer la prise en charge d'IPv6, vous devez d√©finir `USE_IPV6=yes`. Veuillez noter que la configuration IPv6 de votre r√©seau et de votre environnement n'entre pas dans le champ d'application de cette documentation.

=== "Docker / Autoconf / Swarm"

    Tout d'abord, vous devrez configurer le d√©mon Docker pour activer la prise en charge d'IPv6 pour les conteneurs et utiliser ip6tables si n√©cessaire. Voici une configuration d'exemple pour votre fichier /etc/docker/daemon.json :

    ```json
    {
      "experimental": true,
      "ipv6": true,
      "ip6tables": true,
      "fixed-cidr-v6": "fd00:dead:beef::/48"
    }
    ```

    Vous pouvez maintenant red√©marrer le service Docker pour appliquer les modifications :

    ```shell
    systemctl restart docker
    ```

    Une fois Docker configur√© pour prendre en charge IPv6, vous pouvez ajouter le param√®tre `USE_IPV6` et configurer le r√©seau bw-services pour IPv6 :

    ```yaml
    services:
      bw-scheduler:
        image: bunkerity/bunkerweb-scheduler:1.6.5-rc1
        environment:
          USE_IPv6: "yes"

    ...

    networks:
      bw-services:
        name: bw-services
        enable_ipv6: true
        ipam:
          config:
            - subnet: fd00:13:37::/48
              gateway: fd00:13:37::1

    ...
    ```

=== "Linux"

    Vous devrez ajouter ces param√®tres au fichier /etc/bunkerweb/variables.env :

    ```conf
    ...
    USE_IPV6=yes
    ...
    ```

    V√©rifions maintenant l'√©tat de BunkerWeb :

    ```shell
    systemctl status bunkerweb
    ```

    S'il est d√©j√† en cours d'ex√©cution, nous pouvons le red√©marrer :

    ```shell
    systemctl restart bunkerweb
    ```

    Sinon, nous devrons le d√©marrer :

    ```shell
    systemctl start bunkerweb
    ```

## R√©glage de la s√©curit√©

BunkerWeb offre de nombreuses fonctionnalit√©s de s√©curit√© que vous pouvez configurer avec les [fonctionnalit√©s](features.md). M√™me si les valeurs par d√©faut des param√®tres assurent une "s√©curit√© par d√©faut" minimale, nous vous recommandons vivement de les r√©gler. Ce faisant, vous serez en mesure de vous assurer du niveau de s√©curit√© de votre choix, mais aussi de g√©rer les faux positifs.

!!! tip "Autres fonctionnalit√©s"
    Cette section se concentre uniquement sur le r√©glage de la s√©curit√©, voir la section [fonctionnalit√©s](features.md) de la documentation pour d'autres param√®tres.

<figure markdown>
  ![Vue d'ensemble](assets/img/core-order.svg){ align=center }
  <figcaption>Vue d'ensemble et ordre des plugins de s√©curit√© de base</figcaption>
</figure>

## Int√©gration de la console CrowdSec

Si vous n'√™tes pas d√©j√† familier avec l'int√©gration de la console CrowdSec, [CrowdSec](https://www.crowdsec.net/?utm_campaign=bunkerweb&utm_source=doc) exploite l'intelligence participative pour lutter contre les cybermenaces. Consid√©rez-le comme le "Waze de la cybers√©curit√©" : lorsqu'un serveur est attaqu√©, les autres syst√®mes du monde entier sont alert√©s et prot√©g√©s contre les m√™mes attaquants. Vous pouvez en savoir plus √† ce sujet [ici](https://www.crowdsec.net/about?utm_campaign=bunkerweb&utm_source=blog).

**F√©licitations, votre instance BunkerWeb est maintenant inscrite dans votre console CrowdSec !**

Conseil professionnel : Lorsque vous consultez vos alertes, cliquez sur l'option "colonnes" et cochez la case "contexte" pour acc√©der aux donn√©es sp√©cifiques √† BunkerWeb.

<figure markdown>
  ![Vue d'ensemble](assets/img/crowdity4.png){ align=center }
  <figcaption>Donn√©es BunkerWeb affich√©es dans la colonne de contexte</figcaption>
</figure>

## Surveillance et rapports

#### Monitoring <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Prise en charge de STREAM :x:

Le plugin de surveillance vous permet de collecter et de r√©cup√©rer des m√©triques sur BunkerWeb. En l'activant, votre ou vos instances commenceront √† collecter diverses donn√©es li√©es aux attaques, aux requ√™tes et aux performances. Vous pouvez ensuite les r√©cup√©rer en appelant r√©guli√®rement le point de terminaison de l' `/monitoring` API ou en utilisant d'autres plugins comme celui de l'exportateur Prometheus.

**Liste des fonctionnalit√©s**

- Permettre la collecte de diverses m√©triques BunkerWeb
- R√©cup√©rer des m√©triques √† partir de l'API
- Utilisation en combinaison avec d'autres plugins (par exemple Prometheus exporter)
- D√©di√©e √† la page d'interface utilisateur pour surveiller vos instances

**Liste des param√®tres**

| R√©glage                        | D√©faut | Contexte | Multiple | Description                                                        |
| ------------------------------ | ------ | -------- | -------- | ------------------------------------------------------------------ |
| `USE_MONITORING`               | `yes`  | global   | Non      | Activez la surveillance de BunkerWeb.                              |
| `MONITORING_METRICS_DICT_SIZE` | `10M`  | global   | Non      | Taille du dictionnaire pour stocker les m√©triques de surveillance. |

#### Prometheus exporter <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Prise en charge de STREAM :x:

Le plugin d'exportation Prometheus ajoute un [exportateur Prometheus](https://prometheus.io/docs/instrumenting/exporters/) sur votre ou vos instances BunkerWeb. Lorsqu'elle est activ√©e, vous pouvez configurer votre ou vos instances Prometheus pour r√©cup√©rer un point de terminaison sp√©cifique sur Bunkerweb et collecter des m√©triques internes.

Nous fournissons √©galement un [tableau de bord Grafana](https://grafana.com/grafana/dashboards/20755-bunkerweb/) que vous pouvez importer dans votre propre instance et connecter √† votre propre source de donn√©es Prometheus.

**Veuillez noter que l'utilisation du plugin d'exportation Prometheus n√©cessite d'activer le plugin de surveillance (`USE_MONITORING=yes`)**

**Liste des fonctionnalit√©s**

- L'exportateur Prometheus fournit des m√©triques internes √† BunkerWeb
- Port d√©di√© et configurable, IP et URL d'√©coute
- Liste blanche IP/r√©seau pour une s√©curit√© maximale

**Liste des param√®tres**

| R√©glage                        | Dd√©faut                                               | Contexte | Multiple | Description                                                                                              |
| ------------------------------ | ----------------------------------------------------- | -------- | -------- | -------------------------------------------------------------------------------------------------------- |
| `USE_PROMETHEUS_EXPORTER`      | `no`                                                  | global   | Non      | Activez l'exportation Prometheus.                                                                        |
| `PROMETHEUS_EXPORTER_IP`       | `0.0.0.0`                                             | global   | Non      | IP d'√©coute de l'exportateur Prometheus.                                                                 |
| `PROMETHEUS_EXPORTER_PORT`     | `9113`                                                | global   | Non      | Port d'√©coute de l'exportateur Prometheus.                                                               |
| `PROMETHEUS_EXPORTER_URL`      | `/metrics`                                            | global   | Non      | URL HTTP de l'exportateur Prometheus.                                                                    |
| `PROMETHEUS_EXPORTER_ALLOW_IP` | `127.0.0.0/8 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16` | global   | Non      | Liste des adresses IP/r√©seaux autoris√©s √† contacter le point de terminaison de l'exportateur Prometheus. |

#### Reporting <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Prise en charge de STREAM :x:

!!! warning "Plugin de surveillance n√©cessaire"
    Ce plug-in n√©cessite l'installation et l'activation du plug-in Monitoring Pro avec le `USE_MONITORING` param√®tre d√©fini sur `yes`.

Le plugin Reporting fournit une solution compl√®te pour la communication r√©guli√®re de donn√©es importantes de BunkerWeb, y compris les statistiques mondiales, les attaques, les bannissements, les demandes, les raisons et les informations AS. Il offre un large √©ventail de fonctionnalit√©s, notamment la cr√©ation automatique de rapports, des options de personnalisation et une int√©gration transparente avec le plugin monitoring pro. Avec le plugin Reporting, vous pouvez facilement g√©n√©rer et g√©rer des rapports pour surveiller les performances et la s√©curit√© de votre application.

**Liste des fonctionnalit√©s**

- Rapports r√©guliers sur les donn√©es importantes de BunkerWeb, y compris les statistiques mondiales, les attaques, les bannissements, les demandes, les raisons et les informations sur les SA.
- Int√©gration avec le plug-in Monitoring Pro pour une int√©gration transparente et des capacit√©s de reporting am√©lior√©es.
- Prise en charge des webhooks (classique, Discord et Slack) pour les notifications en temps r√©el.
- Prise en charge de SMTP pour les notifications par e-mail.
- Options de configuration pour plus de personnalisation et de flexibilit√©.

**Liste des param√®tres**

| R√©glage                        | Faire d√©faut       | Contexte | Description                                                                                                                     |
| ------------------------------ | ------------------ | -------- | ------------------------------------------------------------------------------------------------------------------------------- |
| `USE_REPORTING_SMTP`           | `no`               | global   | Activez l'envoi du rapport par e-mail.                                                                                          |
| `USE_REPORTING_WEBHOOK`        | `no`               | global   | Activez l'envoi du rapport via le webhook.                                                                                      |
| `REPORTING_SCHEDULE`           | `weekly`           | global   | La fr√©quence √† laquelle les rapports sont envoy√©s.                                                                              |
| `REPORTING_WEBHOOK_URLS`       |                    | global   | Liste des URL de webhook pour recevoir le rapport en Markdown (s√©par√©es par des espaces).                                       |
| `REPORTING_SMTP_EMAILS`        |                    | global   | Liste des adresses e-mail pour recevoir le rapport au format HTML (s√©par√©es par des espaces).                                   |
| `REPORTING_SMTP_HOST`          |                    | global   | Serveur h√¥te utilis√© pour l'envoi SMTP.                                                                                         |
| `REPORTING_SMTP_PORT`          | `465`              | global   | Port utilis√© pour SMTP. Veuillez noter qu'il existe diff√©rentes normes en fonction du type de connexion (SSL = 465, TLS = 587). |
| `REPORTING_SMTP_FROM_EMAIL`    |                    | global   | L'adresse e-mail utilis√©e comme exp√©diteur. Notez que 2FA doit √™tre d√©sactiv√© pour cette adresse e-mail.                        |
| `REPORTING_SMTP_FROM_USER`     |                    | global   | Valeur d'authentification de l'utilisateur pour l'envoi via l'adresse e-mail de l'exp√©diteur.                                   |
| `REPORTING_SMTP_FROM_PASSWORD` |                    | global   | La valeur d'authentification par mot de passe pour l'envoi via l'adresse e-mail de l'exp√©diteur.                                |
| `REPORTING_SMTP_SSL`           | `SSL`              | global   | D√©terminez s'il faut ou non utiliser une connexion s√©curis√©e pour SMTP.                                                         |
| `REPORTING_SMTP_SUBJECT`       | `BunkerWeb Report` | global   | La ligne d'objet de l'e-mail.                                                                                                   |

!!! info "Information et comportement"
    - cas `USE_REPORTING_SMTP` est d√©fini sur `yes`, le param√®tre `REPORTING_SMTP_EMAILS` doit √™tre d√©fini.
    - cas `USE_REPORTING_WEBHOOK` est d√©fini sur `yes`, le param√®tre `REPORTING_WEBHOOK_URLS` doit √™tre d√©fini.
    - Les valeurs accept√©es pour `REPORTING_SCHEDULE` sont `daily`, `weekly` et `monthly`.
    - cas aucun `REPORTING_SMTP_FROM_USER` et `REPORTING_SMTP_FROM_PASSWORD` ne sont d√©finis, le plugin essaiera d'envoyer l'e-mail sans authentification.
    - cas `REPORTING_SMTP_FROM_USER` n'est pas d√©fini mais `REPORTING_SMTP_FROM_PASSWORD` est d√©fini, le plugin utilisera le `REPORTING_SMTP_FROM_EMAIL` comme nom d'utilisateur.
    - En cas d'√©chec du travail, le plug-in r√©essaiera d'envoyer le rapport lors de la prochaine ex√©cution.

### Sauvegarde et restauration

#### Backup S3 <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Prise en charge STREAM :white_check_mark:

L'outil Backup S3 automatise de mani√®re transparente la protection des donn√©es, √† l'instar du plug-in de sauvegarde communautaire. Cependant, il se distingue par le stockage s√©curis√© des sauvegardes directement dans un compartiment S3.

En activant cette fonctionnalit√©, vous prot√©gez de mani√®re proactive **l'int√©grit√© de vos donn√©es**. Le stockage √† **distance** des sauvegardes prot√®ge les informations cruciales contre les menaces telles que ** les pannes mat√©rielles**, **les cyberattaques** ou **les catastrophes naturelles**. Cela garantit √† la fois **la s√©curit√©** et **la disponibilit√©**, ce qui permet une r√©cup√©ration rapide en cas ** d'√©v√©nements inattendus**, pr√©servant la **continuit√© op√©rationnelle** et garantissant **la tranquillit√© d'esprit**.

??? warning "Informations pour les utilisateurs de Red Hat Enterprise Linux (RHEL) 8.9"
    Si vous utilisez **RHEL 8.9** et que vous pr√©voyez d'utiliser une **base de donn√©es externe**, vous devez installer le `mysql-community-client` package pour vous assurer que la `mysqldump` commande est disponible. Vous pouvez installer le package en ex√©cutant les commandes suivantes :

    === "MySQL/MariaDB"

        1. **Installez le paquet de configuration du d√©p√¥t MySQL**

          ```bash
          sudo dnf install https://dev.mysql.com/get/mysql80-community-release-el8-9.noarch.rpm
          ```

        2. **Activez le d√©p√¥t MySQL**

          ```bash
          sudo dnf config-manager --enable mysql80-community
          ```

        3. **Installez le client MySQL**

          ```bash
          sudo dnf install mysql-community-client
          ```

    === "PostgreSQL"

        1. **Installez le paquet de configuration du d√©p√¥t PostgreSQL**

          ```bash
          dnf install "https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-$(uname -m)/pgdg-redhat-repo-latest.noarch.rpm"
          ```

        2. **Installez le client PostgreSQL**

          ```bash
          dnf install postgresql<version>
          ```

**Liste des fonctionnalit√©s**

- Sauvegarde automatique des donn√©es dans un compartiment S3
- Options de planification flexibles : quotidienne, hebdomadaire ou mensuelle
- Gestion de la rotation pour contr√¥ler le nombre de sauvegardes √† conserver
- Niveau de compression personnalisable pour les fichiers de sauvegarde

**Liste des param√®tres**

| R√©glage                       | Faire d√©faut | Contexte | Description                                           |
| ----------------------------- | ------------ | -------- | ----------------------------------------------------- |
| `USE_BACKUP_S3`               | `no`         | global   | Activer ou d√©sactiver la fonction de sauvegarde S3    |
| `BACKUP_S3_SCHEDULE`          | `daily`      | global   | La fr√©quence de la sauvegarde                         |
| `BACKUP_S3_ROTATION`          | `7`          | global   | Le nombre de sauvegardes √† conserver                  |
| `BACKUP_S3_ENDPOINT`          |              | global   | Le point de terminaison S3                            |
| `BACKUP_S3_BUCKET`            |              | global   | Le godet S3                                           |
| `BACKUP_S3_DIR`               |              | global   | L'annuaire S3                                         |
| `BACKUP_S3_REGION`            |              | global   | La r√©gion S3                                          |
| `BACKUP_S3_ACCESS_KEY_ID`     |              | global   | L'ID de la cl√© d'acc√®s S3                             |
| `BACKUP_S3_ACCESS_KEY_SECRET` |              | global   | Le secret de la cl√© d'acc√®s S3                        |
| `BACKUP_S3_COMP_LEVEL`        | `6`          | global   | Le niveau de compression du fichier zip de sauvegarde |

##### Sauvegarde manuelle

Pour lancer manuellement une sauvegarde, ex√©cutez la commande suivante :

=== "Linux"

    ```bash
    bwcli plugin backup_s3 save
    ```

=== "Docker"

    ```bash
    docker exec -it <scheduler_container> bwcli plugin backup_s3 save
    ```

Cette commande cr√©e une sauvegarde de votre base de donn√©es et la stocke dans le compartiment S3 sp√©cifi√© dans le `BACKUP_S3_BUCKET` param√®tre.

Vous pouvez √©galement sp√©cifier un compartiment S3 personnalis√© pour la sauvegarde en fournissant la variable d' `BACKUP_S3_BUCKET` environnement lors de l'ex√©cution de la commande :

=== "Linux"

    ```bash
    BACKUP_S3_BUCKET=your-bucket-name bwcli plugin backup_s3 save
    ```

=== "Docker"

    ```bash
    docker exec -it -e BACKUP_S3_BUCKET=your-bucket-name <scheduler_container> bwcli plugin backup_s3 save
    ```

!!! note "Sp√©cifications pour MariaDB/MySQL"

    Si vous utilisez MariaDB/MySQL, vous pouvez rencontrer l'erreur suivante lors de la sauvegarde de votre base de donn√©es :

    ```bash
    caching_sha2_password could not be loaded: Error loading shared library /usr/lib/mariadb/plugin/caching_sha2_password.so
    ```

    Pour r√©soudre ce probl√®me, vous pouvez ex√©cuter la commande suivante pour changer le plugin d'authentification en `mysql_native_password` :

    ```sql
    ALTER USER 'yourusername'@'localhost' IDENTIFIED WITH mysql_native_password BY 'youpassword';
    ```

    Si vous utilisez l'int√©gration Docker, vous pouvez ajouter la commande suivante au fichier `docker-compose.yml` pour changer automatiquement le plugin d'authentification :

    === "MariaDB"

        ```yaml
        bw-db:
            image: mariadb:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

    === "MySQL"

        ```yaml
        bw-db:
            image: mysql:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

##### Restauration manuelle

Pour lancer manuellement une restauration, ex√©cutez la commande suivante :

=== "Linux"

    ```bash
    bwcli plugin backup_s3 restore
    ```

=== "Docker"

    ```bash
    docker exec -it <scheduler_container> bwcli plugin backup_s3 restore
    ```

Cette commande cr√©e une sauvegarde temporaire de votre base de donn√©es dans le compartiment S3 sp√©cifi√© dans le `BACKUP_S3_BUCKET` param√®tre et restaure votre base de donn√©es √† la derni√®re sauvegarde disponible dans le compartiment.

Vous pouvez √©galement sp√©cifier un fichier de sauvegarde personnalis√© pour la restauration en fournissant le chemin d'acc√®s √† celui-ci en tant qu'argument lors de l'ex√©cution de la commande :

=== "Linux"

    ```bash
    bwcli plugin backup_s3 restore s3_backup_file.zip
    ```

=== "Docker"

    ```bash
    docker exec -it <scheduler_container> bwcli plugin backup restore s3_backup_file.zip
    ```

!!! example "En cas de panne"

    Don't worry if the restore fails, you can always restore your database to the previous state by executing the command again as a backup is created before the restore:

    === "Linux"

        ```bash
        bwcli plugin backup_s3 restore
        ```

    === "Docker"

        ```bash
        docker exec -it <scheduler_container> bwcli plugin backup_s3 restore
        ```

### Migration <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Prise en charge STREAM :white_check_mark:

Le plug-in de migration **r√©volutionne les transferts de** configuration BunkerWeb entre les instances gr√¢ce √† son **interface Web conviviale**, simplifiant ainsi l'ensemble du parcours de migration. Que vous mettiez √† niveau des syst√®mes, que vous fassiez √©voluer une infrastructure ou que vous transformiez d'environnement, cet outil vous permet de transf√©rer sans effort les **param√®tres, les pr√©f√©rences et les donn√©es** avec une facilit√© et une confiance in√©gal√©es. Dites adieu aux processus manuels fastidieux et bonjour √† une exp√©rience de **migration transparente et sans tracas**.

**Liste des fonctionnalit√©s**

- **Migration sans effort :** Transf√©rez facilement les configurations BunkerWeb entre les instances sans les complexit√©s des proc√©dures manuelles.

- **Interface Web intuitive :** Naviguez sans effort dans le processus de migration gr√¢ce √† une interface Web conviviale con√ßue pour un fonctionnement intuitif.

- **Compatibilit√© entre bases de donn√©es :** profitez d'une migration transparente sur diverses plates-formes de bases de donn√©es, notamment SQLite, MySQL, MariaDB et PostgreSQL, garantissant la compatibilit√© avec votre environnement de base de donn√©es pr√©f√©r√©.

#### Cr√©er un fichier de migration

Pour cr√©er manuellement un fichier de migration, ex√©cutez la commande suivante :

=== "Linux"

    ```bash
    bwcli plugin migration create /path/to/migration/file
    ```

=== "Docker"

    1. Cr√©ez un fichier de migration :

        ```bash
        docker exec -it <scheduler_container> bwcli plugin migration create /path/to/migration/file
        ```

    2. Copiez le fichier de migration sur votre ordinateur local :

        ```bash
        docker cp <scheduler_container>:/path/to/migration/file /path/to/migration/file
        ```

Cette commande cr√©era une sauvegarde de votre base de donn√©es et la stockera dans le r√©pertoire de sauvegarde sp√©cifi√© dans la commande.

!!! note "Sp√©cifications pour MariaDB/MySQL"

    Si vous utilisez MariaDB/MySQL, vous pouvez rencontrer l'erreur suivante lors de la sauvegarde de votre base de donn√©es :

    ```bash
    caching_sha2_password could not be loaded: Error loading shared library /usr/lib/mariadb/plugin/caching_sha2_password.so
    ```

    Pour r√©soudre ce probl√®me, vous pouvez ex√©cuter la commande suivante pour changer le plugin d'authentification en `mysql_native_password` :

    ```sql
    ALTER USER 'yourusername'@'localhost' IDENTIFIED WITH mysql_native_password BY 'youpassword';
    ```

    Si vous utilisez l'int√©gration Docker, vous pouvez ajouter la commande suivante au fichier `docker-compose.yml` pour changer automatiquement le plugin d'authentification :

    === "MariaDB"

        ```yaml
        bw-db:
            image: mariadb:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

    === "MySQL"

        ```yaml
        bw-db:
            image: mysql:<version>
            command: --default-authentication-plugin=mysql_native_password
            ...
        ```

#### Initialiser une migration

Pour initialiser manuellement une migration, ex√©cutez la commande suivante :

=== "Linux"

    ```bash
    bwcli plugin migration migrate /path/to/migration/file
    ```

=== "Docker"

    1. Copiez le fichier de migration dans le conteneur :

        ```bash
        docker cp /path/to/migration/file <scheduler_container>:/path/to/migration/file
        ```

    2. Initialisez la migration :

        ```bash
        docker exec -it <scheduler_container> bwcli plugin migration migrate /path/to/migration/file
        ```

=== "Tout-en-un"

    1. Copiez le fichier de migration dans le conteneur :

        ```bash
        docker cp /path/to/migration/file bunkerweb-aio:/path/to/migration/file
        ```

    2. Initialisez la migration :

        ```bash
        docker exec -it bunkerweb-aio bwcli plugin migration migrate /path/to/migration/file
        ```

Cette commande migre de mani√®re transparente vos donn√©es BunkerWeb pour qu'elles correspondent pr√©cis√©ment √† la configuration d√©crite dans le fichier de migration.

## Anti DDoS <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Prise en charge de STREAM :x:

Le  plug-in **anti-DDoS** offre une protection avanc√©e contre les attaques par d√©ni de service distribu√© (DDoS) en surveillant, analysant et filtrant le trafic suspect en temps r√©el.

En utilisant un m√©canisme de **fen√™tre glissante**, le plugin maintient un dictionnaire en m√©moire des horodatages des requ√™tes pour d√©tecter les pics de trafic anormaux √† partir d'adresses IP individuelles. En fonction du mode de s√©curit√© configur√©, il peut soit bloquer les connexions incrimin√©es, soit consigner l'activit√© suspecte pour un examen plus approfondi.

#### Fonctionnalit√©s

- **Analyse du trafic en temps r√©el :** surveille en permanence les demandes entrantes pour d√©tecter les attaques DDoS potentielles.
- **M√©canisme de fen√™tre glissante :** suit l'activit√© r√©cente des demandes dans une fen√™tre de temps configurable.
- **Seuils configurables :** vous permet de d√©finir le nombre maximum de requ√™tes suspectes par IP.
- **Logique de blocage avanc√©e :** √©value √† la fois le nombre de requ√™tes par IP et le nombre d'adresses IP distinctes d√©passant le seuil.
- **Modes de s√©curit√© flexibles :** choisissez entre le blocage imm√©diat de la connexion ou le mode de d√©tection uniquement (journalisation).
- **Magasin de donn√©es en m√©moire optimis√© :** Garantit des recherches √† grande vitesse et un suivi efficace des m√©triques.
- **Entretien m√©nager automatique :** efface p√©riodiquement les donn√©es obsol√®tes pour maintenir des performances optimales.

#### Configuration

Personnalisez le comportement du plug-in √† l'aide des param√®tres suivants :

| R√©glage                      | Faire d√©faut  | Contexte | Multiple | Description                                                                                                 |
| ---------------------------- | ------------- | -------- | -------- | ----------------------------------------------------------------------------------------------------------- |
| `USE_ANTIDDOS`               | `no`          | global   | Non      | Activez ou d√©sactivez la protection anti-DDoS. R√©glez sur `"yes"` pour activer le plugin.                   |
| `ANTIDDOS_METRICS_DICT_SIZE` | `10M`         | global   | Non      | Taille de la banque de donn√©es en m√©moire pour le suivi des m√©triques DDoS (par exemple, `10M`, `500k`).    |
| `ANTIDDOS_THRESHOLD`         | `100`         | global   | Non      | Nombre maximum de requ√™tes suspectes autoris√©es par IP dans la fen√™tre de temps d√©finie.                    |
| `ANTIDDOS_WINDOW_TIME`       | `10`          | global   | Non      | Fen√™tre de temps en secondes pendant laquelle les demandes suspectes sont comptabilis√©es.                   |
| `ANTIDDOS_STATUS_CODES`      | `429 403 444` | global   | Non      | Codes d'√©tat HTTP consid√©r√©s comme suspects et utilis√©s pour d√©clencher des actions anti-DDoS.              |
| `ANTIDDOS_DISTINCT_IP`       | `5`           | global   | Non      | Nombre minimum d'adresses IP distinctes qui doivent d√©passer le seuil avant d'appliquer le mode de blocage. |

#### Bonnes pratiques

- **R√©glage du seuil :** ajustez `ANTIDDOS_THRESHOLD` et `ANTIDDOS_WINDOW_TIME` en fonction de vos mod√®les de trafic typiques.
- **R√©vision du code d'√©tat :** mettez r√©guli√®rement √† jour `ANTIDDOS_STATUS_CODES` pour capturer les comportements suspects nouveaux ou en √©volution.
- **Surveillance :** analysez r√©guli√®rement les journaux et les m√©triques pour affiner les param√®tres et am√©liorer la protection globale.

## Gestionnaire d'utilisateurs <img src='../assets/img/pro-icon.svg' alt='crow pro icon' height='24px' width='24px' style="transform : translateY(3px);"> (PRO)

Le plug-in de gestion des utilisateurs offre une interface robuste pour l'administration des comptes d'utilisateurs au sein de votre syst√®me.

Avec ce plugin, les administrateurs peuvent sans effort cr√©er, mettre √† jour et d√©sactiver des comptes utilisateurs, g√©rer les r√¥les des utilisateurs, basculer l'authentification √† deux facteurs (2FA) et afficher des informations d√©taill√©es sur les utilisateurs telles que les horodatages de la derni√®re connexion et les statuts des comptes (actif ou inactif). Con√ßu dans un souci de s√©curit√© et de facilit√© d'utilisation, ce plug-in simplifie les t√¢ches de gestion des utilisateurs tout en garantissant la conformit√© et l'auditabilit√©.

#### Fonctionnalit√©s

- **Op√©rations de compte d'utilisateur :** importez au format CSV/XSLX, cr√©ez, modifiez et supprimez des comptes d'utilisateur en toute simplicit√©.
- **Contr√¥le d'acc√®s bas√© sur les r√¥les :** Attribuez et modifiez les r√¥les d'utilisateur pour g√©rer les autorisations et les niveaux d'acc√®s.
- **Gestion 2FA :** d√©sactivez l'authentification √† deux facteurs en fonction des d√©cisions administratives.
- **Informations compl√®tes sur les utilisateurs :** surveillez les donn√©es cl√©s des utilisateurs, notamment les heures de derni√®re connexion, les dates de cr√©ation de compte et le statut actif/inactif.
- **Journalisation des audits :** conservez une piste d'audit pour toutes les actions de gestion des utilisateurs afin d'am√©liorer la s√©curit√© et la conformit√©.

<figure markdown>
  ![Vue d'ensemble](assets/img/user-manager.png){ align=center }
  <figcaption>Page Gestionnaire d'utilisateurs</figcaption>
</figure>

<figure markdown>
  ![Cr√©er un formulaire utilisateur](assets/img/user-manager-create.png){ align=center }
  <figcaption>Gestionnaire d'utilisateurs - Cr√©er un formulaire d'utilisateur</figcaption>
</figure>

<figure markdown>
  ![Page d'activit√©s](assets/img/user-manager-activities.png){ align=center }
  <figcaption>Gestionnaire d'utilisateurs - Page Activit√©s</figcaption>
</figure>
